import pandas as pd
import numpy as np
import pyupbit
import datetime
import requests
import random
import time
import os
import json
from langchain.text_splitter import RecursiveCharacterTextSplitter
# ê¸°ì¡´ importë“¤ê³¼ í•¨ê»˜ ì¶”ê°€
from trading_parser import TradingDecisionParser
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from tqdm import tqdm
import statistics  # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ statistics ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
import time  # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ëª¨ë“ˆ

# ì…€ë ˆë‹ˆì›€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class AIBacktester:
    def __init__(self, llama_model_path, n_gpu_layers=20, news_api_key=None, 
             news_datasets=None, use_selenium=False, headless=True, timeframe='1h'):
        """
        Initialize the AI backtesting system with LLM and news integration
        """
        self.model_path = llama_model_path
        self.n_gpu_layers = n_gpu_layers
        self.news_api_key = news_api_key
        self.document_store = []
        self.vectorizer = TfidfVectorizer()
        self.vectors = None

        # ìƒˆë¡œ ì¶”ê°€: timeframe ì„¤ì •
        self.timeframe = timeframe

         # ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì˜¤ë¥˜ ë°©ì§€)
        self.news_database = {}
        self.news_correlations = {}

         # RAG ì‹œìŠ¤í…œìš© ì´ˆê¸°í™”
        self.pattern_correlations = {}  # íŒ¨í„´ ìƒê´€ê´€ê³„ ì €ì¥

        self.trailing_stop_price = None  # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê°€ê²© ì¶”ì ìš©
        self.test_mode = True  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ í”Œë˜ê·¸
        
        # ===== ì¤‘ìš” ì¶”ê°€: historical_data ì´ˆê¸°í™” =====
        self.historical_data = []  # ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘ ëˆ„ì ë˜ëŠ” ê³¼ê±° ë°ì´í„°
        self.backtest_results = []  # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        
        # ë‰´ìŠ¤ ë°ì´í„° ê´€ë ¨ ì„¤ì •
        self.news_datasets = news_datasets or []
        self.use_selenium = use_selenium
        self.selenium_driver = None
        

        # ì¤‘ìš”: ì²˜ë¦¬ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì§‘í•©ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ëª…ì‹œì  ì´ˆê¸°í™”
        self.processed_timestamps = set()


        # ì…€ë ˆë‹ˆì›€ ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.news_cache_dir = "news_cache"
        os.makedirs(self.news_cache_dir, exist_ok=True)
        
        # TradingDecisionParser ì´ˆê¸°í™” (ì¶”ê°€)
        try:
            self.trading_parser = TradingDecisionParser(
                model_name="korean",  # Ollama ëª¨ë¸ëª…
                host="localhost",
                port=11434
            )
            print("TradingDecisionParser ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë¨")
        except Exception as e:
            print(f"Warning: TradingDecisionParser ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            print("íŒŒì„œ ì—†ì´ ì§„í–‰í•˜ì§€ë§Œ LLM íŒŒì‹± í’ˆì§ˆì´ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            self.trading_parser = None
        
        # ë‹¤ì¤‘ ë‰´ìŠ¤ ë°ì´í„°ì…‹ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” (í˜•ì‹ ìë™ ê°ì§€)
        self.news_handlers = []
        print(f"Initialized with {len(self.news_datasets)} datasets")
        for dataset in self.news_datasets:
            print(f"Attempting to load dataset: {dataset}")

        for dataset_path in self.news_datasets:
            try:
                print(f"Loading dataset from: {dataset_path}")
                handler = NewsDatasetHandler(dataset_path)
                self.news_handlers.append(handler)
                print(f"News dataset loaded: {dataset_path} (Format: {handler.format_config['type']})")
            except Exception as e:
                print(f"Failed to load dataset {dataset_path}: {str(e)}")
        
        # ì…€ë ˆë‹ˆì›€ ë“œë¼ì´ë²„ ì´ˆê¸°í™” (ë‰´ìŠ¤ ê²€ìƒ‰ì— ì‚¬ìš©)
        if self.use_selenium:
            try:
                chrome_options = Options()
                if headless:
                    chrome_options.add_argument("--headless")
                chrome_options.add_argument("--no-sandbox")
                chrome_options.add_argument("--disable-dev-shm-usage")
                chrome_options.add_argument("--disable-gpu")
                chrome_options.add_argument("--window-size=1920,1080")
                chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
                
                # ê³ ìœ í•œ user-data-dir ì‚¬ìš©
                import tempfile
                temp_dir = tempfile.mkdtemp()
                chrome_options.add_argument(f"--user-data-dir={temp_dir}")
                chrome_options.add_argument("--disable-web-security")
                chrome_options.add_argument("--disable-features=VizDisplayCompositor")
                chrome_options.add_argument("--remote-debugging-port=0")
                
                self.selenium_driver = webdriver.Chrome(options=chrome_options)
                print("Selenium driver successfully initialized!")
            except Exception as e:
                print(f"Error initializing Selenium driver: {str(e)}")
                self.selenium_driver = None
                self.use_selenium = False
        
        # Initialize LLM
        try:
            from llama_cpp import Llama
            self.llm = Llama(
                model_path=self.model_path,
                n_gpu_layers=self.n_gpu_layers,
                n_ctx=8192
            )
            print("LLM successfully initialized!")
        except Exception as e:
            print(f"Error initializing LLM: {str(e)}")
            self.llm = None
    
    

    def calculate_opportunity_score(self, tech_indicators, price, current_news):
        """RAG ê¸°ë°˜ íˆ¬ì ê¸°íšŒ ì ìˆ˜ ê³„ì‚° (0-100ì )"""
        
        # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
        similar_patterns = self.find_similar_patterns(tech_indicators, success_weight=True, time_decay=True)
        
        if not similar_patterns:
            return 0, "íŒ¨í„´ ë°ì´í„° ë¶€ì¡±"
        
        # ì™„ë£Œëœ ê±°ë˜ë§Œ í•„í„°ë§
        completed_patterns = [p for p in similar_patterns if p.get('trade_result', {}).get('completed', False)]
        
        if len(completed_patterns) < 3:
            return 25, f"íŒ¨í„´ ë¶€ì¡± ({len(completed_patterns)}ê°œ)"
        
        # ì„±ê³µë¥  ê³„ì‚°
        successful = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
        success_rate = len(successful) / len(completed_patterns)
        
        # í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°  
        avg_profit = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in successful) / len(successful) if successful else 0
        
        # ë‰´ìŠ¤ ê°ì„± ë³´ì •
        news_sentiment = self.analyze_news_sentiment(current_news)
        news_boost = 0
        if news_sentiment['sentiment_score'] > 0.3:
            news_boost = 10
        elif news_sentiment['sentiment_score'] < -0.3:
            news_boost = -10
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        base_score = (success_rate * 60) + (min(avg_profit, 10) * 4)  # ìµœëŒ€ 100ì 
        final_score = max(0, min(100, base_score + news_boost))
        
        reason = f"ìŠ¹ë¥  {success_rate:.0%}, í‰ê· ìˆ˜ìµ {avg_profit:.1f}%, íŒ¨í„´ {len(completed_patterns)}ê°œ"
        
        return final_score, reason
    


    
    def rag_based_trigger_check(self, price, timestamp, tech_indicators, current_news):
        """RAG ê¸°ë°˜ AI í˜¸ì¶œ ì—¬ë¶€ ê²°ì •"""
        
        # 1. ê¸°ë³¸ íŠ¸ë¦¬ê±° ì²´í¬ (ê¸°ì¡´ ë¡œì§)
        basic_trigger = self.check_volatility_breakout_trigger(price, timestamp, 0)
        
        if not basic_trigger:
            return False, "ê¸°ë³¸ íŠ¸ë¦¬ê±° ë¯¸ë‹¬ì„±"
        
        # 2. RAG ê¸°íšŒ ì ìˆ˜ ê³„ì‚°
        opportunity_score, reason = self.calculate_opportunity_score(tech_indicators, price, current_news)
        
        # 3. ì„ê³„ì  ì²´í¬ (ğŸš¨ ì—¬ê¸° ìˆ˜ì •!)
        if opportunity_score >= 75:  # 70 â†’ 85ë¡œ ìƒí–¥
            return True, f"ê³ í™•ë¥  ì‹œì  (ì ìˆ˜: {opportunity_score}ì , {reason})"
        
        elif opportunity_score >= 65:  # 50 â†’ 75ë¡œ ìƒí–¥
            # ì¤‘ê°„ ì ìˆ˜ëŠ” ì¶”ê°€ ì¡°ê±´ ì²´í¬
            support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
            if support_analysis.get('is_near_support') and support_analysis.get('strength', 0) > 0.7:  # 0.7 â†’ 0.8ë¡œ ìƒí–¥
                return True, f"ì¤‘í™•ë¥ +ê°•ì§€ì§€ (ì ìˆ˜: {opportunity_score}ì )"
        
        return False, f"í™•ë¥  ë¶€ì¡± (ì ìˆ˜: {opportunity_score}ì , {reason})"
    
    def integrated_decision_system(self, ai_result, pattern_advice, news_sentiment, market_trend, confluence_signals):
        """5ê°€ì§€ ìš”ì†Œ í†µí•© ì˜ì‚¬ê²°ì •"""
        
        decision_score = 0
        reasons = []
        
        # 1. AI ì‹ í˜¸ (35%)
        if ai_result['signal'] == 'BUY':
            ai_contribution = ai_result['confidence'] * 0.35
            decision_score += ai_contribution
            reasons.append(f"AIë§¤ìˆ˜ {ai_result['confidence']:.2f}")
        
        # 2. RAG íŒ¨í„´ (30%) - í•µì‹¬!
        if pattern_advice['recommendation'] == 'BUY':
            rag_contribution = pattern_advice['confidence'] * 0.30
            decision_score += rag_contribution
            reasons.append(f"RAGë§¤ìˆ˜ ìŠ¹ë¥ {pattern_advice.get('win_rate', 0):.0%}")
            
            # ê¸°ëŒ€ìˆ˜ìµ ë³´ë„ˆìŠ¤
            if pattern_advice.get('profit_expectation', 0) > 3:
                decision_score += 0.05
        
        # 3. ë‰´ìŠ¤ ê°ì„± (15%)
        if news_sentiment.get('sentiment_score', 0) > 0.3:
            news_contribution = news_sentiment['sentiment_score'] * 0.15
            decision_score += news_contribution
            reasons.append(f"ë‰´ìŠ¤ê¸ì • {news_sentiment['sentiment_score']:.2f}")
        
        # 4. ì‹œì¥ ì¶”ì„¸ (10%)
        if "uptrend" in market_trend.lower():
            decision_score += 0.10
            reasons.append("ìƒìŠ¹ì¶”ì„¸")
        
        # 5. ê¸°ìˆ ì  ì‹ í˜¸ (10%)
        tech_score = confluence_signals.get('total_score', 0) / 100  # 0-1ë¡œ ì •ê·œí™”
        decision_score += tech_score * 0.10
        
        # ìµœì¢… íŒë‹¨
        should_buy = decision_score >= 0.65  # 65% ì´ìƒ
        
        return {
            'should_buy': should_buy,
            'total_score': decision_score,
            'reasons': reasons,
            'details': f"ì¢…í•©ì ìˆ˜ {decision_score:.2f} ({'ë§¤ìˆ˜' if should_buy else 'ëŒ€ê¸°'})"
        }











    def _check_bounce_pattern(self, current_price):
        """
        ì§€ì§€ì„ ì—ì„œ ë°˜ë“± íŒ¨í„´ í™•ì¸
        """
        if len(self.historical_data) < 3:
            return False
        
        # ìµœê·¼ 3ê°œ ê°€ê²© í™•ì¸
        recent_prices = [item['price'] for item in self.historical_data[-3:]]
        recent_prices.append(current_price)
        
        # í•˜ë½ í›„ ìƒìŠ¹ íŒ¨í„´ í™•ì¸ (Vì ë°˜ë“±)
        if len(recent_prices) >= 3:
            if recent_prices[-3] > recent_prices[-2] < recent_prices[-1]:
                print(f"ğŸ”„ Vì ë°˜ë“± íŒ¨í„´ ê°ì§€: {recent_prices[-3]:,.0f} > {recent_prices[-2]:,.0f} < {recent_prices[-1]:,.0f}")
                return True
        
        return False

    def check_strong_buy_signal_enhanced(self, price, tech_indicators, market_trend, 
                                    confidence, news_sentiment, pattern_advice, 
                                    fear_greed_index=50):
        """ê°•í™”ëœ ë§¤ìˆ˜ ì‹ í˜¸ ê²€ì¦ (íŒ¨í„´ + ì‹¬ë¦¬ ì§€ìˆ˜ í†µí•©)"""
        
        buy_score = 0
        reasons = []
        
        print(f"ğŸ” ê°•í™”ëœ ë§¤ìˆ˜ ì‹ í˜¸ ë¶„ì„ - ê°€ê²©: â‚©{price:,.0f}")
        
        # 1. ê¸°ë³¸ ì‹œì¥ ì¶”ì„¸ í™•ì¸
        if "uptrend" in market_trend.lower() or "bullish" in market_trend.lower():
            buy_score += 3
            reasons.append("âœ… ìƒìŠ¹ì¶”ì„¸ í™•ì¸ (+3ì )")
        elif "strong downtrend" in market_trend.lower():
            print("âŒ ê°•í•œ í•˜ë½ì¶”ì„¸ - ë§¤ìˆ˜ ê¸ˆì§€")
            return False, ["ê°•í•œ í•˜ë½ì¶”ì„¸ - ë§¤ìˆ˜ ê¸ˆì§€"]
        elif "downtrend" in market_trend.lower():
            buy_score -= 1
            reasons.append("âš ï¸ í•˜ë½ì¶”ì„¸ ì£¼ì˜ (-1ì )")
        
        # 2. ì§€ì§€ì„  + ë°˜ë“± í™•ì¸
        support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
        
        if support_analysis['is_near_support'] and support_analysis['strength'] >= 0.6:
            if self._check_bounce_pattern(price):
                buy_score += 4
                reasons.append(f"âœ… ê°•í•œ ì§€ì§€ì„  ë°˜ë“± (+4ì , ê°•ë„: {support_analysis['strength']:.2f})")
            else:
                buy_score += 2
                reasons.append(f"âœ… ì§€ì§€ì„  ê·¼ì²˜ (+2ì , ê°•ë„: {support_analysis['strength']:.2f})")
        elif support_analysis['is_near_support']:
            buy_score += 1
            reasons.append(f"ğŸ”¸ ì•½í•œ ì§€ì§€ì„  (+1ì , ê°•ë„: {support_analysis['strength']:.2f})")
        
        # 3. RSI ë¶„ì„ (ë‹¤ì´ë²„ì „ìŠ¤ ê°ì§€ ì¶”ê°€)
        rsi = None
        if 'RSI(14)' in tech_indicators:
            try:
                rsi = float(str(tech_indicators['RSI(14)']).replace(',', ''))
            except:
                pass
        
        if rsi is not None:
            if rsi < 25:
                buy_score += 4
                reasons.append(f"âœ… ê·¹ë„ ê³¼ë§¤ë„ (+4ì , RSI: {rsi:.1f})")
            elif rsi < 35:
                buy_score += 3
                reasons.append(f"âœ… ê³¼ë§¤ë„ (+3ì , RSI: {rsi:.1f})")
            elif rsi > 75:
                buy_score -= 3
                reasons.append(f"âŒ ê·¹ë„ ê³¼ë§¤ìˆ˜ (-3ì , RSI: {rsi:.1f})")
            elif rsi > 65:
                buy_score -= 1
                reasons.append(f"âš ï¸ ê³¼ë§¤ìˆ˜ ì£¼ì˜ (-1ì , RSI: {rsi:.1f})")
            else:
                reasons.append(f"ğŸ”¸ RSI ì¤‘ë¦½ (0ì , RSI: {rsi:.1f})")
        
        # 4. MACD ì‹ í˜¸ í™•ì¸
        macd = tech_indicators.get('MACD', '')
        if 'Bullish crossover' in str(macd):
            buy_score += 4
            reasons.append("âœ… MACD ê³¨ë“ í¬ë¡œìŠ¤ (+4ì )")
        elif 'Bullish' in str(macd):
            buy_score += 2
            reasons.append("âœ… MACD ìƒìŠ¹ (+2ì )")
        elif 'Bearish crossover' in str(macd):
            buy_score -= 4
            reasons.append("âŒ MACD ë°ë“œí¬ë¡œìŠ¤ (-4ì )")
        elif 'Bearish' in str(macd):
            buy_score -= 2
            reasons.append("âš ï¸ MACD í•˜ë½ (-2ì )")
        
        # 5. ë‰´ìŠ¤ ê°ì„± í™•ì¸
        sentiment_score = news_sentiment.get('sentiment_score', 0)
        if sentiment_score > 0.5:
            buy_score += 3
            reasons.append(f"âœ… ë§¤ìš° ê¸ì •ì  ë‰´ìŠ¤ (+3ì , ì ìˆ˜: {sentiment_score:.2f})")
        elif sentiment_score > 0.3:
            buy_score += 2
            reasons.append(f"âœ… ê¸ì •ì  ë‰´ìŠ¤ (+2ì , ì ìˆ˜: {sentiment_score:.2f})")
        elif sentiment_score < -0.5:
            buy_score -= 3
            reasons.append(f"âŒ ë§¤ìš° ë¶€ì •ì  ë‰´ìŠ¤ (-3ì , ì ìˆ˜: {sentiment_score:.2f})")
        elif sentiment_score < -0.3:
            buy_score -= 2
            reasons.append(f"âŒ ë¶€ì •ì  ë‰´ìŠ¤ (-2ì , ì ìˆ˜: {sentiment_score:.2f})")
        
        # 6. AI ì‹ ë¢°ë„ í™•ì¸
        if confidence >= 0.8:
            buy_score += 3
            reasons.append(f"âœ… ë†’ì€ AI ì‹ ë¢°ë„ (+3ì , {confidence:.2f})")
        elif confidence >= 0.6:
            buy_score += 2
            reasons.append(f"âœ… ì¤‘ê°„ AI ì‹ ë¢°ë„ (+2ì , {confidence:.2f})")
        elif confidence < 0.4:
            buy_score -= 2
            reasons.append(f"âš ï¸ ë‚®ì€ AI ì‹ ë¢°ë„ (-2ì , {confidence:.2f})")
        
        # 7. íŒ¨í„´ ê¸°ë°˜ ì¡°ì–¸ ë°˜ì˜ (í•µì‹¬ ì¶”ê°€!)
        if pattern_advice.get('recommendation') == 'BUY':
            pattern_confidence = pattern_advice.get('confidence', 0)
            expected_profit = pattern_advice.get('profit_expectation', 0)
            win_rate = pattern_advice.get('win_rate', 0)
            
            # íŒ¨í„´ ì ìˆ˜ ê³„ì‚°
            pattern_score = (pattern_confidence * 2) + (expected_profit / 3) + (win_rate * 5)
            pattern_score = min(5, pattern_score)  # ìµœëŒ€ 5ì 
            
            buy_score += pattern_score
            reasons.append(f"âœ… ì„±ê³µ íŒ¨í„´ ë§¤ì¹­ (+{pattern_score:.1f}ì )")
            reasons.append(f"   â””â”€ ì‹ ë¢°ë„: {pattern_confidence:.2f}, ê¸°ëŒ€ìˆ˜ìµ: {expected_profit:.1f}%, ìŠ¹ë¥ : {win_rate:.0%}")
        
        # 8. Fear & Greed Index ë°˜ì˜ (ì—­ë°œìƒ íˆ¬ì)
        if fear_greed_index <= 20:  # ê·¹ë‹¨ì  ê³µí¬
            buy_score += 4
            reasons.append(f"âœ… ê·¹ë‹¨ì  ê³µí¬ ìƒíƒœ - ì—­ë°œìƒ ë§¤ìˆ˜ ê¸°íšŒ (+4ì , FGI: {fear_greed_index})")
        elif fear_greed_index <= 35:  # ê³µí¬
            buy_score += 2
            reasons.append(f"âœ… ê³µí¬ ìƒíƒœ - ë§¤ìˆ˜ ê¸°íšŒ (+2ì , FGI: {fear_greed_index})")
        elif fear_greed_index >= 80:  # ê·¹ë‹¨ì  íƒìš•
            buy_score -= 3
            reasons.append(f"âŒ ê·¹ë‹¨ì  íƒìš• - ê³¼ì—´ ìœ„í—˜ (-3ì , FGI: {fear_greed_index})")
        elif fear_greed_index >= 65:  # íƒìš•
            buy_score -= 1
            reasons.append(f"âš ï¸ íƒìš• ìƒíƒœ - ì£¼ì˜ (-1ì , FGI: {fear_greed_index})")
        
        # 9. ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜
        bb = tech_indicators.get('Bollinger Bands', '')
        if 'lower' in str(bb).lower():
            buy_score += 3
            reasons.append("âœ… ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ (+3ì )")
        elif 'upper' in str(bb).lower():
            buy_score -= 2
            reasons.append("âš ï¸ ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ (-2ì )")
        
        # ìµœì¢… íŒë‹¨ (ì„ê³„ê°’ ì¡°ì •: 8ì  â†’ 6ì )
        print(f"ğŸ“Š ê°•í™”ëœ ë§¤ìˆ˜ ì‹ í˜¸ ì ìˆ˜: {buy_score}ì ")
        for reason in reasons:
            print(f"  {reason}")
        
        if buy_score >= 10:
            final_reasons = reasons + [f"ğŸš€ ë§¤ìš° ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸ (ì´ {buy_score}ì )"]
            print(f"ğŸš€ ê²°ë¡ : ë§¤ìš° ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸ - ì´ {buy_score}ì ")
            return True, final_reasons
        elif buy_score >= 3:  # ì„ê³„ê°’ ì™„í™”
            final_reasons = reasons + [f"ğŸ“ˆ ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸ (ì´ {buy_score}ì )"]
            print(f"ğŸ“ˆ ê²°ë¡ : ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸ - ì´ {buy_score}ì ")
            return True, final_reasons
        else:
            final_reasons = reasons + [f"âŒ ë§¤ìˆ˜ ì¡°ê±´ ë¯¸ë‹¬ (ì´ {buy_score}ì )"]
            print(f"âŒ ê²°ë¡ : ë§¤ìˆ˜ ì¡°ê±´ ë¯¸ë‹¬ - ì´ {buy_score}ì  (ìµœì†Œ 6ì  í•„ìš”)")
            return False, final_reasons


    def _process_news_for_storage(self, news_data):
        """RAG ì €ì¥ìš© ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬"""
        processed_news = []
        for news in news_data[:5]:  # ìµœì‹  5ê°œë§Œ ì €ì¥
            processed_news.append({
                'title': news.get('title', '')[:200],  # ì œëª© 200ì ì œí•œ
                'description': news.get('description', '')[:500],  # ë‚´ìš© 500ì ì œí•œ
                'source': news.get('source', ''),
                'publishedAt': news.get('publishedAt', ''),
                'url': news.get('url', '')
            })
        return processed_news

    def _create_news_summary(self, news_data):
        """ë‰´ìŠ¤ ìš”ì•½ ìƒì„±"""
        if not news_data:
            return ""
        
        titles = [news.get('title', '') for news in news_data[:3]]
        return " | ".join(titles)




    def store_enhanced_market_pattern(self, tech_indicators, price, ai_decision, actual_decision, 
                                confidence, market_trend, news_sentiment, pattern_advice, 
                                timestamp, rejection_reason=None, news_data=None):
        """ê°€ìƒ ê±°ë˜ ê²°ê³¼ê¹Œì§€ ì¶”ì í•˜ëŠ” ê°•í™”ëœ íŒ¨í„´ ì €ì¥"""
        
        pattern_id = f"{timestamp.strftime('%Y%m%d%H%M%S')}_{hash(str(tech_indicators))}"
        
        # ê¸°ë³¸ íŒ¨í„´ ì •ë³´
        base_pattern = {
            'pattern_id': pattern_id,
            'date': timestamp.strftime('%Y-%m-%d'),
            'timestamp': timestamp,
            'indicators': tech_indicators,
            'price': price,
            'ai_decision': ai_decision,
            'actual_decision': actual_decision,
            'confidence': confidence,
            'market_trend': market_trend,
            'news_sentiment': news_sentiment,
            'pattern_advice': pattern_advice,
            'support_analysis': self._check_near_support_level_enhanced("KRW-BTC", price),
            'rejection_reason': rejection_reason,
            # â†“ ë‰´ìŠ¤ ì •ë³´ ì¶”ê°€
            'news_data': self._process_news_for_storage(news_data) if news_data else [],
            'news_summary': self._create_news_summary(news_data) if news_data else "",
            'news_count': len(news_data) if news_data else 0,
            'news_timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # ì‹¤ì œ ê±°ë˜ ê²°ê³¼ ì¶”ì 
        if actual_decision == 'BUY':
            base_pattern['trade_result'] = {
                'type': 'actual_trade',
                'completed': False,
                'entry_price': price,
                'exit_price': None,
                'profit_pct': None,
                'success': None,
                'exit_reason': None
            }
        
        # ê°€ìƒ ê±°ë˜ ê²°ê³¼ ì¶”ì  ì„¤ì •
        elif ai_decision == 'BUY' and actual_decision != 'BUY':
            base_pattern['hypothetical_trade'] = {
                'type': 'hypothetical_trade',
                'would_have_bought': True,
                'hypothetical_entry_price': price,
                'tracking_start_date': timestamp.strftime('%Y-%m-%d'),
                'tracking_days': 0,
                'max_tracking_days': 7,  # 7ì¼ê°„ ì¶”ì 
                'daily_prices': [price],
                'completed': False
            }
        
        # HOLD ê²°ì •ì˜ ê¸°íšŒë¹„ìš© ì¶”ì 
        elif ai_decision == 'HOLD':
            base_pattern['opportunity_cost_tracking'] = {
                'type': 'opportunity_cost',
                'hold_decision_price': price,
                'tracking_start_date': timestamp.strftime('%Y-%m-%d'),
                'tracking_days': 0,
                'max_tracking_days': 5,  # 5ì¼ê°„ ì¶”ì 
                'daily_prices': [price],
                'completed': False
            }
        
        # íŒ¨í„´ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
        base_pattern['pattern_metrics'] = {
            'success_count': 0,
            'failure_count': 0,
            'total_profit': 0,
            'avg_profit': 0,
            'success_rate': 0,
            'hypothetical_success_count': 0,
            'hypothetical_failure_count': 0,
            'hypothetical_total_profit': 0,
            'opportunity_cost_total': 0,
            'last_update': timestamp.strftime('%Y-%m-%d'),
            'usage_count': 0
        }
        
        # document_storeì— ì¶”ê°€
        if not hasattr(self, 'document_store'):
            self.document_store = []
        
        self.document_store.append(base_pattern)
        
        print(f"ğŸ’¾ ê°•í™”ëœ íŒ¨í„´ ì €ì¥: {pattern_id}")
        print(f"  â”œâ”€ AI ê²°ì •: {ai_decision}")
        print(f"  â”œâ”€ ì‹¤ì œ ê²°ì •: {actual_decision}")
        if rejection_reason:
            print(f"  â”œâ”€ ê±°ë¶€ ì´ìœ : {rejection_reason}")
        
        return pattern_id

    def track_hypothetical_trades(self, current_price, current_date):
        """ëª¨ë“  ê°€ìƒ ê±°ë˜ ë° ê¸°íšŒë¹„ìš© ì¶”ì """
        
        if not hasattr(self, 'document_store'):
            return
        
        updated_patterns = 0
        
        for pattern in self.document_store:
            # ê°€ìƒ ê±°ë˜ ì¶”ì 
            if 'hypothetical_trade' in pattern and not pattern['hypothetical_trade']['completed']:
                hypo_trade = pattern['hypothetical_trade']
                
                # ì¶”ì  ê¸°ê°„ ì²´í¬
                hypo_trade['tracking_days'] += 1
                hypo_trade['daily_prices'].append(current_price)
                
                # 7ì¼ ì¶”ì  ì™„ë£Œ ë˜ëŠ” í° ë³€í™” ë°œìƒì‹œ ê²°ê³¼ ê³„ì‚°
                if (hypo_trade['tracking_days'] >= hypo_trade['max_tracking_days'] or 
                    abs((current_price / hypo_trade['hypothetical_entry_price']) - 1) > 0.1):  # 10% ë³€í™”
                    
                    entry_price = hypo_trade['hypothetical_entry_price']
                    profit_pct = ((current_price / entry_price) - 1) * 100
                    
                    # ê°€ìƒ ê±°ë˜ ê²°ê³¼ ê¸°ë¡
                    hypo_trade.update({
                        'completed': True,
                        'hypothetical_exit_price': current_price,
                        'hypothetical_profit_pct': profit_pct,
                        'hypothetical_success': profit_pct > 0.5,  # ìˆ˜ìˆ˜ë£Œ ê³ ë ¤ 0.5% ì´ìƒ
                        'completion_date': current_date,
                        'lesson_learned': self._generate_lesson(pattern['ai_decision'], 
                                                            pattern['actual_decision'], 
                                                            profit_pct)
                    })
                    
                    # íŒ¨í„´ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    if profit_pct > 0.5:
                        pattern['pattern_metrics']['hypothetical_success_count'] += 1
                    else:
                        pattern['pattern_metrics']['hypothetical_failure_count'] += 1
                    
                    pattern['pattern_metrics']['hypothetical_total_profit'] += profit_pct
                    
                    updated_patterns += 1
                    
                    print(f"ğŸ“Š ê°€ìƒ ê±°ë˜ ì™„ë£Œ: {pattern['pattern_id'][:10]}...")
                    print(f"  â””â”€ ë†“ì¹œ ê¸°íšŒ: {profit_pct:+.2f}% ({'ìˆ˜ìµ' if profit_pct > 0.5 else 'ì†ì‹¤'})")
            
            # ê¸°íšŒë¹„ìš© ì¶”ì 
            elif 'opportunity_cost_tracking' in pattern and not pattern['opportunity_cost_tracking']['completed']:
                opp_track = pattern['opportunity_cost_tracking']
                
                opp_track['tracking_days'] += 1
                opp_track['daily_prices'].append(current_price)
                
                # 5ì¼ ì¶”ì  ì™„ë£Œ
                if opp_track['tracking_days'] >= opp_track['max_tracking_days']:
                    hold_price = opp_track['hold_decision_price']
                    opportunity_cost = ((current_price / hold_price) - 1) * 100
                    
                    opp_track.update({
                        'completed': True,
                        'final_price': current_price,
                        'opportunity_cost_pct': opportunity_cost,
                        'was_good_hold': opportunity_cost < 0,  # í•˜ë½í–ˆìœ¼ë©´ ì¢‹ì€ HOLD
                        'completion_date': current_date
                    })
                    
                    pattern['pattern_metrics']['opportunity_cost_total'] += opportunity_cost
                    updated_patterns += 1
                    
                    if abs(opportunity_cost) > 2.0:  # 2% ì´ìƒ ë³€í™”ì‹œë§Œ ë¡œê¹…
                        print(f"ğŸ“Š ê¸°íšŒë¹„ìš© ì¶”ì  ì™„ë£Œ: {pattern['pattern_id'][:10]}...")
                        print(f"  â””â”€ HOLD ê²°ê³¼: {opportunity_cost:+.2f}% ({'ì•„ì‰¬ìš´ HOLD' if opportunity_cost > 3 else 'ì˜¬ë°”ë¥¸ HOLD'})")
        
        if updated_patterns > 0:
            print(f"ğŸ’¾ {updated_patterns}ê°œ íŒ¨í„´ì˜ ê°€ìƒ ê²°ê³¼ ì—…ë°ì´íŠ¸ë¨")

    def _generate_lesson(self, ai_decision, actual_decision, result_pct):
        """ê²°ê³¼ ê¸°ë°˜ êµí›ˆ ìƒì„±"""
        
        if ai_decision == 'BUY' and actual_decision != 'BUY':
            if result_pct > 3.0:
                return f"ë§¤ìˆ˜ ê±°ë¶€ë¡œ {result_pct:.1f}% ê¸°íšŒ ìƒì‹¤ - ë‹¤ìŒì—” ë” ì ê·¹ì  ê³ ë ¤ í•„ìš”"
            elif result_pct < -2.0:
                return f"ë§¤ìˆ˜ ê±°ë¶€ë¡œ {abs(result_pct):.1f}% ì†ì‹¤ íšŒí”¼ ì„±ê³µ - ì˜¬ë°”ë¥¸ íŒë‹¨"
            else:
                return f"ë§¤ìˆ˜ ê±°ë¶€ ê²°ê³¼ {result_pct:.1f}% - ì¤‘ë¦½ì  ê²°ê³¼"
        
        return "ê²°ê³¼ ë¶„ì„ ì¤‘"
    




    def calculate_dynamic_stop_loss(self, entry_price, market_volatility, support_strength):
        """
        ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ë™ì  ì†ì ˆë§¤ ê³„ì‚°
        """
        base_stop_loss = -3.0
        
        # ë³€ë™ì„±ì— ë”°ë¥¸ ì¡°ì •
        if market_volatility > 0.08:  # ê³ ë³€ë™ì„±
            stop_loss = -5.0
            volatility_reason = "ê³ ë³€ë™ì„±"
        elif market_volatility > 0.05:  # ì¤‘ë³€ë™ì„±  
            stop_loss = -4.0
            volatility_reason = "ì¤‘ë³€ë™ì„±"
        elif market_volatility < 0.03:  # ì €ë³€ë™ì„±
            stop_loss = -2.5
            volatility_reason = "ì €ë³€ë™ì„±"
        else:
            stop_loss = base_stop_loss
            volatility_reason = "ë³´í†µë³€ë™ì„±"
        
        # ì§€ì§€ì„  ê°•ë„ì— ë”°ë¥¸ ì¡°ì •
        if support_strength >= 0.8:  # ë§¤ìš° ê°•í•œ ì§€ì§€ì„ 
            stop_loss *= 0.7  # 30% ì™„í™”
            support_reason = "ë§¤ìš° ê°•í•œ ì§€ì§€ì„  (30% ì™„í™”)"
        elif support_strength >= 0.6:  # ê°•í•œ ì§€ì§€ì„ 
            stop_loss *= 0.85  # 15% ì™„í™”
            support_reason = "ê°•í•œ ì§€ì§€ì„  (15% ì™„í™”)"
        else:
            support_reason = "ì¼ë°˜ ì§€ì§€ì„ "
        
        print(f"ğŸ›¡ï¸ ë™ì  ì†ì ˆë§¤ ê³„ì‚°: {stop_loss:.1f}% ({volatility_reason}, {support_reason})")
        return stop_loss

    def calculate_dynamic_profit_target(self, market_trend, confidence, pattern_quality):
        """
        ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ë™ì  ìµì ˆ ëª©í‘œ
        """
        base_profit = 5.0
        
        # ì‹œì¥ ì¶”ì„¸ì— ë”°ë¥¸ ì¡°ì •
        if "strong uptrend" in market_trend.lower():
            profit_target = 8.0
            trend_reason = "ê°•í•œ ìƒìŠ¹ì¥"
        elif "uptrend" in market_trend.lower():
            profit_target = 6.0
            trend_reason = "ìƒìŠ¹ì¥"
        elif "downtrend" in market_trend.lower():
            profit_target = 3.0
            trend_reason = "í•˜ë½ì¥ì—ì„œ ë¹ ë¥¸ ì‹¤í˜„"
        else:
            profit_target = base_profit
            trend_reason = "ì¤‘ë¦½ì¥"
        
        # AI ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ì •
        confidence_multiplier = 1.0
        if confidence >= 0.8:
            confidence_multiplier = 1.2
            confidence_reason = "ë†’ì€ ì‹ ë¢°ë„ (20% ì¦ê°€)"
        elif confidence < 0.5:
            confidence_multiplier = 0.8
            confidence_reason = "ë‚®ì€ ì‹ ë¢°ë„ (20% ê°ì†Œ)"
        else:
            confidence_reason = "ë³´í†µ ì‹ ë¢°ë„"
        
        profit_target *= confidence_multiplier
        
        # íŒ¨í„´ í’ˆì§ˆì— ë”°ë¥¸ ì¡°ì •
        if pattern_quality >= 70:
            profit_target *= 1.1
            pattern_reason = "ê³ í’ˆì§ˆ íŒ¨í„´ (10% ì¦ê°€)"
        else:
            pattern_reason = "ì¼ë°˜ íŒ¨í„´"
        
        print(f"ğŸ¯ ë™ì  ìµì ˆ ëª©í‘œ ê³„ì‚°: {profit_target:.1f}% ({trend_reason}, {confidence_reason}, {pattern_reason})")
        return profit_target

    
    
    def improved_exit_strategy_enhanced(self, current_price, entry_price, entry_date, current_date, 
                                    market_trend, profit_target, stop_loss, confidence,
                                    position_adjustments=None):
        """ê°•í™”ëœ ì²­ì‚° ì „ëµ - ë³¸ì „ ë³´ì¥ + ë¶€ë¶„ ìµì ˆ"""
        
        profit_pct = ((current_price / entry_price) - 1) * 100
        
        # í¬ì§€ì…˜ ì¡°ì • ì •ë³´ ë°˜ì˜
        if position_adjustments:
            profit_target += position_adjustments.get('profit_target_adjustment', 0)
            stop_loss += position_adjustments.get('stop_loss_adjustment', 0)
        
        # ğŸš¨ ìˆ˜ì • 1: ê¸°ë³¸ ì†ì ˆë§¤ í™•ì¸ (ìµœìš°ì„ )
        if profit_pct <= stop_loss:
            return "SELL_STOPLOSS", f"ì†ì ˆë§¤ ì‹¤í–‰ ({profit_pct:.2f}% <= {stop_loss:.1f}%)"
        
        # ğŸš¨ ìˆ˜ì • 2: ê°„ë‹¨í•œ ìµì ˆ ìš°ì„  ì ìš©
        if profit_pct >= profit_target:
            return "SELL_PROFIT", f"ëª©í‘œ ìˆ˜ìµ ë‹¬ì„± ({profit_pct:.2f}% >= {profit_target:.1f}%)"
        
        # ğŸš¨ ìˆ˜ì • 3: í”Œë˜ê·¸ ì²´í¬ ë³€ê²½
        breakeven_active = getattr(self, 'breakeven_protection_active', False)
        partial_taken = getattr(self, 'partial_profit_taken', False)
        
        # 2. ë³¸ì „ ë³´ì¥ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ (2.5% ìˆ˜ìµ ì‹œ í™œì„±í™”)
        if profit_pct >= 2.5 and not breakeven_active:
            breakeven_price = entry_price * 1.001  # ìˆ˜ìˆ˜ë£Œ 0.1% ê³ ë ¤
            self.trailing_stop_price = max(
                getattr(self, 'trailing_stop_price', 0), 
                breakeven_price
            )
            self.breakeven_protection_active = True
            print(f"ğŸ’ ë³¸ì „ ë³´ì¥ í™œì„±í™”: â‚©{breakeven_price:,.0f}")
        
        # 3. ë¶€ë¶„ ìµì ˆ ì‹œìŠ¤í…œ (ëª©í‘œ ìˆ˜ìµì˜ 70% ë‹¬ì„±ì‹œ)
        partial_profit_threshold = profit_target * 0.7
        if profit_pct >= partial_profit_threshold and not partial_taken:
            self.partial_profit_taken = True
            return "SELL_PARTIAL_PROFIT", f"ë¶€ë¶„ ìµì ˆ (50%) - {profit_pct:.2f}% >= {partial_profit_threshold:.1f}%"
        
        # ğŸš¨ ìˆ˜ì • 4: ê°„ë‹¨í•œ ì‹œê°„ ê¸°ë°˜ ì²­ì‚° ì¶”ê°€
        try:
            # ê°„ë‹¨í•œ ë‚ ì§œ ê³„ì‚°ìœ¼ë¡œ ëŒ€ì²´
            entry_dt = pd.to_datetime(entry_date)
            current_dt = pd.to_datetime(current_date)
            holding_days = (current_dt - entry_dt).days
            
            # 7ì¼ ì´ìƒ ë³´ìœ  ì‹œ ë¬´ì¡°ê±´ ì²­ì‚°
            if holding_days >= 7:
                return "SELL_TIMEOUT", f"ì¥ê¸° ë³´ìœ ë¡œ ì²­ì‚° ({holding_days}ì¼, {profit_pct:.2f}%)"
                
        except Exception as e:
            print(f"ë‚ ì§œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            # ë‚ ì§œ ê³„ì‚° ì‹¤íŒ¨ì‹œì—ë„ ë‹¤ë¥¸ ì¡°ê±´ë“¤ ì²´í¬
        
        # 7. íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ í™•ì¸
        trailing_price = getattr(self, 'trailing_stop_price', 0)
        if trailing_price > 0 and current_price <= trailing_price:
            return "SELL_TRAILING", f"íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì‹¤í–‰ ({profit_pct:.2f}%)"
        
        return "HOLD", f"ë³´ìœ  ê³„ì† ({profit_pct:.2f}%)"


    def simple_exit_strategy(self, current_price, entry_price, entry_date, current_date, 
                            market_trend, profit_target, stop_loss, confidence,
                            position_adjustments=None):
        """ì´ˆê°„ë‹¨ ë§¤ë„ ë¡œì§ - í…ŒìŠ¤íŠ¸ìš©"""
        
        profit_pct = ((current_price / entry_price) - 1) * 100
        
        # ğŸš¨ ë¬´ì¡°ê±´ ì‘ë™í•˜ëŠ” ë§¤ë„ ì¡°ê±´ë“¤
        if profit_pct <= -2.0:  # ì†ì ˆ -2%
            return "SELL_STOPLOSS", f"ì†ì ˆë§¤ ({profit_pct:.2f}%)"
        
        if profit_pct >= 5.0:   # ìµì ˆ +5%
            return "SELL_PROFIT", f"ìµì ˆ ({profit_pct:.2f}%)"
        
        # ê°„ë‹¨í•œ ì‹œê°„ ì²­ì‚° (3ì¼)
        try:
            entry_dt = pd.to_datetime(entry_date)
            current_dt = pd.to_datetime(current_date)
            if (current_dt - entry_dt).days >= 3:
                return "SELL_TIMEOUT", f"3ì¼ ê²½ê³¼ ì²­ì‚° ({profit_pct:.2f}%)"
        except:
            pass
        
        return "HOLD", f"ë³´ìœ  ({profit_pct:.2f}%)"






    def calculate_position_size(self, price, stop_loss_pct, balance=None, risk_level=1.0, confidence=0.5, market_trend="neutral", pattern_quality=0):
        """
        ê°œì„ ëœ í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° - ê¸°ë³¸ íˆ¬ì ë¹„ìœ¨ + ì‹œì¥ ìƒí™© ì¡°ì •
        
        Args:
            price: í˜„ì¬ ê°€ê²©
            stop_loss_pct: ì†ì ˆë§¤ ë¹„ìœ¨ (ì‚¬ìš© ì•ˆí•¨)
            balance: ê³„ì¢Œ ì”ê³ 
            risk_level: ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ (ì‚¬ìš© ì•ˆí•¨)
            confidence: AI ì‹ ë¢°ë„ (0.0~1.0)
            market_trend: ì‹œì¥ ì¶”ì„¸
            pattern_quality: íŒ¨í„´ í’ˆì§ˆ ì ìˆ˜
            
        Returns:
            tuple: (ì½”ì¸ ìˆ˜ëŸ‰, íˆ¬ì ê¸ˆì•¡, íˆ¬ì ë¹„ìœ¨)
        """
        # ê¸°ë³¸ ì”ê³  ì„¤ì •
        if balance is None:
            balance = getattr(self, 'current_balance', getattr(self, 'initial_balance', 10000000))
        
        # ğŸ¯ ê¸°ë³¸ íˆ¬ì ë¹„ìœ¨: 50%
        base_investment_ratio = 0.05
        
        # ğŸ“Š ì‹œì¥ ìƒí™©ë³„ ë¹„ìœ¨ ì¡°ì •
        market_adjustment = 0.0
        
        # 1. ì‹œì¥ ì¶”ì„¸ì— ë”°ë¥¸ ì¡°ì •
        if "strong uptrend" in market_trend.lower() or "bullish" in market_trend.lower():
            market_adjustment += 0.10  # +10%
        elif "uptrend" in market_trend.lower():
            market_adjustment += 0.05  # +5%
        elif "strong downtrend" in market_trend.lower() or "bearish" in market_trend.lower():
            market_adjustment -= 0.10  # -10%
        elif "downtrend" in market_trend.lower():
            market_adjustment -= 0.05  # -5%
        
        # 2. AI ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ì •
        if confidence >= 0.8:
            market_adjustment += 0.10  # +10% (ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„)
        elif confidence >= 0.7:
            market_adjustment += 0.05  # +5% (ë†’ì€ ì‹ ë¢°ë„)
        elif confidence < 0.4:
            market_adjustment -= 0.10  # -10% (ë‚®ì€ ì‹ ë¢°ë„)
        elif confidence < 0.5:
            market_adjustment -= 0.05  # -5% (ì¤‘ê°„ ì‹ ë¢°ë„)
        
        # 3. íŒ¨í„´ í’ˆì§ˆì— ë”°ë¥¸ ì¡°ì •
        if pattern_quality >= 70:
            market_adjustment += 0.05  # +5% (ê³ í’ˆì§ˆ íŒ¨í„´)
        elif pattern_quality >= 50:
            market_adjustment += 0.02  # +2% (ì¤‘í’ˆì§ˆ íŒ¨í„´)
        elif pattern_quality < 30:
            market_adjustment -= 0.05  # -5% (ì €í’ˆì§ˆ íŒ¨í„´)
        
        # 4. ì—°ì† ì„±ê³µ/ì‹¤íŒ¨ì— ë”°ë¥¸ ì¡°ì •
        consecutive_wins = getattr(self, 'consecutive_wins', 0)
        consecutive_losses = getattr(self, 'consecutive_losses', 0)
        
        if consecutive_wins >= 3:
            market_adjustment += 0.05  # +5% (ì—°ì† ì„±ê³µ)
        elif consecutive_losses >= 3:
            market_adjustment -= 0.10  # -10% (ì—°ì† ì‹¤íŒ¨)
        elif consecutive_losses >= 2:
            market_adjustment -= 0.05  # -5% (ì—°ì† ì‹¤íŒ¨)
        
        # ìµœì¢… íˆ¬ì ë¹„ìœ¨ ê³„ì‚° (40%~60% ë²”ìœ„ ì œí•œ)
        final_investment_ratio = base_investment_ratio + market_adjustment
        final_investment_ratio = max(0.04, min(0.06, final_investment_ratio))
        
        # ğŸ’° ì‹¤ì œ íˆ¬ì ê¸ˆì•¡ ê³„ì‚°
        investment_amount = balance * final_investment_ratio
        
        # ìˆ˜ìˆ˜ë£Œ ê³ ë ¤ (0.05%)
        fee_rate = 0.0005
        net_investment = investment_amount / (1 + fee_rate)
        
        # ì½”ì¸ ìˆ˜ëŸ‰ ê³„ì‚°
        coin_amount = net_investment / price
        
        # ìµœì†Œ íˆ¬ì ê¸ˆì•¡ ì²´í¬ (1000ì› ì´ìƒ)
        if investment_amount < 1000:
            print(f"âš ï¸ ì”ê³  ë¶€ì¡±: â‚©{balance:,.0f} â†’ íˆ¬ì ë¶ˆê°€")
            return 0, 0, 0
        
        # ê²°ê³¼ ë¡œê¹…
        print(f"ğŸ’° í¬ì§€ì…˜ í¬ê¸° ê³„ì‚°:")
        print(f"  â”œâ”€ ê¸°ë³¸ íˆ¬ì ë¹„ìœ¨: {base_investment_ratio*100:.0f}%")
        print(f"  â”œâ”€ ì‹œì¥ ì¡°ì •: {market_adjustment*100:+.0f}%")
        print(f"  â”œâ”€ ìµœì¢… íˆ¬ì ë¹„ìœ¨: {final_investment_ratio*100:.1f}%")
        print(f"  â”œâ”€ íˆ¬ì ê¸ˆì•¡: â‚©{investment_amount:,.0f}")
        print(f"  â”œâ”€ ì½”ì¸ ìˆ˜ëŸ‰: {coin_amount:.8f} BTC")
        print(f"  â””â”€ ë‚¨ì€ ì”ê³ : â‚©{balance - investment_amount:,.0f}")
        
        # ì¡°ì • ì´ìœ  ë¡œê¹…
        reasons = []
        if abs(market_adjustment) > 0.01:
            if market_adjustment > 0:
                reasons.append(f"ìƒìŠ¹ ì¡°ì • +{market_adjustment*100:.1f}%")
            else:
                reasons.append(f"í•˜ë½ ì¡°ì • {market_adjustment*100:.1f}%")
        
        if reasons:
            print(f"  ğŸ“Š ì¡°ì • ì´ìœ : {', '.join(reasons)}")
        
        return coin_amount, investment_amount, final_investment_ratio


    def check_risk_limits(self, current_date, backtest_results):
        """
        íŒ¨í„´ í•™ìŠµìš© ë¦¬ìŠ¤í¬ ì²´í¬ - ì¿¨ë‹¤ìš´ ì—†ìŒ
        
        Args:
            current_date: í˜„ì¬ ë‚ ì§œ
            backtest_results: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ëª©ë¡
            
        Returns:
            bool: í•­ìƒ True (íŒ¨í„´ í•™ìŠµì„ ìœ„í•´ ê±°ë˜ ê³„ì†)
        """
        # íŒ¨í„´ í•™ìŠµ ëª¨ë“œ: ì†ì‹¤ ìƒíƒœë§Œ ëª¨ë‹ˆí„°ë§í•˜ê³  ê±°ë˜ëŠ” ê³„ì†
        daily_loss_limit = getattr(self, 'daily_loss_limit', -10.0)  # ëª¨ë‹ˆí„°ë§ìš©
        weekly_loss_limit = getattr(self, 'weekly_loss_limit', -20.0)  # ëª¨ë‹ˆí„°ë§ìš©
        monthly_loss_limit = getattr(self, 'monthly_loss_limit', -30.0)  # ëª¨ë‹ˆí„°ë§ìš©
        
        # í˜„ì¬ ë‚ ì§œ í™•ì¸
        if isinstance(current_date, str):
            current_date = pd.to_datetime(current_date)
        
        # ì¼ì¼ ì†ì‹¤ ê³„ì‚°
        daily_pnl = 0.0
        for result in reversed(backtest_results):
            result_date = result.get('datetime', result.get('date', None))
            if isinstance(result_date, str):
                result_date = pd.to_datetime(result_date)
            
            if result_date and result_date.date() == current_date.date():
                profit_pct = result.get('profit_pct', 0)
                if profit_pct != 0 and result.get('actual_decision') in ['SELL', 'SELL_PROFIT', 'SELL_STOPLOSS', 'SELL_TRAILING']:
                    daily_pnl += profit_pct
        
        # ì£¼ê°„ ì†ì‹¤ ê³„ì‚°
        week_start = current_date - datetime.timedelta(days=7)
        weekly_pnl = 0.0
        for result in reversed(backtest_results):
            result_date = result.get('datetime', result.get('date', None))
            if isinstance(result_date, str):
                result_date = pd.to_datetime(result_date)
            
            if result_date and week_start.date() <= result_date.date() <= current_date.date():
                profit_pct = result.get('profit_pct', 0)
                if profit_pct != 0 and result.get('actual_decision') in ['SELL', 'SELL_PROFIT', 'SELL_STOPLOSS', 'SELL_TRAILING']:
                    weekly_pnl += profit_pct
        
        # ì›”ê°„ ì†ì‹¤ ê³„ì‚°
        month_start = current_date - datetime.timedelta(days=30)
        monthly_pnl = 0.0
        for result in reversed(backtest_results):
            result_date = result.get('datetime', result.get('date', None))
            if isinstance(result_date, str):
                result_date = pd.to_datetime(result_date)
            
            if result_date and month_start.date() <= result_date.date() <= current_date.date():
                profit_pct = result.get('profit_pct', 0)
                if profit_pct != 0 and result.get('actual_decision') in ['SELL', 'SELL_PROFIT', 'SELL_STOPLOSS', 'SELL_TRAILING']:
                    monthly_pnl += profit_pct
        
        # íŒ¨í„´ í•™ìŠµ ëª¨ë“œ: ì†ì‹¤ ìƒíƒœë§Œ ë¡œê¹…, ê±°ë˜ëŠ” ê³„ì†
        if daily_pnl <= daily_loss_limit:
            print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ: ì¼ì¼ ëŒ€ì†ì‹¤ {daily_pnl:.2f}% ë°œìƒ - ê³„ì† í•™ìŠµ ì¤‘")
        
        if weekly_pnl <= weekly_loss_limit:
            print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ: ì£¼ê°„ ëŒ€ì†ì‹¤ {weekly_pnl:.2f}% ë°œìƒ - ê³„ì† í•™ìŠµ ì¤‘")
        
        if monthly_pnl <= monthly_loss_limit:
            print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ: ì›”ê°„ ëŒ€ì†ì‹¤ {monthly_pnl:.2f}% ë°œìƒ - ê³„ì† í•™ìŠµ ì¤‘")
        
        # í˜„ì¬ ì†ì‹¤ ìƒíƒœ ë¡œê¹…
        if abs(daily_pnl) > 1.0 or abs(weekly_pnl) > 2.0:
            print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ ì†ìµ ìƒíƒœ - ì¼ì¼: {daily_pnl:.2f}%, ì£¼ê°„: {weekly_pnl:.2f}%, ì›”ê°„: {monthly_pnl:.2f}%")
        
        # íŒ¨í„´ í•™ìŠµì„ ìœ„í•´ í•­ìƒ ê±°ë˜ í—ˆìš©
        return True


    def manage_adaptive_risk(self, profit_pct, consecutive_wins=0, consecutive_losses=0):
        """
        ì—°ì† ì„±ê³µ/ì‹¤íŒ¨ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ë™ì  ì¡°ì •
        
        Args:
            profit_pct: í˜„ì¬ ê±°ë˜ì˜ ì†ìµë¥ 
            consecutive_wins: ì—°ì† ì„±ê³µ íšŸìˆ˜
            consecutive_losses: ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜
            
        Returns:
            float: ì¡°ì •ëœ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ (0.5~2.0)
        """
        # ê¸°ë³¸ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€
        base_risk_level = 1.0
        
        # ì—°ì† ìŠ¹/íŒ¨ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ì¡°ì •
        if not hasattr(self, 'consecutive_wins'):
            self.consecutive_wins = 0
        
        if not hasattr(self, 'consecutive_losses'):
            self.consecutive_losses = 0
        
        # í˜„ì¬ ê±°ë˜ ê²°ê³¼ ë°˜ì˜
        if profit_pct > 0:
            self.consecutive_wins += 1
            self.consecutive_losses = 0
        elif profit_pct < 0:
            self.consecutive_losses += 1
            self.consecutive_wins = 0
        
        # ì—°ì† ì„±ê³µ ì‹œ ë¦¬ìŠ¤í¬ ì ì§„ì  ì¦ê°€ (ìµœëŒ€ 2.0ë°°)
        if self.consecutive_wins >= 3:
            risk_multiplier = min(2.0, 1.0 + (self.consecutive_wins - 2) * 0.1)
        # ì—°ì† ì‹¤íŒ¨ ì‹œ ë¦¬ìŠ¤í¬ ì ì§„ì  ê°ì†Œ (ìµœì†Œ 0.5ë°°)
        elif self.consecutive_losses >= 2:
            risk_multiplier = max(0.5, 1.0 - (self.consecutive_losses - 1) * 0.1)
        else:
            risk_multiplier = 1.0
        
        # ìµœì¢… ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ê³„ì‚°
        adjusted_risk = base_risk_level * risk_multiplier
        
        # ì¶”ê°€ ì¡°ì • ë¡œì§ (ì˜ˆ: ë³€ë™ì„±ì— ë”°ë¥¸ ë¯¸ì„¸ ì¡°ì • ë“±)
        market_volatility = getattr(self, 'market_volatility', 0.05)  # ê¸°ë³¸ê°’ 5%
        
        # ë†’ì€ ë³€ë™ì„±ì—ì„œëŠ” ë¦¬ìŠ¤í¬ ì¶•ì†Œ
        if market_volatility > 0.08:  # 8% ì´ìƒ ë³€ë™ì„±
            volatility_factor = 0.9
        # ë‚®ì€ ë³€ë™ì„±ì—ì„œëŠ” ë¦¬ìŠ¤í¬ ì†Œí­ ì¦ê°€
        elif market_volatility < 0.03:  # 3% ë¯¸ë§Œ ë³€ë™ì„±
            volatility_factor = 1.1
        else:
            volatility_factor = 1.0
        
        final_risk = adjusted_risk * volatility_factor
        
        # ìµœì¢… ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ì œí•œ (0.5~2.0 ë²”ìœ„ ìœ ì§€)
        final_risk = max(0.5, min(2.0, final_risk))
        
        print(f"ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ì¡°ì •: {final_risk:.2f}x (ì—°ì† ì„±ê³µ: {self.consecutive_wins}, ì—°ì† ì‹¤íŒ¨: {self.consecutive_losses})")
        
        return final_risk
    
    def calculate_pattern_quality_score(self, pattern):
        """
        ê°œì„ ëœ íŒ¨í„´ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        
        Args:
            pattern: íŒ¨í„´ ê°ì²´
            
        Returns:
            float: 0-100 ì‚¬ì´ì˜ í’ˆì§ˆ ì ìˆ˜
        """
        if not pattern:
            return 0
        
        # 1. ì„±ê³µë¥  ì ìˆ˜ (40ì  ë§Œì ìœ¼ë¡œ ì¶•ì†Œ)
        success_rate_score = 0
        
        if 'pattern_metrics' in pattern:
            metrics = pattern['pattern_metrics']
            success_count = metrics.get('success_count', 0)
            failure_count = metrics.get('failure_count', 0)
            total_count = success_count + failure_count
            
            if total_count > 0:
                success_rate = success_count / total_count
                # ì„±ê³µë¥  ì ìˆ˜ (0% -> 0ì , 50% -> 20ì , 100% -> 40ì )
                success_rate_score = success_rate * 40
                
                # ìµœì†Œ ê±°ë˜ íšŸìˆ˜ í˜ë„í‹° ì™„í™”
                if total_count < 3:  # 5 -> 3ìœ¼ë¡œ ì™„í™”
                    min_trades_penalty = (3 - total_count) * 2  # ê±°ë˜ë‹¹ 2ì  ê°ì†Œë¡œ ì™„í™”
                    success_rate_score = max(0, success_rate_score - min_trades_penalty)
        
        # 2. ìƒ˜í”Œ í¬ê¸° ì ìˆ˜ (20ì  ë§Œì )
        sample_size_score = 0
        
        if 'pattern_metrics' in pattern:
            metrics = pattern['pattern_metrics']
            success_count = metrics.get('success_count', 0)
            failure_count = metrics.get('failure_count', 0)
            total_count = success_count + failure_count
            
            # ìƒ˜í”Œ í¬ê¸° ê¸°ì¤€ ì™„í™”
            if total_count >= 8:  # 10 -> 8ë¡œ ì™„í™”
                sample_size_score = 20
            elif total_count >= 5:
                sample_size_score = 16  # 15 -> 16ìœ¼ë¡œ ì¦ê°€
            elif total_count >= 3:
                sample_size_score = 12  # 10 -> 12ë¡œ ì¦ê°€
            elif total_count >= 2:  # 1 -> 2ë¡œ ë³€ê²½
                sample_size_score = 8   # 5 -> 8ë¡œ ì¦ê°€
            elif total_count >= 1:
                sample_size_score = 4   # ìƒˆë¡œ ì¶”ê°€
        
        # 3. ì‹œì¥ í™˜ê²½ ìœ ì‚¬ë„ ì ìˆ˜ (25ì  ë§Œì ìœ¼ë¡œ ì¦ê°€)
        market_similarity_score = 0
        
        pattern_trend = pattern.get('market_trend', '')
        current_trend = ''
        if hasattr(self, 'backtest_results') and self.backtest_results:
            recent_results = self.backtest_results[-5:]  # 10 -> 5ë¡œ ì¶•ì†Œ
            for result in reversed(recent_results):
                if 'market_trend' in result:
                    current_trend = result['market_trend']
                    break
        
        # ì¶”ì„¸ ìœ ì‚¬ë„ ì ìˆ˜ (ë” ê´€ëŒ€í•˜ê²Œ)
        if current_trend and pattern_trend:
            if current_trend == pattern_trend:
                market_similarity_score = 25
            elif ("uptrend" in current_trend and "uptrend" in pattern_trend) or \
                ("downtrend" in current_trend and "downtrend" in pattern_trend):
                market_similarity_score = 20  # 15 -> 20ìœ¼ë¡œ ì¦ê°€
            elif ("neutral" in current_trend and ("weak" in pattern_trend or "consolidation" in pattern_trend)) or \
                (("weak" in current_trend or "consolidation" in current_trend) and "neutral" in pattern_trend):
                market_similarity_score = 15  # 10 -> 15ë¡œ ì¦ê°€
            else:
                market_similarity_score = 5   # 0 -> 5ë¡œ ì¦ê°€ (ì™„ì „íˆ ë‹¤ë¥¸ ì¶”ì„¸ë„ ì•½ê°„ì˜ ì ìˆ˜)
        
        # 4. ìµœê·¼ì„± ì ìˆ˜ (15ì  ë§Œì ìœ¼ë¡œ ì¦ê°€)
        recency_score = 0
        
        pattern_date = None
        if 'timestamp' in pattern:
            pattern_date = pattern['timestamp']
        elif 'date' in pattern:
            pattern_date = pd.to_datetime(pattern['date'])
        
        current_date = datetime.datetime.now()
        
        if pattern_date:
            try:
                days_diff = (current_date - pattern_date).days
                
                # ìµœê·¼ì„± ê¸°ì¤€ ì™„í™”
                if days_diff <= 60:  # 30 -> 60ì¼ë¡œ í™•ëŒ€
                    recency_score = 15
                elif days_diff <= 120:  # 90 -> 120ì¼ë¡œ í™•ëŒ€
                    recency_score = 12  # 7 -> 12ë¡œ ì¦ê°€
                elif days_diff <= 240:  # 180 -> 240ì¼ë¡œ í™•ëŒ€
                    recency_score = 9   # 5 -> 9ë¡œ ì¦ê°€
                elif days_diff <= 365:
                    recency_score = 6   # 3 -> 6ìœ¼ë¡œ ì¦ê°€
                else:
                    recency_score = 3   # 0 -> 3ìœ¼ë¡œ ì¦ê°€ (ì™„ì „íˆ ì˜¤ë˜ëœ íŒ¨í„´ë„ ì•½ê°„ì˜ ì ìˆ˜)
            except:
                recency_score = 5  # 0 -> 5ë¡œ ì¦ê°€
        
        # ì´ì  ê³„ì‚°
        total_score = success_rate_score + sample_size_score + market_similarity_score + recency_score
        
        # ì ìˆ˜ ë¡œê¹…
        if hasattr(self, 'debug_mode') and self.debug_mode:
            print(f"ê°œì„ ëœ íŒ¨í„´ í’ˆì§ˆ ì ìˆ˜: {total_score:.1f}/100")
            print(f"- ì„±ê³µë¥  ì ìˆ˜: {success_rate_score:.1f}/40")
            print(f"- ìƒ˜í”Œ í¬ê¸° ì ìˆ˜: {sample_size_score:.1f}/20")
            print(f"- ì‹œì¥ ìœ ì‚¬ë„ ì ìˆ˜: {market_similarity_score:.1f}/25")
            print(f"- ìµœê·¼ì„± ì ìˆ˜: {recency_score:.1f}/15")
        
        return total_score
    
    def filter_patterns_by_quality(self, similar_patterns, min_quality_score=70):
        """
        í’ˆì§ˆ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒ¨í„´ í•„í„°ë§
        
        Args:
            similar_patterns: ìœ ì‚¬ íŒ¨í„´ ëª©ë¡
            min_quality_score: ìµœì†Œ í’ˆì§ˆ ì ìˆ˜ (ê¸°ë³¸ê°’: 70)
            
        Returns:
            list: í’ˆì§ˆ ì ìˆ˜ê°€ ê¸°ì¤€ ì´ìƒì¸ íŒ¨í„´ ëª©ë¡
        """
        if not similar_patterns:
            return []
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° í•„í„°ë§
        quality_patterns = []
        
        for pattern in similar_patterns:
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self.calculate_pattern_quality_score(pattern)
            
            # ì ìˆ˜ë¥¼ íŒ¨í„´ì— ì¶”ê°€
            pattern['quality_score'] = quality_score
            
            # ìµœì†Œ í’ˆì§ˆ ì ìˆ˜ ì´ìƒì¸ì§€ í™•ì¸
            if quality_score >= min_quality_score:
                quality_patterns.append(pattern)
        
        # í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        quality_patterns.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
        
        print(f"í’ˆì§ˆ ì ìˆ˜ í•„í„°ë§: {len(quality_patterns)}/{len(similar_patterns)} íŒ¨í„´ ì„ íƒë¨ (ê¸°ì¤€: {min_quality_score}ì )")
        
        return quality_patterns
    
    def update_pattern_score(self, pattern_id, trade_result):
        """
        ê±°ë˜ ê²°ê³¼ì— ë”°ë¥¸ íŒ¨í„´ ì ìˆ˜ ì—…ë°ì´íŠ¸
        
        Args:
            pattern_id: íŒ¨í„´ ID
            trade_result: ê±°ë˜ ê²°ê³¼ ê°ì²´
            
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'document_store'):
            print("íŒ¨í„´ ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # íŒ¨í„´ ì°¾ê¸°
        target_pattern = None
        pattern_index = -1
        
        for i, pattern in enumerate(self.document_store):
            if pattern.get('pattern_id') == pattern_id:
                target_pattern = pattern
                pattern_index = i
                break
        
        if target_pattern is None:
            print(f"íŒ¨í„´ {pattern_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ì´ë¯¸ ì™„ë£Œëœ ê±°ë˜ì¸ì§€ í™•ì¸
        if target_pattern.get('trade_result', {}).get('completed', False):
            print(f"íŒ¨í„´ {pattern_id}ì˜ ê±°ë˜ê°€ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
        
        # ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ í•¨ìˆ˜ì™€ ë™ì¼)
        entry_price = target_pattern['trade_result'].get('entry_price')
        if entry_price is None:
            entry_price = target_pattern['price']
        
        exit_price = trade_result.get('exit_price', 0)
        if entry_price > 0 and exit_price > 0:
            profit_pct = ((exit_price / entry_price) - 1) * 100
            success = profit_pct > 0
            
            # ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸
            target_pattern['trade_result'].update({
                'completed': True,
                'exit_price': exit_price,
                'profit_pct': profit_pct,
                'success': success,
                'exit_reason': trade_result.get('exit_reason', 'UNKNOWN'),
                'exit_date': trade_result.get('exit_date', datetime.datetime.now().strftime("%Y-%m-%d")),
                'holding_days': self.calculate_holding_days(target_pattern['date'], trade_result.get('exit_date', datetime.datetime.now().strftime("%Y-%m-%d")))
            })
            
            # íŒ¨í„´ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            target_pattern['pattern_metrics'].update({
                'success_count': target_pattern['pattern_metrics']['success_count'] + (1 if success else 0),
                'failure_count': target_pattern['pattern_metrics']['failure_count'] + (0 if success else 1),
                'total_profit': target_pattern['pattern_metrics']['total_profit'] + profit_pct,
                'last_update': datetime.datetime.now().strftime("%Y-%m-%d")
            })
            
            # í‰ê·  ìˆ˜ìµ ë° ì„±ê³µë¥  ì¬ê³„ì‚°
            total_trades = target_pattern['pattern_metrics']['success_count'] + target_pattern['pattern_metrics']['failure_count']
            if total_trades > 0:
                target_pattern['pattern_metrics']['avg_profit'] = target_pattern['pattern_metrics']['total_profit'] / total_trades
                target_pattern['pattern_metrics']['success_rate'] = target_pattern['pattern_metrics']['success_count'] / total_trades * 100
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì‹ ê·œ ì¶”ê°€)
            quality_score = self.calculate_pattern_quality_score(target_pattern)
            target_pattern['pattern_metrics']['quality_score'] = quality_score
            
            # ë¬¸ì„œ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
            self.document_store[pattern_index] = target_pattern
            print(f"íŒ¨í„´ {pattern_id} ê±°ë˜ ê²°ê³¼ ë° í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸: ìˆ˜ìµ={profit_pct:.2f}%, ì„±ê³µ={success}, í’ˆì§ˆ={quality_score:.1f}")
            
            return True
        else:
            print(f"íŒ¨í„´ {pattern_id}ì˜ ê°€ê²© ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False


    def update_pattern_with_trade_result(self, pattern_id, exit_price, exit_date, exit_reason):
        """ê±°ë˜ ê²°ê³¼ë¡œ íŒ¨í„´ ì •ë³´ ì—…ë°ì´íŠ¸
        
        Args:
            pattern_id: íŒ¨í„´ ê³ ìœ  ID
            exit_price: ë§¤ë„ ê°€ê²©
            exit_date: ë§¤ë„ ë‚ ì§œ
            exit_reason: ë§¤ë„ ì´ìœ  ('PROFIT', 'STOPLOSS', 'TRAILING', 'MANUAL')
        
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'document_store'):
            print("Warning: document_store not initialized")
            return False
        
        # í•´ë‹¹ íŒ¨í„´ ì°¾ê¸°
        target_pattern = None
        pattern_index = -1
        
        for i, pattern in enumerate(self.document_store):
            if pattern.get('pattern_id') == pattern_id:
                target_pattern = pattern
                pattern_index = i
                break
        
        if target_pattern is None:
            print(f"Pattern {pattern_id} not found in document store")
            return False
        
        # ì´ë¯¸ ì™„ë£Œëœ ê±°ë˜ì¸ì§€ í™•ì¸
        if target_pattern.get('trade_result', {}).get('completed', False):
            print(f"Trade for pattern {pattern_id} already completed")
            return False
        
        # ì§„ì… ê°€ê²© í™•ì¸
        entry_price = target_pattern['trade_result'].get('entry_price')
        if entry_price is None:
            print(f"No entry price for pattern {pattern_id}")
            entry_price = target_pattern['price']  # íŒ¨í„´ ì €ì¥ ì‹œ ê°€ê²© ì‚¬ìš©
        
        # ê²°ê³¼ ê³„ì‚°
        if entry_price > 0 and exit_price > 0:
            profit_pct = ((exit_price / entry_price) - 1) * 100
            success = profit_pct > 0
            
            # ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸
            target_pattern['trade_result'].update({
                'completed': True,
                'exit_price': exit_price,
                'profit_pct': profit_pct,
                'success': success,
                'exit_reason': exit_reason,
                'exit_date': exit_date.strftime("%Y-%m-%d") if isinstance(exit_date, datetime.datetime) else exit_date,
                'holding_days': self.calculate_holding_days(target_pattern['date'], exit_date)
            })
            
            # íŒ¨í„´ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            target_pattern['pattern_metrics'].update({
                'success_count': target_pattern['pattern_metrics']['success_count'] + (1 if success else 0),
                'failure_count': target_pattern['pattern_metrics']['failure_count'] + (0 if success else 1),
                'total_profit': target_pattern['pattern_metrics']['total_profit'] + profit_pct,
                'last_update': datetime.datetime.now().strftime("%Y-%m-%d")
            })
            
            # í‰ê·  ìˆ˜ìµ ë° ì„±ê³µë¥  ì¬ê³„ì‚°
            total_trades = target_pattern['pattern_metrics']['success_count'] + target_pattern['pattern_metrics']['failure_count']
            if total_trades > 0:
                target_pattern['pattern_metrics']['avg_profit'] = target_pattern['pattern_metrics']['total_profit'] / total_trades
                target_pattern['pattern_metrics']['success_rate'] = target_pattern['pattern_metrics']['success_count'] / total_trades * 100
            
            # ë¬¸ì„œ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
            self.document_store[pattern_index] = target_pattern
            print(f"Pattern {pattern_id} updated with trade result: profit={profit_pct:.2f}%, success={success}")
            
            # ì‹ ê·œ: ë°”ì´ë„ˆë¦¬ ì••ì¶• í˜•ì‹ìœ¼ë¡œ RAG ë°ì´í„° ì €ì¥
            try:
                import pickle
                import gzip
                with gzip.open('rag_pattern_store.pkl.gz', 'wb') as f:
                    pickle.dump(self.document_store, f)
                print("RAG pattern store saved to compressed file")
            except Exception as e:
                print(f"Failed to save RAG pattern store: {str(e)}")
            
            return True
        else:
            print(f"Invalid prices for pattern {pattern_id}")
            return False



    def store_market_pattern(self, current_indicators, price, decision, context_date=None):
        """ì‹œì¥ íŒ¨í„´ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - ì„±ê³µ íŒ¨í„´ í•™ìŠµì„ ìœ„í•´ ê°œì„ ë¨
        
        Args:
            current_indicators: í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ
            price: í˜„ì¬ ê°€ê²©
            decision: AI ê²°ì • ('BUY', 'SELL', 'HOLD')
            context_date: ì»¨í…ìŠ¤íŠ¸ ë‚ ì§œ (ê¸°ë³¸ê°’: í˜„ì¬)
        """
        # í˜„ì¬ ì‹œì¥ ì¶”ì„¸ ê°ì§€
        market_trend = self.detect_market_trend(current_indicators)
        
        # ì§€ì§€ì„  ì •ë³´ ì¶”ê°€
        if price:
            support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
        else:
            support_analysis = {}
        
        # í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ì„¤ì •
        if context_date is None:
            current_datetime = datetime.datetime.now()
        else:
            current_datetime = context_date if isinstance(context_date, datetime.datetime) else pd.to_datetime(context_date)
        
        # ì‹ ê·œ: ê±°ë˜ ID ìƒì„± (íŒ¨í„´ê³¼ ê²°ê³¼ ì—°ê²°ìš©)
        pattern_id = f"{current_datetime.strftime('%Y%m%d%H%M%S')}_{hash(str(current_indicators))}"
        
        # íŒ¨í„´ ì €ì¥ ê°ì²´ ìƒì„±
        new_context = {
            'pattern_id': pattern_id,  # ì‹ ê·œ: íŒ¨í„´ ê³ ìœ  ID
            'date': current_datetime.strftime("%Y-%m-%d"),
            'timestamp': current_datetime,
            'indicators': current_indicators,
            'price': price,  # ì‹ ê·œ: ê°€ê²© ì •ë³´ ì €ì¥
            'market_trend': market_trend,
            'support_analysis': support_analysis,
            'ai_decision': decision,  # ì‹ ê·œ: AI ê²°ì • ì €ì¥
            'content': f"Market shows {market_trend} with RSI at {current_indicators.get('RSI(14)', 'N/A')}. "
                    f"MACD is {current_indicators.get('MACD', 'N/A')}. "
                    f"Bollinger Bands: {current_indicators.get('Bollinger Bands', 'N/A')}. "
                    f"Moving Averages: {current_indicators.get('Moving Averages', 'N/A')}. "
                    f"Support level nearby: {support_analysis.get('is_near_support', False)}, "
                    f"Support strength: {support_analysis.get('strength', 0):.2f}.",
            'trade_result': {  # ì‹ ê·œ: ê±°ë˜ ê²°ê³¼ ì €ì¥ ì˜ì—­
                'completed': False,  # ê±°ë˜ ì™„ë£Œ ì—¬ë¶€
                'entry_price': price if decision == 'BUY' else None,
                'exit_price': None,
                'profit_pct': None,
                'success': None,
                'exit_reason': None,
                'holding_days': None
            },
            'pattern_metrics': {  # ì‹ ê·œ: íŒ¨í„´ ë©”íŠ¸ë¦­
                'success_count': 0,
                'failure_count': 0,
                'total_profit': 0,
                'avg_profit': 0,
                'success_rate': 0,
                'last_update': current_datetime.strftime("%Y-%m-%d"),
                'usage_count': 0  # ì´ íŒ¨í„´ì´ ì°¸ì¡°ëœ íšŸìˆ˜
            }
        }
        
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì‚¬ (pattern_id ê¸°ë°˜)
        if not hasattr(self, 'document_store'):
            self.document_store = []
            
        existing_index = -1
        for i, doc in enumerate(self.document_store):
            if doc.get('pattern_id') == pattern_id:
                existing_index = i
                break
        
        if existing_index >= 0:
            # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            self.document_store[existing_index] = new_context
            print(f"Pattern {pattern_id} updated in document store")
        else:
            # ìƒˆ í•­ëª© ì¶”ê°€
            self.document_store.append(new_context)
            print(f"New pattern {pattern_id} added to document store")
        
        return pattern_id  # ì‹ ê·œ: ì €ì¥ëœ íŒ¨í„´ì˜ ID ë°˜í™˜
            
    def reset(self):
        """ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ìƒíƒœ ì´ˆê¸°í™”"""
        self.historical_data = []
        self.backtest_results = []
        self.processed_timestamps = set()
        self.document_store = []
        self.consecutive_losses = 0
        self.stop_loss_streak = 0
        self.cooldown_until = -1
        self.recovery_factor = 1.0
        self.trailing_stop_price = 0.0
        print("ë°±í…ŒìŠ¤í„° ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def calculate_holding_days(self, entry_date, exit_date):
        """
        ë‘ ë‚ ì§œ ì‚¬ì´ì˜ ì¼ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            entry_date (str): ì§„ì… ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD HH:MM:SS í˜•ì‹)
            exit_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD HH:MM:SS í˜•ì‹)
            
        Returns:
            int: ë³´ìœ  ê¸°ê°„(ì¼)
        """
        try:
            # ë‚ ì§œ í¬ë§· ì •ê·œí™” (ì‹œê°„ ë¶€ë¶„ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬)
            if ' ' in entry_date:
                entry_date = entry_date.split(' ')[0]
            if ' ' in exit_date:
                exit_date = exit_date.split(' ')[0]
            
            entry_dt = pd.to_datetime(entry_date)
            exit_dt = pd.to_datetime(exit_date)
            
            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta = exit_dt - entry_dt
            return max(0, delta.days)
        except Exception as e:
            print(f"ë‚ ì§œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0
    def load_daily_data(self, target_date, timeframe='1h'):
        """
        ëª…í™•í•˜ê²Œ íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„°ë§Œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
        
        Args:
            target_date: ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)
            timeframe: '1m', '15m', '1h' ë“±
        """
        try:
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜
            if isinstance(target_date, str):
                date_obj = pd.to_datetime(target_date)
            else:
                date_obj = target_date
                
            # ë‹¤ìŒë‚  ê³„ì‚° (í•˜ë£¨ì¹˜ ë°ì´í„° ìš”ì²­)
            next_day = date_obj + datetime.timedelta(days=1)
            
            print(f"ë¡œë”© ì¤‘: {date_obj.strftime('%Y-%m-%d')}ì˜ {timeframe} ë°ì´í„°")
            
            # ì‹œê°„ í”„ë ˆì„ë³„ ë°ì´í„° í¬ì¸íŠ¸ ê³„ì‚°
            timeframe_map = {
                '1m': 1440,     # í•˜ë£¨ = 24ì‹œê°„ * 60ë¶„
                '15m': 96,      # í•˜ë£¨ = 24ì‹œê°„ * 4 (15ë¶„ë‹¨ìœ„)
                '1h': 24,       # í•˜ë£¨ = 24ì‹œê°„
                '4h': 6,        # í•˜ë£¨ = 24ì‹œê°„ / 4
                '1d': 1         # í•˜ë£¨ = 1ì¼
            }
            
            count = timeframe_map.get(timeframe, 24)
            
            # ì •í™•í•œ ë²”ìœ„ ì§€ì •ì„ ìœ„í•´ fromê³¼ to ëª¨ë‘ ëª…ì‹œ
            from_date = date_obj.strftime('%Y-%m-%d')
            to_date = next_day.strftime('%Y-%m-%d')
            
            print(f"ë°ì´í„° ìš”ì²­ ë²”ìœ„: {from_date} ~ {to_date}")
            
            # pyupbitë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì •í™•í•œ ë‚ ì§œ ë²”ìœ„ ì§€ì •)
            df = pyupbit.get_ohlcv(
                "KRW-BTC", 
                interval=timeframe, 
                count=count, 
                to=to_date
            )
            
            # ë°ì´í„° í•„í„°ë§ - ìš”ì²­í•œ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ìœ ì§€
            if df is not None and not df.empty:
                # ë‚ ì§œ í•„ë“œ ì¶”ê°€
                df['date'] = df.index.strftime('%Y-%m-%d %H:%M:%S')
                
                # ìš”ì²­ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
                filtered_df = df[df.index.date == date_obj.date()]
                
                if not filtered_df.empty:
                    print(f"ì„±ê³µ: {len(filtered_df)}ê°œ {timeframe} ë°ì´í„° ë¡œë“œë¨ (í•„í„°ë§ ì „: {len(df)})")
                    return filtered_df
                else:
                    print(f"ê²½ê³ : {date_obj.strftime('%Y-%m-%d')} ë°ì´í„° ì—†ìŒ (í•„í„°ë§ í›„)")
                    return pd.DataFrame()
            else:
                print(f"ê²½ê³ : {date_obj.strftime('%Y-%m-%d')} ë°ì´í„° ì—†ìŒ")
                return pd.DataFrame()
                    
        except Exception as e:
            print(f"ì˜¤ë¥˜: ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ {str(e)}")
            return pd.DataFrame()

    def load_weekly_data(self, start_date, timeframe='1h'):
        """
        ì£¼ë³„ ë°ì´í„° ë¡œë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ
            timeframe: '1m', '15m', '1h' ë“±
        """
        try:
            # ì‹œê°„ í”„ë ˆì„ë³„ ë°ì´í„° í¬ì¸íŠ¸ ê³„ì‚°
            timeframe_map = {
                '1m': 10080,    # 1ì£¼ì¼ = 7ì¼ * 24ì‹œê°„ * 60ë¶„
                '15m': 672,     # 1ì£¼ì¼ = 7ì¼ * 24ì‹œê°„ * 4 (15ë¶„ë‹¨ìœ„)
                '1h': 168,      # 1ì£¼ì¼ = 7ì¼ * 24ì‹œê°„
                '4h': 42,       # 1ì£¼ì¼ = 7ì¼ * 6 (4ì‹œê°„ë‹¨ìœ„)
                '1d': 7         # 1ì£¼ì¼ = 7ì¼
            }
            
            count = timeframe_map.get(timeframe, 168)
            
            # ì£¼ ëë‚  ê³„ì‚°
            week_end = pd.to_datetime(start_date) + datetime.timedelta(days=7)
            
            # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            df = pyupbit.get_ohlcv("KRW-BTC", interval=timeframe, count=count, to=week_end.strftime('%Y-%m-%d'))
            
            if df is not None and not df.empty:
                df['date'] = df.index.strftime('%Y-%m-%d %H:%M:%S')
                return df
            else:
                print(f"No data retrieved for week starting {start_date}")
                return pd.DataFrame()
                
        except Exception as e:
            print(f"Error loading weekly data: {str(e)}")
            return pd.DataFrame()

    def check_support_trigger(self, current_price, timestamp):
        """
        ì§€ì§€ì„  ë„ë‹¬ ì—¬ë¶€ ì²´í¬ (AI í˜¸ì¶œ íŠ¸ë¦¬ê±°)
        
        Returns:
            bool: ì§€ì§€ì„  ê·¼ì²˜ ë„ë‹¬ ì‹œ True
        """
        try:
            # ì§€ì§€ì„  ê³„ì‚°
            support_levels = self._calculate_enhanced_support_levels("KRW-BTC")
            
            if not support_levels:
                return False
            
            # ì§€ì§€ì„ ê³¼ì˜ ê±°ë¦¬ ì²´í¬
            closest_distance = float('inf')
            for support in support_levels:
                if support > 0:
                    distance_pct = abs((current_price - support) / current_price) * 100
                    closest_distance = min(closest_distance, distance_pct)
            
            # ì§€ì§€ì„  3% ì´ë‚´ ë„ë‹¬ ì‹œ íŠ¸ë¦¬ê±°
            is_triggered = closest_distance <= 3.0
            
            if is_triggered:
                print(f"[TRIGGER] Support level reached at {timestamp}")
                print(f"Price: â‚©{current_price:,.0f}, Distance: {closest_distance:.2f}%")
            
            return is_triggered
            
        except Exception as e:
            print(f"Error checking support trigger: {str(e)}")
            return False


    def collect_all_news_for_period(self, start_date, end_date):
        """ë°±í…ŒìŠ¤íŒ… ì‹œì‘ ì „ ì „ì²´ ê¸°ê°„ ë‰´ìŠ¤ ì‚¬ì „ ìˆ˜ì§‘"""
        print(f"Collecting all news for period: {start_date} to {end_date}")
        
        self.news_database = {}
        self.news_correlations = {}
        
        current_date = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date)
        
        while current_date <= end_dt:
            date_str = current_date.strftime('%Y-%m-%d')
            
            # í•´ë‹¹ ë‚ ì§œ ë‰´ìŠ¤ ìˆ˜ì§‘
            news_data = self.fetch_news("BTC", current_date, current_date + datetime.timedelta(days=1))
            
            if news_data:
                self.news_database[date_str] = news_data
                print(f"Collected {len(news_data)} news for {date_str}")
            
            current_date += datetime.timedelta(days=1)
            time.sleep(0.1)  # API ì œí•œ ê³ ë ¤
        
        print(f"Total news collection complete: {len(self.news_database)} days")
        return self.news_database


    def analyze_with_llm_with_context(self, coin, price, tech_indicators, news_data, analysis_context, test_mode=False):
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í¬í•¨í•œ 3ë‹¨ê³„ AI ë¶„ì„ - ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì§€ì› ê°•í™”"""
        if not self.llm:
            return {"signal": "ERROR", "analysis": "LLM not initialized", "confidence": 0}

        print("\n" + "="*70)
        print(f"ğŸš€ STARTING 3-STAGE AI ANALYSIS WITH CONTEXT - {coin}")
        print(f"Context: {analysis_context['current_date']} {analysis_context.get('current_time', '')}")
        print("="*70)

        # ê¸°ì¡´ ë¶„ì„ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€)
        market_trend = self.detect_market_trend(tech_indicators)
        news_sentiment = self.analyze_news_sentiment(news_data)
        support_analysis = self._check_near_support_level_enhanced(coin, price)

        # í˜„ì¬ ì‹œì  ì •ë³´ - ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        current_datetime = analysis_context.get('current_datetime')
        if current_datetime is None:
            # ì»¨í…ìŠ¤íŠ¸ì— datetimeì´ ì—†ìœ¼ë©´ ë‚ ì§œ/ì‹œê°„ ì •ë³´ ì¡°í•©
            if 'current_date' in analysis_context:
                date_str = analysis_context['current_date']
                time_str = analysis_context.get('current_time', '00:00:00')
                try:
                    current_datetime = pd.to_datetime(f"{date_str} {time_str}")
                except:
                    current_datetime = datetime.datetime.now()
            else:
                current_datetime = datetime.datetime.now()
        
        print(f"[CONTEXT] Using datetime: {current_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"[CONTEXT] Backtest mode: {analysis_context.get('backtest_mode', False)}")

        # === 1ë‹¨ê³„: ë‰´ìŠ¤ ìš”ì•½ ===
        news_context = self.get_news_context_for_ai(current_datetime, lookback_days=3)
        news_summary = self.summarize_news_with_ai(news_context)

        # === 2ë‹¨ê³„: ì¢…í•© ë¶„ì„ + ê²°ì • ===
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨í•˜ì—¬ í˜¸ì¶œ
        comprehensive_analysis = self.comprehensive_analysis_with_ai_with_context(
            coin, price, tech_indicators, news_summary, support_analysis, analysis_context
        )

        # === 3ë‹¨ê³„: JSON ì¶”ì¶œ ===
        decision_result = self.extract_trading_decision(comprehensive_analysis)

        # === ê²°ê³¼ ì²˜ë¦¬ ===
        decision = decision_result.get('decision', 'HOLD')
        profit_target = decision_result.get('profit_target', 5.0)
        stop_loss = decision_result.get('stop_loss', -2.0)
        trailing_stop = decision_result.get('trailing_stop', 1.0)
        confidence = decision_result.get('confidence', 0.5)
        reasoning = decision_result.get('reasoning', 'AI 3-stage analysis with context completed')

        # ì†ì ˆê°€ ìŒìˆ˜ ê²€ì¦
        if stop_loss > 0:
            print(f"WARNING: Stop loss was positive ({stop_loss}%), converting to negative")
            stop_loss = -abs(stop_loss)

        # ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • (ê¸°ì¡´ ì½”ë“œ)
        confluence_signals = self._calculate_confluence_score(tech_indicators, news_sentiment, support_analysis, market_trend)
        market_regime = self._detect_market_regime(tech_indicators, self.get_recent_market_context())

        # ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” íŒŒë¼ë¯¸í„° ì¡°ì •ì„ ë‹¤ë¥´ê²Œ í•  ìˆ˜ ìˆìŒ
        if analysis_context.get('backtest_mode', False):
            # ë°±í…ŒìŠ¤íŠ¸ íŠ¹í™” íŒŒë¼ë¯¸í„° ì¡°ì • (ì˜ˆ: ë” ë³´ìˆ˜ì ì¸ ì„¤ì •)
            profit_target, stop_loss, trailing_stop = self._apply_dynamic_parameters_for_backtest(
                profit_target, stop_loss, trailing_stop, 
                confluence_signals, market_regime, analysis_context
            )
        else:
            # ì¼ë°˜ ê±°ë˜ íŒŒë¼ë¯¸í„° ì¡°ì •
            profit_target, stop_loss, trailing_stop = self._apply_dynamic_parameters(
                profit_target, stop_loss, trailing_stop, 
                confluence_signals, market_regime, {}
            )

        # === ìµœì¢… ê²°ê³¼ ì¶œë ¥ ===
        print("ğŸ¯ FINAL TRADING DECISION WITH CONTEXT:")
        print("="*70)
        print(f"SIGNAL: {decision}")
        print(f"CONFIDENCE: {confidence:.2f}")
        print(f"PROFIT TARGET: {profit_target}%")
        print(f"STOP LOSS: {stop_loss}%")
        print(f"TRAILING STOP: {trailing_stop}%")
        print(f"MARKET TREND: {market_trend}")
        print(f"NEWS SUMMARY: {news_summary[:100]}...")
        print(f"CONTEXT DATE: {current_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*70)
        print()

        # í˜„ì¬ íŒ¨í„´ì„ document_storeì— ì¶”ê°€ (RAG í•™ìŠµ)
        if tech_indicators:
            # í˜„ì¬ ì‹œì¥ ì¶”ì„¸ ê°ì§€
            market_trend = self.detect_market_trend(tech_indicators)
            
            # ì§€ì§€ì„  ì •ë³´ ì¶”ê°€
            current_price_val = price
            
            if current_price_val:
                support_analysis_for_rag = self._check_near_support_level_enhanced(coin, current_price_val)
            else:
                support_analysis_for_rag = {}
            
            new_context = {
                'date': current_datetime.strftime("%Y-%m-%d"),
                'timestamp': current_datetime,
                'indicators': tech_indicators,
                'market_trend': market_trend,
                'support_analysis': support_analysis_for_rag,
                'content': f"Market shows {market_trend} with RSI at {tech_indicators.get('RSI(14)', 'N/A')}. "
                        f"MACD is {tech_indicators.get('MACD', 'N/A')}. "
                        f"Bollinger Bands: {tech_indicators.get('Bollinger Bands', 'N/A')}. "
                        f"Moving Averages: {tech_indicators.get('Moving Averages', 'N/A')}. "
                        f"Support level nearby: {support_analysis_for_rag.get('is_near_support', False)}, "
                        f"Support strength: {support_analysis_for_rag.get('strength', 0):.2f}."
            }
            
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì‚¬
            existing_index = -1
            
            # document_storeê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
            if not hasattr(self, 'document_store'):
                self.document_store = []
                
            for i, doc in enumerate(self.document_store):
                if doc.get('date') == new_context['date']:
                    existing_index = i
                    break
            
            if existing_index >= 0:
                # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
                self.document_store[existing_index] = new_context
            else:
                # ìƒˆ í•­ëª© ì¶”ê°€
                self.document_store.append(new_context)

        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€)
        return {
            "signal": decision,
            "profit_target": profit_target,
            "stop_loss": stop_loss,
            "trailing_stop": trailing_stop,
            "analysis": comprehensive_analysis,  # 2ë‹¨ê³„ ì „ì²´ í…ìŠ¤íŠ¸
            "confidence": confidence,
            "market_trend": market_trend,
            "news_sentiment": news_sentiment,
            "reasoning": reasoning,
            "support_analysis": support_analysis,
            "news_summary": news_summary,  # 1ë‹¨ê³„ ê²°ê³¼
            "confluence_score": confluence_signals.get('total_score', 0),
            "market_regime": market_regime,
            "context_date": current_datetime.strftime('%Y-%m-%d %H:%M:%S'),
            "backtest_mode": analysis_context.get('backtest_mode', False)
        }



    def analyze_news_price_correlations(self, minute_data):
        """ë‰´ìŠ¤ì™€ ê°€ê²© ë³€í™”ì˜ ìƒê´€ê´€ê³„ ì‚¬ì „ ë¶„ì„ - íƒ€ì„ì¡´ ì²˜ë¦¬ ê°œì„ """
        correlations = {}
        
        for date_str, news_list in self.news_database.items():
            for news in news_list:
                try:
                    # ë‰´ìŠ¤ ì‹œê°„ì„ naive datetimeìœ¼ë¡œ ë³€í™˜
                    news_time = pd.to_datetime(news['publishedAt'])
                    if hasattr(news_time, 'tz') and news_time.tz is not None:
                        news_time = news_time.tz_localize(None)
                    
                    # ë‰´ìŠ¤ ë°œìƒ í›„ ê°€ê²© ë³€í™” ê³„ì‚°
                    price_impacts = self._calculate_price_impacts_after_news(news_time, minute_data)
                    
                    # ë‰´ìŠ¤ ê°ì„± ë¶„ì„
                    sentiment = self.analyze_news_sentiment([news])
                    
                    correlation_data = {
                        'news_id': news.get('url', str(hash(news['title']))),
                        'timestamp': news_time,
                        'title': news['title'],
                        'sentiment_score': sentiment['sentiment_score'],
                        'themes': sentiment.get('key_topics', []),
                        'price_impact_1h': price_impacts.get('1h', 0),
                        'price_impact_6h': price_impacts.get('6h', 0),
                        'price_impact_24h': price_impacts.get('24h', 0),
                        'volume_impact': price_impacts.get('volume', 0)
                    }
                    
                    correlations[news_time.isoformat()] = correlation_data
                    
                except Exception as e:
                    print(f"Error analyzing news correlation: {str(e)}")
                    continue
        
        self.news_correlations = correlations
        print(f"Analyzed correlations for {len(correlations)} news items")
        return correlations

    def _calculate_price_impacts_after_news(self, news_time, price_data):
        """
        ë‰´ìŠ¤ ë°œìƒ í›„ ê°€ê²© ì˜í–¥ ê³„ì‚°
        
        Args:
            news_time: ë‰´ìŠ¤ ë°œí–‰ ì‹œê°„
            price_data: ê°€ê²© ë°ì´í„° ëª©ë¡
            
        Returns:
            dict: ê° ê¸°ê°„ë³„ ê°€ê²© ì˜í–¥ ë¹„ìœ¨
        """
        try:
            # íƒ€ì„ì¡´ ì²˜ë¦¬ - ì˜¬ë°”ë¥¸ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì •
            if hasattr(news_time, 'tz') and news_time.tz is not None:
                # timezone-awareë¥¼ timezone-naiveë¡œ ë³€í™˜
                news_time = news_time.tz_localize(None)
            
            # ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
            if isinstance(news_time, str):
                news_time = pd.to_datetime(news_time)
            
            # price_dataì˜ datetime í•„ë“œë“¤ë„ í†µì¼
            processed_data = []
            for data in price_data:
                data_datetime = data.get('datetime')
                if data_datetime is not None:
                    # ë¬¸ìì—´ì´ë¼ë©´ ë¨¼ì € datetimeìœ¼ë¡œ ë³€í™˜
                    if isinstance(data_datetime, str):
                        data_datetime = pd.to_datetime(data_datetime)
                    
                    # timezone awareë¼ë©´ naiveë¡œ ë³€í™˜
                    if hasattr(data_datetime, 'tz') and data_datetime.tz is not None:
                        data_datetime = data_datetime.tz_localize(None)
                    
                    processed_data.append({
                        'datetime': data_datetime,
                        'close': data.get('close', 0),
                        'volume': data.get('volume', 0)
                    })
            
            # ë‰´ìŠ¤ ì‹œì  ê°€ê²© ì°¾ê¸°
            news_price = None
            news_index = None
            
            for i, data in enumerate(processed_data):
                if data['datetime'] >= news_time:
                    news_price = data['close']
                    news_index = i
                    break
            
            if news_price is None or news_price == 0:
                return {}
            
            # ë‰´ìŠ¤ ì‹œì  ì´í›„ ê° ì‹œê°„ëŒ€ë³„ ê°€ê²© ì˜í–¥ ê³„ì‚°
            impacts = {}
            time_frames = {'1h': 1, '6h': 6, '24h': 24}
            
            for timeframe, hours in time_frames.items():
                target_time = news_time + datetime.timedelta(hours=hours)
                
                # í•´ë‹¹ ì‹œê°„ì˜ ê°€ê²© ì°¾ê¸°
                for data in processed_data:
                    if data['datetime'] >= target_time:
                        later_price = data['close']
                        if later_price > 0 and news_price > 0:
                            impacts[timeframe] = ((later_price / news_price) - 1) * 100
                        break
            
            # ê±°ë˜ëŸ‰ ë³€í™” ê³„ì‚°
            if news_index is not None and news_index > 0 and len(processed_data) > news_index + 6:
                # ë‰´ìŠ¤ ì „ í‰ê·  ê±°ë˜ëŸ‰
                pre_avg_volume = sum(data['volume'] for data in processed_data[max(0, news_index-6):news_index]) / min(6, news_index)
                
                # ë‰´ìŠ¤ í›„ í‰ê·  ê±°ë˜ëŸ‰
                post_avg_volume = sum(data['volume'] for data in processed_data[news_index:news_index+6]) / min(6, len(processed_data)-news_index)
                
                # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨
                if pre_avg_volume > 0:
                    impacts['volume'] = ((post_avg_volume / pre_avg_volume) - 1) * 100
            
            return impacts
            
        except Exception as e:
            print(f"ê°€ê²© ì˜í–¥ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {}


    def get_news_context_for_ai(self, current_datetime, lookback_days=3):
        """
        AIì—ê²Œ ì œê³µí•  ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± - ì‹¤ì‹œê°„ ë¶„ì„ í™œìš©
        
        Args:
            current_datetime: í˜„ì¬ ì‹œì 
            lookback_days: ëª‡ì¼ ì „ ë‰´ìŠ¤ê¹Œì§€ í¬í•¨í• ì§€
            
        Returns:
            dict: ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        """
        relevant_news = []
        seen_urls = set()  # URL ì¤‘ë³µ ì²´í¬ìš©
        seen_titles = set()  # ì œëª© ì¤‘ë³µ ì²´í¬ìš©
        
        # current_datetimeì„ naiveë¡œ ë³€í™˜
        if hasattr(current_datetime, 'tz') and current_datetime.tz is not None:
            current_datetime = current_datetime.tz_localize(None)
        
        # current_datetimeì´ stringì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
        if isinstance(current_datetime, str):
            current_datetime = pd.to_datetime(current_datetime)
        
        print(f"[NEWS CONTEXT] Looking for news around {current_datetime}")
        
        # ì‹œê°„ ë²”ìœ„ ì„¤ì •
        start_date = current_datetime - datetime.timedelta(days=lookback_days)
        
        # í•„í„°ë§ëœ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        try:
            # í˜„ì¬ ì‹œì ì˜ ë‰´ìŠ¤ ê²€ìƒ‰
            news_data = self.fetch_news("BTC", start_date, current_datetime)
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë‰´ìŠ¤ ì¶”ê°€
            for news in news_data:
                news_url = news.get('url', '')
                news_title = news.get('title', '')
                
                # URL ë˜ëŠ” ì œëª© ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
                if news_url and news_url not in seen_urls:
                    relevant_news.append(news)
                    seen_urls.add(news_url)
                    seen_titles.add(news_title)
                elif not news_url and news_title and news_title not in seen_titles:
                    relevant_news.append(news)
                    seen_titles.add(news_title)
        except Exception as e:
            print(f"ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
        
        # ìƒê´€ê´€ê³„ ë¶„ì„ëœ ë‰´ìŠ¤ë§Œ ì‚¬ìš©í•´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        news_with_correlation = []
        
        if hasattr(self, 'news_correlations') and self.news_correlations:
            # news_correlationsì—ì„œ ìµœê·¼ í•­ëª©ë§Œ í•„í„°ë§
            for news_id, news_info in self.news_correlations.items():
                try:
                    news_time = pd.to_datetime(news_info.get('timestamp', ''))
                    
                    # ì§€ì •ëœ ì‹œê°„ ë²”ìœ„ ë‚´ì˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
                    if start_date <= news_time <= current_datetime:
                        news_with_correlation.append({
                            'title': news_info.get('title', ''),
                            'published': news_info.get('timestamp', ''),
                            'sentiment': news_info.get('sentiment_score', 0),
                            'predicted_impact': {
                                'direction': 'positive' if news_info.get('price_impact_6h', 0) > 0 else 'negative',
                                'magnitude': abs(news_info.get('price_impact_6h', 0)),
                                'confidence': min(0.9, 0.4 + abs(news_info.get('sentiment_score', 0))),
                            },
                            'themes': news_info.get('themes', [])
                        })
                except Exception as e:
                    print(f"ìƒê´€ê´€ê³„ ë‰´ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        
        # ìƒê´€ê´€ê³„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰
        if not news_with_correlation:
            print("ìƒê´€ê´€ê³„ ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ ë‰´ìŠ¤ ë¶„ì„ ì‹¤í–‰")
            for news in relevant_news[:5]:  # ìµœëŒ€ 5ê°œë§Œ ì²˜ë¦¬
                try:
                    news_sentiment = self.analyze_news_sentiment([news])
                    predicted_impact = self._predict_news_impact(news, news_sentiment)
                    
                    news_with_correlation.append({
                        'title': news.get('title', '')[:100],
                        'published': news.get('publishedAt', ''),
                        'sentiment': news_sentiment['sentiment_score'],
                        'predicted_impact': predicted_impact,
                        'themes': news_sentiment.get('key_topics', [])
                    })
                except Exception as e:
                    print(f"ë‰´ìŠ¤ í•­ëª© ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                    continue
        
        # ì „ì²´ ê°ì„± ì ìˆ˜ ê³„ì‚°
        overall_sentiment = 0
        if news_with_correlation:
            sentiment_scores = [news['sentiment'] for news in news_with_correlation]
            overall_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
        
        return {
            'news_count': len(relevant_news),
            'overall_sentiment': overall_sentiment,
            'top_news': news_with_correlation[:5],  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
            'sentiment_summary': self._categorize_sentiment(overall_sentiment)
        }
    




    def _predict_news_impact(self, news, sentiment_analysis):
        """ê³¼ê±° ìƒê´€ê´€ê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‰´ìŠ¤ ì˜í–¥ ì˜ˆì¸¡ - ê°œì„ ëœ ë²„ì „"""
        # news_correlationsê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not hasattr(self, 'news_correlations') or not self.news_correlations:
            print("Warning: news_correlations not available, using default prediction")
            current_sentiment = sentiment_analysis['sentiment_score']
            
            # ë‰´ìŠ¤ ì œëª© í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ ì¶”ê°€ ì˜ˆì¸¡ ì •ë³´ ì œê³µ
            title = news.get('title', '').lower()
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì˜í–¥ë„ ì¡°ì •
            high_impact_keywords = ['breakout', 'surge', 'crash', 'rally', 'institutional', 'adoption']
            keyword_impact = any(keyword in title for keyword in high_impact_keywords)
            
            # ê¸°ë³¸ ì˜ˆì¸¡ ê°•ë„ ê³„ì‚°
            base_magnitude = abs(current_sentiment * 5)
            
            # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì˜í–¥ë„ ì¦ê°€
            if keyword_impact:
                base_magnitude *= 1.5
            
            # ê°„ë‹¨í•œ ê°ì„± ê¸°ë°˜ ì˜ˆì¸¡
            if current_sentiment > 0.3:
                return {
                    'direction': 'positive', 
                    'magnitude': min(base_magnitude, 10),  # ìµœëŒ€ 10ìœ¼ë¡œ ì œí•œ
                    'confidence': 0.5 + (0.2 if keyword_impact else 0)
                }
            elif current_sentiment < -0.3:
                return {
                    'direction': 'negative', 
                    'magnitude': min(base_magnitude, 10),
                    'confidence': 0.5 + (0.2 if keyword_impact else 0)
                }
            else:
                return {
                    'direction': 'neutral', 
                    'magnitude': 0, 
                    'confidence': 0.3
                }
        
        # ê¸°ì¡´ ë¡œì§ (ë‰´ìŠ¤ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²½ìš°)
        similar_impacts = []
        current_sentiment = sentiment_analysis['sentiment_score']
        
        # ë‰´ìŠ¤ ì œëª©ì´ë‚˜ ë‚´ìš©ì—ì„œ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        news_title = news.get('title', '').lower()
        news_desc = news.get('description', '').lower()
        news_content = f"{news_title} {news_desc}"
        
        for correlation in self.news_correlations.values():
            sentiment_diff = abs(correlation['sentiment_score'] - current_sentiment)
            
            # ê°ì„±ë¿ë§Œ ì•„ë‹ˆë¼ ë‰´ìŠ¤ ìœ í˜•ë„ ë¹„êµ
            if sentiment_diff < 0.3:  # ìœ ì‚¬í•œ ê°ì„±
                # ë‰´ìŠ¤ ì œëª© ìœ ì‚¬ë„ë„ í™•ì¸ (ì„ íƒì )
                correlation_title = correlation.get('title', '').lower()
                
                # ê³µí†µ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ì¦ê°€
                common_keywords = ['bitcoin', 'btc', 'crypto', 'price', 'market']
                has_common_context = any(keyword in news_content and keyword in correlation_title 
                                    for keyword in common_keywords)
                
                impact = correlation.get('price_impact_6h', 0)
                if has_common_context:
                    similar_impacts.append(impact * 1.1)  # 10% ê°€ì¤‘ì¹˜ ì¦ê°€
                else:
                    similar_impacts.append(impact)
        
        if similar_impacts:
            avg_impact = sum(similar_impacts) / len(similar_impacts)
            
            # ë‰´ìŠ¤ ì†ŒìŠ¤ì˜ ì‹ ë¢°ë„ë„ ê³ ë ¤
            source = news.get('source', '').lower()
            trusted_sources = ['coindesk', 'cointelegraph', 'reuters', 'bloomberg']
            source_multiplier = 1.2 if any(trusted in source for trusted in trusted_sources) else 1.0
            
            return {
                'direction': 'positive' if avg_impact > 0 else 'negative' if avg_impact < 0 else 'neutral',
                'magnitude': abs(avg_impact) * source_multiplier,
                'confidence': min(len(similar_impacts) / 10, 1.0) * 100,
                'source_reliability': source_multiplier
            }
        
        # ìƒê´€ê´€ê³„ ë°ì´í„°ê°€ ì—†ì§€ë§Œ ë‰´ìŠ¤ ìì²´ ë¶„ì„
        return {
            'direction': 'positive' if current_sentiment > 0 else 'negative' if current_sentiment < 0 else 'neutral',
            'magnitude': abs(current_sentiment * 3),  # ë³´ìˆ˜ì  ì˜ˆì¸¡
            'confidence': 0.4,  # ì¤‘ê°„ ì‹ ë¢°ë„
            'note': 'Based on sentiment analysis only'
        }

    def _categorize_sentiment(self, sentiment_score):
        """ê°ì„± ì ìˆ˜ë¥¼ ì¹´í…Œê³ ë¦¬í™”"""
        if sentiment_score > 0.3:
            return "strongly positive"
        elif sentiment_score > 0.1:
            return "moderately positive"
        elif sentiment_score < -0.3:
            return "strongly negative"
        elif sentiment_score < -0.1:
            return "moderately negative"
        else:
            return "neutral"

    def get_pattern_based_advice(self, similar_patterns):
        """ìœ ì‚¬ íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ê±°ë˜ ì¡°ì–¸ ìƒì„±
        
        Args:
            similar_patterns: ìœ ì‚¬ íŒ¨í„´ ëª©ë¡
        
        Returns:
            dict: íŒ¨í„´ ê¸°ë°˜ ê±°ë˜ ì¡°ì–¸
        """
        if not similar_patterns:
            return {
                'recommendation': 'INSUFFICIENT_DATA',
                'confidence': 0.0,
                'reasoning': 'No similar patterns found',
                'profit_expectation': 0.0,
                'params': {
                    'profit_target': 5.0,
                    'stop_loss': -2.0,
                    'trailing_stop': 1.0
                }
            }
        
        # 1. ì™„ë£Œëœ ê±°ë˜ë§Œ í•„í„°ë§
        completed_patterns = [p for p in similar_patterns if p.get('trade_result', {}).get('completed', False)]
        
        if not completed_patterns:
            print("Warning: No completed trades in similar patterns")
            return {
                'recommendation': 'INSUFFICIENT_DATA',
                'confidence': 0.0,
                'reasoning': 'Similar patterns found but no completed trades',
                'profit_expectation': 0.0,
                'params': {
                    'profit_target': 5.0,
                    'stop_loss': -2.0,
                    'trailing_stop': 1.0
                }
            }
        
        # 2. íŒ¨í„´ í†µê³„ ê³„ì‚°
        successful_patterns = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
        failed_patterns = [p for p in completed_patterns if not p.get('trade_result', {}).get('success', False)]
        
        # ìŠ¹ë¥  ê³„ì‚°
        win_rate = len(successful_patterns) / len(completed_patterns) if completed_patterns else 0
        
        # í‰ê·  ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°
        avg_profit = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in successful_patterns) / len(successful_patterns) if successful_patterns else 0
        avg_loss = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in failed_patterns) / len(failed_patterns) if failed_patterns else 0
        
        # ê¸°ëŒ€ ìˆ˜ìµ ê³„ì‚°
        expected_profit = (win_rate * avg_profit) + ((1 - win_rate) * avg_loss)
        
        # 3. ê²°ì • ê·œì¹™
        # ìŠ¹ë¥ ì´ 50% ì´ìƒì´ê³  ê¸°ëŒ€ ìˆ˜ìµì´ ì–‘ìˆ˜ë©´ BUY
        if win_rate >= 0.5 and expected_profit > 0:
            recommendation = 'BUY'
            confidence = min(0.95, win_rate + (expected_profit / 20))  # ìµœëŒ€ 0.95
            reasoning = f"Based on {len(completed_patterns)} similar patterns with {win_rate:.0%} win rate and {expected_profit:.2f}% expected profit"
        # ìŠ¹ë¥ ì´ ë‚®ì§€ë§Œ ê¸°ëŒ€ ìˆ˜ìµì´ ë†’ì€ ê²½ìš° (ë†’ì€ ë¦¬ìŠ¤í¬/ë¦¬ì›Œë“œ)
        elif win_rate < 0.5 and expected_profit > 1.5:
            recommendation = 'BUY'
            confidence = 0.5 + (expected_profit / 30)  # ì¤‘ê°„ ì •ë„ í™•ì‹ 
            reasoning = f"High risk/reward opportunity based on {len(completed_patterns)} similar patterns with {expected_profit:.2f}% expected profit despite {win_rate:.0%} win rate"
        # ìŠ¹ë¥ ì´ ë‚®ê³  ê¸°ëŒ€ ìˆ˜ìµë„ ë‚®ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš°
        else:
            recommendation = 'HOLD'
            confidence = 0.5 + (abs(expected_profit) / 20) if expected_profit < 0 else 0.5
            reasoning = f"Avoiding risk based on {len(completed_patterns)} similar patterns with {win_rate:.0%} win rate and {expected_profit:.2f}% expected profit"
        
        # 4. ìµœì  íŒŒë¼ë¯¸í„° ê³„ì‚°
        # ìˆ˜ìµ íŒ¨í„´ì—ì„œ ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        if successful_patterns:
            # ê°€ì¥ ìˆ˜ìµì´ ì¢‹ì•˜ë˜ ìƒìœ„ 3ê°œ íŒ¨í„´ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            top_patterns = sorted(successful_patterns, key=lambda p: p.get('trade_result', {}).get('profit_pct', 0), reverse=True)[:3]
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            total_weight = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in top_patterns)
            profit_targets = []
            stop_losses = []
            trailing_stops = []
            
            for p in top_patterns:
                profit_pct = p.get('trade_result', {}).get('profit_pct', 0)
                weight = profit_pct / total_weight if total_weight > 0 else 1/len(top_patterns)
                
                # ì›ë˜ ëª©í‘œ íŒŒë¼ë¯¸í„° ì¶”ì •
                exit_reason = p.get('trade_result', {}).get('exit_reason', '')
                
                if exit_reason == 'PROFIT':
                    # ìµì ˆ ëª©í‘œëŠ” ì‹¤ì œ ìˆ˜ìµë³´ë‹¤ ì•½ê°„ ë†’ê²Œ ì„¤ì •
                    profit_targets.append((profit_pct * 1.1) * weight)
                elif exit_reason == 'TRAILING':
                    # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ì€ ì‹¤ì œ ìˆ˜ìµì˜ ë¹„ìœ¨ë¡œ ì¶”ì •
                    trailing_stops.append((profit_pct * 0.3) * weight)
                
                # ì†ì ˆë§¤ëŠ” í‰ê·  ì†ì‹¤ì—ì„œ ì¶”ì •
                if failed_patterns:
                    avg_failed = abs(sum(p.get('trade_result', {}).get('profit_pct', 0) for p in failed_patterns) / len(failed_patterns))
                    stop_losses.append(-avg_failed * 1.2 * weight)  # ì•½ê°„ ì—¬ìœ ìˆê²Œ ì„¤ì •
                else:
                    stop_losses.append(-2.0 * weight)  # ê¸°ë³¸ê°’
            
            # ìµœì¢… íŒŒë¼ë¯¸í„° ê³„ì‚°
            optimized_params = {
                'profit_target': sum(profit_targets) if profit_targets else 5.0,
                'stop_loss': sum(stop_losses) if stop_losses else -2.0,
                'trailing_stop': sum(trailing_stops) if trailing_stops else 1.0
            }
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            optimized_params = {
                'profit_target': 5.0,
                'stop_loss': -2.0,
                'trailing_stop': 1.0
            }
        
        # 5. ìµœì¢… ì¡°ì–¸ êµ¬ì„±
        advice = {
            'recommendation': recommendation,
            'confidence': confidence,
            'reasoning': reasoning,
            'win_rate': win_rate,
            'avg_profit': avg_profit,
            'avg_loss': avg_loss,
            'profit_expectation': expected_profit,
            'similar_patterns_count': len(completed_patterns),
            'params': optimized_params
        }
        
        return advice

    def save_rag_patterns(self, file_path="rag_pattern_store.pkl.gz"):
        """RAG íŒ¨í„´ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì—¬ ì €ì¥
        
        Args:
            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'document_store') or not self.document_store:
            print("Warning: No patterns to save")
            return False
        
        try:
            import pickle
            import gzip
            with gzip.open(file_path, 'wb') as f:
                pickle.dump(self.document_store, f)
            print(f"Successfully saved {len(self.document_store)} patterns to {file_path}")
            return True
        except Exception as e:
            print(f"Error saving RAG patterns: {str(e)}")
            return False

    def load_rag_patterns(self, file_path="rag_pattern_store.pkl.gz"):
        """ì €ì¥ëœ RAG íŒ¨í„´ ë°ì´í„° ë¡œë“œ
        
        Args:
            file_path: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pickle
            import gzip
            import os
            
            if not os.path.exists(file_path):
                print(f"RAG pattern file {file_path} not found")
                return False
            
            with gzip.open(file_path, 'rb') as f:
                self.document_store = pickle.load(f)
            
            print(f"Successfully loaded {len(self.document_store)} patterns from {file_path}")
            
            # íŒ¨í„´ í†µê³„ ì¶œë ¥
            completed_patterns = [p for p in self.document_store if p.get('trade_result', {}).get('completed', False)]
            successful_patterns = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
            
            if completed_patterns:
                win_rate = len(successful_patterns) / len(completed_patterns) * 100
                print(f"Pattern stats: {len(completed_patterns)} completed trades, {win_rate:.1f}% win rate")
                
                # ê°€ì¥ ì„±ê³µì ì¸ íŒ¨í„´ ì •ë³´
                if successful_patterns:
                    best_pattern = max(successful_patterns, key=lambda p: p.get('trade_result', {}).get('profit_pct', 0))
                    best_profit = best_pattern.get('trade_result', {}).get('profit_pct', 0)
                    print(f"Best pattern: {best_profit:.2f}% profit on {best_pattern.get('date', 'unknown date')}")
            
            return True
        except Exception as e:
            print(f"Error loading RAG patterns: {str(e)}")
            return False


    def _calculate_news_similarity(self, current_news, stored_news):
        """ë‰´ìŠ¤ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not current_news or not stored_news:
            return 0
        
        # í˜„ì¬ ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ
        current_keywords = set()
        for news in current_news[:3]:
            title = news.get('title', '').lower()
            keywords = ['regulation', 'etf', 'institutional', 'adoption', 'hack', 'security', 
                    'fed', 'rate', 'inflation', 'mining', 'halving', 'upgrade']
            for keyword in keywords:
                if keyword in title:
                    current_keywords.add(keyword)
        
        # ì €ì¥ëœ ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ
        stored_keywords = set()
        for news in stored_news:
            title = news.get('title', '').lower()
            for keyword in keywords:
                if keyword in title:
                    stored_keywords.add(keyword)
        
        # ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚°
        if not current_keywords and not stored_keywords:
            return 0
        
        intersection = len(current_keywords.intersection(stored_keywords))
        union = len(current_keywords.union(stored_keywords))
        
        return intersection / union if union > 0 else 0


    def find_similar_patterns(self, current_indicators, lookback_days=30, success_weight=False, time_decay=False, current_news=None): 
        """ìœ ì‚¬í•œ ê³¼ê±° íŒ¨í„´ ê²€ìƒ‰ - ì„±ê³µ íŒ¨í„´ ê°€ì¤‘ì¹˜ ê¸°ëŠ¥ ì¶”ê°€"""
        similar_contexts = []
        
        # document_storeê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì´ˆê¸°í™”
        if not hasattr(self, 'document_store') or not self.document_store:
            self.document_store = []
            return []
        
        # í˜„ì¬ ì‹œì  í™•ì¸ (ì‹œê°„ ê°€ì¤‘ì¹˜ ê³„ì‚°ìš©)
        current_date = datetime.datetime.now()
        
        # ê²€ìƒ‰ ë¡œì§ (ê¸°ì¡´ í•¨ìˆ˜ ë‚´ìš© ìœ ì§€)
        for doc in self.document_store[-lookback_days*3:]:
            similarity_score = 0
            matching_points = 0
            
            # RSI ìœ ì‚¬ë„ ì²´í¬
            if 'RSI(14)' in doc.get('indicators', {}) and 'RSI(14)' in current_indicators:
                try:
                    doc_rsi = float(str(doc['indicators']['RSI(14)']).replace(',', ''))
                    current_rsi = float(str(current_indicators['RSI(14)']).replace(',', ''))
                    rsi_diff = abs(doc_rsi - current_rsi)
                    
                    if rsi_diff < 5:
                        similarity_score += 3  # ë§¤ìš° ìœ ì‚¬
                        matching_points += 1
                    elif rsi_diff < 10:
                        similarity_score += 2  # ìœ ì‚¬
                        matching_points += 1
                    elif rsi_diff < 15:
                        similarity_score += 1  # ì•½ê°„ ìœ ì‚¬
                        matching_points += 1
                except:
                    pass
            
             # â†“ ë‰´ìŠ¤ ìœ ì‚¬ë„ ë¹„êµ ì¶”ê°€
            if current_news and doc.get('news_data'):
                news_similarity_score = self._calculate_news_similarity(current_news, doc.get('news_data', []))
                if news_similarity_score > 0.3:  # 30% ì´ìƒ ìœ ì‚¬ì‹œ
                    similarity_score += news_similarity_score * 3  # ë‰´ìŠ¤ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
                    matching_points += 1
                    print(f"ë‰´ìŠ¤ ìœ ì‚¬ë„ ë°œê²¬: {news_similarity_score:.2f}")
            
            
            
            
            # MACD ìœ ì‚¬ë„ ì²´í¬
            if 'MACD' in doc.get('indicators', {}) and 'MACD' in current_indicators:
                doc_macd = doc['indicators']['MACD']
                current_macd = current_indicators['MACD']
                
                if doc_macd == current_macd:
                    similarity_score += 2
                    matching_points += 1
                elif ("Bullish" in doc_macd and "Bullish" in current_macd) or \
                    ("Bearish" in doc_macd and "Bearish" in current_macd):
                    similarity_score += 1
                    matching_points += 1
            
            # ë³¼ë¦°ì € ë°´ë“œ ìœ ì‚¬ë„ ì²´í¬
            if 'Bollinger Bands' in doc.get('indicators', {}) and 'Bollinger Bands' in current_indicators:
                if doc['indicators']['Bollinger Bands'] == current_indicators['Bollinger Bands']:
                    similarity_score += 2
                    matching_points += 1
            
            # ì´ë™í‰ê· ì„  ìœ ì‚¬ë„ ì²´í¬
            if 'Moving Averages' in doc.get('indicators', {}) and 'Moving Averages' in current_indicators:
                if doc['indicators']['Moving Averages'] == current_indicators['Moving Averages']:
                    similarity_score += 2
                    matching_points += 1
                elif ("Price >" in doc['indicators']['Moving Averages'] and "Price >" in current_indicators['Moving Averages']) or \
                    ("Price <" in doc['indicators']['Moving Averages'] and "Price <" in current_indicators['Moving Averages']):
                    similarity_score += 1
                    matching_points += 1
            
            # ì‹œì¥ ì¶”ì„¸ ìœ ì‚¬ë„ ì²´í¬
            doc_trend = doc.get('market_trend', '')
            current_trend = self.detect_market_trend(current_indicators)
            
            if doc_trend and current_trend:
                if doc_trend == current_trend:
                    similarity_score += 3
                    matching_points += 1
                elif ("uptrend" in doc_trend and "uptrend" in current_trend) or \
                    ("downtrend" in doc_trend and "downtrend" in current_trend):
                    similarity_score += 2
                    matching_points += 1
            
            # ì§€ì§€ì„  ìœ ì‚¬ë„ ì²´í¬
            if 'support_analysis' in doc and current_indicators:
                doc_support = doc.get('support_analysis', {})
                current_price = None
                if hasattr(self, 'historical_data') and len(self.historical_data) > 0:
                    current_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close'))
                
                if current_price:
                    current_support = self._check_near_support_level_enhanced("KRW-BTC", current_price)
                    
                    # ì§€ì§€ì„  ê·¼ì²˜ ì—¬ë¶€ ë§¤ì¹­
                    if doc_support.get('is_near_support') == current_support.get('is_near_support'):
                        similarity_score += 1.5
                        matching_points += 1
                    
                    # ì§€ì§€ì„  ê°•ë„ ìœ ì‚¬ë„
                    if doc_support.get('strength') and current_support.get('strength'):
                        strength_diff = abs(doc_support['strength'] - current_support['strength'])
                        if strength_diff < 0.1:
                            similarity_score += 2
                            matching_points += 1
                        elif strength_diff < 0.2:
                            similarity_score += 1
                            matching_points += 1
            
            # ì¶”ê°€: ê±°ë˜ ê²°ê³¼ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
            if success_weight and 'trade_result' in doc:
                trade_result = doc['trade_result']
                if trade_result.get('completed', False):
                    # ì„±ê³µí•œ ê±°ë˜ì¸ ê²½ìš° ê°€ì¤‘ì¹˜ ì¦ê°€
                    if trade_result.get('success', False):
                        profit_pct = trade_result.get('profit_pct', 0)
                        # ë†’ì€ ìˆ˜ìµë¥ ì¼ìˆ˜ë¡ ë” í° ê°€ì¤‘ì¹˜
                        similarity_score *= 1.0 + min(1.0, profit_pct / 10.0)
                    # ì‹¤íŒ¨í•œ ê±°ë˜ì¸ ê²½ìš° ê°€ì¤‘ì¹˜ ê°ì†Œ
                    else:
                        similarity_score *= 0.8
            
            # ì¶”ê°€: ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
            if time_decay and 'timestamp' in doc:
                try:
                    doc_date = pd.to_datetime(doc['timestamp'])
                    days_old = (current_date - doc_date).days
                    if days_old > 0:
                        # ìµœëŒ€ 50% ê°ì†Œ (180ì¼ ì´ìƒ ì§€ë‚œ ê²½ìš°)
                        time_decay_factor = max(0.5, 1.0 - (days_old / 360.0))
                        similarity_score *= time_decay_factor
                except:
                    pass
            
            # ìœ ì‚¬ë„ê°€ ì¶©ë¶„íˆ ë†’ì€ íŒ¨í„´ë§Œ ì„ íƒ (ê¸°ì¡´ ë¡œì§)
            if matching_points >= 2 and similarity_score >= 4:
                # ê±°ë˜ ê²°ê³¼ ì •ë³´ í¬í•¨ (ìˆëŠ” ê²½ìš°)
                trade_info = {}
                if 'trade_result' in doc:
                    trade_info = {
                        'completed': doc['trade_result'].get('completed', False),
                        'success': doc['trade_result'].get('success', False),
                        'profit_pct': doc['trade_result'].get('profit_pct', 0),
                        'exit_reason': doc['trade_result'].get('exit_reason', 'Unknown')
                    }
                
                similar_contexts.append({
                    'date': doc.get('date', ''),
                    'similarity_score': similarity_score,
                    'content': doc.get('content', ''),
                    'indicators': doc.get('indicators', {}),
                    'support_analysis': doc.get('support_analysis', {}),
                    'market_trend': doc.get('market_trend', ''),
                    'trade_result': trade_info,  # ì¶”ê°€: ê±°ë˜ ê²°ê³¼ ì •ë³´
                    'pattern_id': doc.get('pattern_id', '')  # ì¶”ê°€: íŒ¨í„´ ID
                })
        
        # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬
        similar_contexts.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # ê²°ê³¼ ë¡œê¹…
        print(f"Found {len(similar_contexts)} similar patterns")
        for i, pattern in enumerate(similar_contexts[:3]):  # ìƒìœ„ 3ê°œë§Œ ë¡œê¹…
            profit_info = ""
            if 'trade_result' in pattern and pattern['trade_result'].get('completed', False):
                profit = pattern['trade_result'].get('profit_pct', 0)
                success = "Success" if pattern['trade_result'].get('success', False) else "Failure"
                profit_info = f", {success} with {profit:.2f}% profit"
            
            print(f"Pattern {i+1}: Date={pattern['date']}, Score={pattern['similarity_score']:.2f}{profit_info}")
        
        return similar_contexts[:10]  # ìƒìœ„ 10ê°œ ë°˜í™˜ (ê¸°ì¡´ 5ê°œì—ì„œ í™•ì¥)

    def store_market_pattern(self, tech_indicators, price, decision, timestamp):
        """ë§¤ìˆ˜ ì‹œì ì˜ íŒ¨í„´ ì €ì¥ (ìµœì†Œ ê¸°ëŠ¥ë§Œ êµ¬í˜„)"""
        if not hasattr(self, 'document_store'):
            self.document_store = []
        
        # íŒ¨í„´ ID ìƒì„±
        pattern_id = f"{timestamp.strftime('%Y%m%d%H%M%S')}_{hash(str(tech_indicators))}"
        
        # í˜„ì¬ ì‹œì¥ ìƒíƒœ ì €ì¥
        pattern = {
            'pattern_id': pattern_id,
            'date': timestamp.strftime('%Y-%m-%d'),
            'timestamp': timestamp,
            'indicators': tech_indicators,
            'price': price,
            'ai_decision': decision,
            'market_trend': self.detect_market_trend(tech_indicators),
            'support_analysis': self._check_near_support_level_enhanced("KRW-BTC", price),
            'trade_result': {
                'completed': False,
                'entry_price': price,
                'exit_price': None,
                'profit_pct': None,
                'success': None
            }
        }
        
        self.document_store.append(pattern)
        print(f"Stored new pattern with ID: {pattern_id}")
        return pattern_id
    
    def update_pattern_with_result(self, pattern_id, exit_price, exit_date, exit_reason):
        """ë§¤ë„ ì‹œì ì— íŒ¨í„´ ê²°ê³¼ ì—…ë°ì´íŠ¸ (ìµœì†Œ ê¸°ëŠ¥ë§Œ êµ¬í˜„)"""
        if not hasattr(self, 'document_store'):
            return False
        
        # íŒ¨í„´ ì°¾ê¸°
        for pattern in self.document_store:
            if pattern.get('pattern_id') == pattern_id:
                # ìˆ˜ìµë¥  ê³„ì‚°
                entry_price = pattern['trade_result']['entry_price']
                profit_pct = ((exit_price / entry_price) - 1) * 100
                
                # ê²°ê³¼ ì—…ë°ì´íŠ¸
                pattern['trade_result'].update({
                    'completed': True,
                    'exit_price': exit_price,
                    'exit_date': exit_date.strftime('%Y-%m-%d'),
                    'profit_pct': profit_pct,
                    'success': profit_pct > 0,
                    'exit_reason': exit_reason
                })
                
                print(f"Updated pattern {pattern_id} with result: {profit_pct:.2f}% profit, {exit_reason}")
                return True
        
        return False


    def _calculate_enhanced_support_levels(self, ticker):
        """ê°œì„ ëœ ì§€ì§€ì„  ê³„ì‚° - ì´ˆê¸° ë°ì´í„° ë¶€ì¡± ë¬¸ì œ í•´ê²°"""
        try:
            # ë°ì´í„° ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            if not hasattr(self, 'historical_data') or not self.historical_data:
                print("Warning: No historical data available for support calculation")
                return []
            
            # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ì™„í™”
            if len(self.historical_data) < 5:  # 30ì¼ â†’ 5ì¼ë¡œ ì™„í™”
                print(f"Warning: Only {len(self.historical_data)} days of data, using simple support calculation")
                # ê°„ë‹¨í•œ ì§€ì§€ì„  ê³„ì‚°
                prices = [item.get('price', item.get('close', 0)) for item in self.historical_data]
                if prices:
                    min_price = min(prices)
                    max_price = max(prices)
                    # ë‹¨ìˆœ ì§€ì§€ì„  ë°˜í™˜
                    return [min_price, min_price * 1.02, max_price * 0.98]
                return []
            
            # í†µí•© ì§€ì§€ì„ ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            support_weights = {}
            
            try:
                # 1. ê¸°ë³¸ ì§€ì§€ì„  ê³„ì‚° (ìµœê·¼ ê°€ê²© ê¸°ë°˜)
                recent_data = self.historical_data[-min(30, len(self.historical_data)):]
                temp_data = []
                for item in recent_data:
                    temp_data.append({
                        'close': item.get('close', item.get('price', 0)),
                        'open': item.get('open', item.get('close', item.get('price', 0))),
                        'high': item.get('high', item.get('close', item.get('price', 0))),
                        'low': item.get('low', item.get('close', item.get('price', 0))),
                        'volume': item.get('volume', 0)
                    })
                
                if temp_data:
                    temp_df = pd.DataFrame(temp_data)
                    standard_supports = self._calculate_standard_supports(temp_df)
                    for level in standard_supports:
                        if level > 0:  # ìœ íš¨í•œ ê°€ê²©ë§Œ
                            support_weights[level] = support_weights.get(level, 0) + 1.0
            except Exception as e:
                print(f"Error in standard support calculation: {str(e)}")
            
            try:
                # 2. ë‹¨ìˆœ ì§€ì§€ì„  (ìµœì €ê°€ ê¸°ë°˜)
                prices = [item.get('price', item.get('close', 0)) for item in self.historical_data]
                if prices:
                    min_price = min(prices)
                    recent_low = min(prices[-5:]) if len(prices) >= 5 else min_price
                    
                    # ìµœê·¼ ì €ê°€ ê·¼ì²˜ì˜ ì§€ì§€ì„ ë“¤
                    support_weights[recent_low] = support_weights.get(recent_low, 0) + 2.0
                    support_weights[recent_low * 0.98] = support_weights.get(recent_low * 0.98, 0) + 1.5
                    support_weights[recent_low * 0.95] = support_weights.get(recent_low * 0.95, 0) + 1.0
            except Exception as e:
                print(f"Error in simple support calculation: {str(e)}")
            
            try:
                # 3. ì‹¬ë¦¬ì  ì§€ì§€ì„  (ë¼ìš´ë“œ ë„˜ë²„)
                if self.historical_data:
                    current_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close', 0))
                    if current_price > 0:
                        # 1ë§Œì›, 5ë§Œì›, 10ë§Œì› ë‹¨ìœ„
                        for divisor in [10000, 50000, 100000]:
                            rounded = (int(current_price / divisor) * divisor)
                            if rounded < current_price:
                                support_weights[rounded] = support_weights.get(rounded, 0) + 1.2
            except Exception as e:
                print(f"Error in psychological support calculation: {str(e)}")
            
            # ì§€ì§€ì„ ì´ ì—†ëŠ” ê²½ìš°
            if not support_weights:
                print("Warning: No support levels calculated, using default")
                if self.historical_data:
                    try:
                        current_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close', 0))
                        if current_price > 0:
                            # ê¸°ë³¸ ì§€ì§€ì„  ìƒì„±
                            return [current_price * 0.95, current_price * 0.92, current_price * 0.90]
                    except:
                        pass
                return []
            
            # í˜„ì¬ ê°€ê²© í™•ì¸
            current_price = None
            try:
                if self.historical_data:
                    current_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close'))
            except:
                pass
            
            # ì§€ì§€ì„  ëª©ë¡ ìƒì„± (ê°€ì¤‘ì¹˜ ê¸°ì¤€ ì •ë ¬)
            weighted_supports = [(price, weight) for price, weight in support_weights.items()]
            weighted_supports.sort(key=lambda x: x[1], reverse=True)
            
            # ìƒìœ„ ì§€ì§€ì„  ì„ íƒ (ìµœëŒ€ 5ê°œ)
            top_supports = [price for price, _ in weighted_supports[:5]]
            
            # í˜„ì¬ ê°€ê²© ì´í•˜ë§Œ ìœ ì§€
            if current_price and current_price > 0:
                valid_supports = [s for s in top_supports if s <= current_price]
            else:
                valid_supports = top_supports
            
            # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì§€ì§€ì„ ì€ ë°˜í™˜
            if not valid_supports and self.historical_data:
                try:
                    last_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close', 0))
                    if last_price > 0:
                        valid_supports = [last_price * 0.95]
                except:
                    pass
            
            #if valid_supports:
                #print(f"Calculated {len(valid_supports)} support levels")
            #else:
             #   print("Warning: No valid support levels found")
            
            return valid_supports
            
        except Exception as e:
            print(f"Error in enhanced support calculation: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì§€ì§€ì„  ë°˜í™˜
            try:
                if hasattr(self, 'historical_data') and self.historical_data:
                    last_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close', 0))
                    if last_price > 0:
                        return [last_price * 0.95, last_price * 0.90]
            except:
                pass
            return []




    def calculate_enhanced_position_size(self, price, confidence, market_regime, pattern_advice, 
                                    fear_greed_index=50, balance=None, ai_decision="HOLD"):
        """ğŸš¨ ê¸´ê¸‰ ìˆ˜ì •: ì•ˆì „í•œ í¬ì§€ì…˜ ì‚¬ì´ì§• - íŒŒì‚° ë°©ì§€ + ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ìˆ˜ì •"""
        
        if balance is None:
            balance = getattr(self, 'current_balance', getattr(self, 'initial_balance', 10000000))
        
        # ğŸš¨ ê¸´ê¸‰ ì•ˆì „ì¥ì¹˜ 1: ì”ê³  ë¶€ì¡± ì²´í¬
        if balance < 10000:  # 1ë§Œì› ë¯¸ë§Œì´ë©´ ê±°ë˜ ê¸ˆì§€
            print(f"âš ï¸ ì”ê³  ë¶€ì¡±ìœ¼ë¡œ ê±°ë˜ ì¤‘ë‹¨: â‚©{balance:,.0f}")
            return 0, 0, 0, {
                'strategy_type': "ì”ê³  ë¶€ì¡±",
                'psychology_reason': "ê±°ë˜ ì¤‘ë‹¨",
                'pattern_reason': "ì•ˆì „ì¥ì¹˜ ì‘ë™"
            }
        
        if ai_decision == "BUY":
            print(f"ğŸš€ AI BUY ì‹ í˜¸ - ì•ˆì „ íˆ¬ì ëª¨ë“œ")
            
            # ğŸš¨ ê¸´ê¸‰ ìˆ˜ì •: ë§¤ìš° ë³´ìˆ˜ì ì¸ íˆ¬ì ë¹„ìœ¨
            base_investment_ratio = 0.02  # ê¸°ë³¸ 2%ë¡œ ì¶•ì†Œ
            
            # ğŸš¨ ì•ˆì „ì¥ì¹˜ 2: ìµœëŒ€ íˆ¬ì ë¹„ìœ¨ ì œí•œ
            max_investment_ratio = 0.03  # ìµœëŒ€ 3%ë¡œ ì œí•œ (ê¸°ì¡´ 5% â†’ 3%)
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì†Œí­ ì¡°ì •ë§Œ
            if confidence >= 0.8:
                confidence_multiplier = 1.2  # ê¸°ì¡´ 1.5 â†’ 1.2
            elif confidence >= 0.6:
                confidence_multiplier = 1.1  # ê¸°ì¡´ 1.2 â†’ 1.1
            else:
                confidence_multiplier = 0.9  # ê¸°ì¡´ 0.8 â†’ 0.9
            
            # Fear & Greed Index ì˜í–¥ ìµœì†Œí™”
            if fear_greed_index <= 25:
                psychology_multiplier = 1.1  # ê¸°ì¡´ 1.3 â†’ 1.1
            elif fear_greed_index >= 75:
                psychology_multiplier = 0.9  # ê¸°ì¡´ 0.8 â†’ 0.9
            else:
                psychology_multiplier = 1.0
            
            # ìµœì¢… íˆ¬ì ë¹„ìœ¨ ê³„ì‚°
            final_investment_ratio = base_investment_ratio * confidence_multiplier * psychology_multiplier
            
            # ğŸš¨ ê°•ë ¥í•œ ìƒí•œ ì œí•œ
            final_investment_ratio = min(final_investment_ratio, max_investment_ratio)
            
            # ğŸš¨ ì•ˆì „ì¥ì¹˜ 3: ì ˆëŒ€ ê¸ˆì•¡ ì²´í¬
            investment_amount = balance * final_investment_ratio
            max_absolute_amount = min(balance * 0.05, 50000)  # ìµœëŒ€ 5% ë˜ëŠ” 5ë§Œì› ì¤‘ ì‘ì€ ê°’
            
            if investment_amount > max_absolute_amount:
                investment_amount = max_absolute_amount
                final_investment_ratio = investment_amount / balance
            
            # ìµœì†Œ íˆ¬ì ê¸ˆì•¡ ì²´í¬ (ë„ˆë¬´ ì‘ìœ¼ë©´ ê±°ë˜ ì•ˆí•¨)
            if investment_amount < 1000:
                print(f"âš ï¸ íˆ¬ì ê¸ˆì•¡ ë„ˆë¬´ ì‘ìŒ: â‚©{investment_amount:,.0f}")
                return 0, 0, 0, {
                    'strategy_type': "ê¸ˆì•¡ ë¶€ì¡±",
                    'psychology_reason': "ìµœì†Œ ê¸ˆì•¡ ë¯¸ë‹¬",
                    'pattern_reason': "ê±°ë˜ ìƒëµ"
                }
            
            # ğŸš¨ ìˆ˜ì •ëœ ìˆ˜ìˆ˜ë£Œ ê³„ì‚°
            fee_rate = 0.0005
            fee = investment_amount * fee_rate
            net_investment = investment_amount - fee  # âœ… ì˜¬ë°”ë¥¸ ê³„ì‚°
            coin_amount = net_investment / price
            
            # ğŸš¨ ì´ ë¹„ìš© ê³„ì‚° (íˆ¬ìê¸ˆì•¡ + ìˆ˜ìˆ˜ë£Œ)
            total_cost = investment_amount + fee
            
            # ğŸš¨ ìµœì¢… ì•ˆì „ í™•ì¸
            if total_cost >= balance:
                print(f"ğŸš¨ ì´ ë¹„ìš©ì´ ì”ê³  ì´ˆê³¼: ë¹„ìš©=â‚©{total_cost:,.0f}, ì”ê³ =â‚©{balance:,.0f}")
                return 0, 0, 0, {
                    'strategy_type': "ë¹„ìš© ì´ˆê³¼",
                    'psychology_reason': "ì•ˆì „ì¥ì¹˜",
                    'pattern_reason': "ê±°ë˜ ì°¨ë‹¨"
                }
            
            print(f"ğŸ’° ìˆ˜ì •ëœ í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼:")
            print(f"  â”œâ”€ í˜„ì¬ ì”ê³ : â‚©{balance:,.0f}")
            print(f"  â”œâ”€ íˆ¬ì ë¹„ìœ¨: {final_investment_ratio*100:.2f}%")
            print(f"  â”œâ”€ íˆ¬ì ê¸ˆì•¡: â‚©{investment_amount:,.0f}")
            print(f"  â”œâ”€ ë§¤ìˆ˜ ìˆ˜ìˆ˜ë£Œ: â‚©{fee:,.0f}")
            print(f"  â”œâ”€ ì‹¤ì œ êµ¬ë§¤ê¸ˆì•¡: â‚©{net_investment:,.0f}")
            print(f"  â”œâ”€ ì½”ì¸ ìˆ˜ëŸ‰: {coin_amount:.8f} BTC")
            print(f"  â”œâ”€ ì´ ë¹„ìš©: â‚©{total_cost:,.0f}")
            print(f"  â””â”€ ê±°ë˜ í›„ ì”ê³ : â‚©{balance - total_cost:,.0f}")
            
            # ğŸš¨ ì¤‘ìš”: ìˆ˜ìµ ê³„ì‚°ì„ ìœ„í•œ ì •í™•í•œ ê°’ë“¤ ë°˜í™˜
            return coin_amount, total_cost, final_investment_ratio, {
                'profit_target_adjustment': 0.0,
                'stop_loss_adjustment': 0.0,
                'strategy_type': f"ì•ˆì „ íˆ¬ì {final_investment_ratio*100:.1f}%",
                'psychology_reason': f"FGI {fear_greed_index}",
                'pattern_reason': f"ì‹ ë¢°ë„ {confidence:.2f}",
                'net_investment': net_investment,  # ì‹¤ì œ êµ¬ë§¤ì— ì‚¬ìš©ëœ ê¸ˆì•¡
                'total_cost': total_cost,          # ì´ ë¹„ìš© (íˆ¬ìê¸ˆì•¡ + ìˆ˜ìˆ˜ë£Œ)
                'fee': fee                         # ìˆ˜ìˆ˜ë£Œ
            }
        
        else:
            # AIê°€ BUY ì‹ í˜¸ë¥¼ ë³´ë‚´ì§€ ì•Šì€ ê²½ìš°
            return 0, 0, 0.0, {
                'strategy_type': "AI ë¹„ë§¤ìˆ˜",
                'psychology_reason': "ëŒ€ê¸°",
                'pattern_reason': "ì‹ í˜¸ ì—†ìŒ"
            }

    def calculate_trading_statistics(self):
        """ê³¼ê±° ê±°ë˜ í†µê³„ ê³„ì‚°"""
        if not hasattr(self, 'document_store') or not self.document_store:
            return 0.5, 3.0, -2.0  # ê¸°ë³¸ê°’
        
        completed_trades = [p for p in self.document_store 
                        if p.get('trade_result', {}).get('completed', False)]
        
        if len(completed_trades) < 3:
            return 0.5, 3.0, -2.0  # ìµœì†Œ 3ê±°ë˜ ë¯¸ë§Œì‹œ ê¸°ë³¸ê°’
        
        successful_trades = [t for t in completed_trades 
                            if t.get('trade_result', {}).get('success', False)]
        failed_trades = [t for t in completed_trades 
                        if not t.get('trade_result', {}).get('success', False)]
        
        win_rate = len(successful_trades) / len(completed_trades)
        
        avg_profit = (sum(t.get('trade_result', {}).get('profit_pct', 0) 
                        for t in successful_trades) / len(successful_trades)) if successful_trades else 3.0
        
        avg_loss = (sum(t.get('trade_result', {}).get('profit_pct', 0) 
                    for t in failed_trades) / len(failed_trades)) if failed_trades else -2.0
        
        return win_rate, avg_profit, avg_loss
    
    def confirmation_candle_system(self, ai_decision, confidence, current_candle_data, 
                                next_candle_data=None, historical_context=None):
        """ë‹¤ìŒ ìº”ë“¤ë¡œ AI ì‹ í˜¸ ê²€ì¦"""
        
        if ai_decision != "BUY" or next_candle_data is None:
            return ai_decision, confidence, "ì»¨íŒ ë¶ˆí•„ìš”"
        
        # í˜„ì¬ ìº”ë“¤ ì •ë³´
        current_price = current_candle_data.get('close', 0)
        current_volume = current_candle_data.get('volume', 0)
        current_open = current_candle_data.get('open', current_price)
        
        # ë‹¤ìŒ ìº”ë“¤ ì •ë³´
        next_price = next_candle_data.get('close', 0)
        next_volume = next_candle_data.get('volume', 0)
        next_open = next_candle_data.get('open', next_price)
        next_high = next_candle_data.get('high', next_price)
        next_low = next_candle_data.get('low', next_price)
        
        # ì»¨íŒ ì¡°ê±´ë“¤ ì²´í¬
        confirmations = []
        confirmation_score = 0
        
        # 1. ìº”ë“¤ ë°©í–¥ í™•ì¸ (ì–‘ë´‰/ìŒë´‰)
        if next_price > next_open:  # ì–‘ë´‰
            confirmations.append("ì–‘ë´‰ í˜•ì„±")
            confirmation_score += 2
        elif next_price == next_open:  # ë„ì§€
            confirmations.append("ë„ì§€ í˜•ì„±")
            confirmation_score += 0.5
        else:  # ìŒë´‰
            confirmations.append("ìŒë´‰ í˜•ì„± (ë¶€ì •ì )")
            confirmation_score -= 1
        
        # 2. ê°€ê²© ìƒìŠ¹ í™•ì¸
        price_change_pct = ((next_price / current_price) - 1) * 100
        if price_change_pct > 1.0:  # 1% ì´ìƒ ìƒìŠ¹
            confirmations.append(f"ê°•í•œ ìƒìŠ¹ {price_change_pct:.1f}%")
            confirmation_score += 3
        elif price_change_pct > 0.3:  # 0.3% ì´ìƒ ìƒìŠ¹
            confirmations.append(f"ìƒìŠ¹ {price_change_pct:.1f}%")
            confirmation_score += 1
        elif price_change_pct < -0.5:  # 0.5% ì´ìƒ í•˜ë½
            confirmations.append(f"í•˜ë½ {price_change_pct:.1f}% (ë¶€ì •ì )")
            confirmation_score -= 2
        
        # 3. ê±°ë˜ëŸ‰ ì¦ê°€ í™•ì¸
        if current_volume > 0:
            volume_change = next_volume / current_volume
            if volume_change > 1.5:  # 50% ì´ìƒ ì¦ê°€
                confirmations.append(f"ê±°ë˜ëŸ‰ ê¸‰ì¦ {volume_change:.1f}x")
                confirmation_score += 2
            elif volume_change > 1.2:  # 20% ì´ìƒ ì¦ê°€
                confirmations.append(f"ê±°ë˜ëŸ‰ ì¦ê°€ {volume_change:.1f}x")
                confirmation_score += 1
            elif volume_change < 0.8:  # 20% ì´ìƒ ê°ì†Œ
                confirmations.append(f"ê±°ë˜ëŸ‰ ê°ì†Œ {volume_change:.1f}x (ë¶€ì •ì )")
                confirmation_score -= 1
        
        # 4. ìº”ë“¤ ì‹¤ì²´ í¬ê¸° í™•ì¸ (ìƒìŠ¹ ëª¨ë©˜í…€)
        candle_body_pct = abs(next_price - next_open) / next_open * 100
        if candle_body_pct > 2.0:  # 2% ì´ìƒ ì‹¤ì²´
            confirmations.append(f"í° ìº”ë“¤ ì‹¤ì²´ {candle_body_pct:.1f}%")
            confirmation_score += 1
        
        # 5. ìƒí•˜ë‹¨ ê¼¬ë¦¬ ë¶„ì„ (ë§¤ìˆ˜ ì••ë ¥)
        if next_high > 0 and next_low > 0:
            upper_shadow = (next_high - max(next_open, next_price)) / next_open * 100
            lower_shadow = (min(next_open, next_price) - next_low) / next_open * 100
            
            if lower_shadow > upper_shadow * 1.5:  # ì•„ë˜ê¼¬ë¦¬ê°€ ê¸´ ê²½ìš°
                confirmations.append("ì•„ë˜ê¼¬ë¦¬ ê¸´ ìº”ë“¤ (ë§¤ìˆ˜ ì••ë ¥)")
                confirmation_score += 1
        
        # 6. ê¸°ìˆ ì  ì§€í‘œ ì»¨íŒ (ìˆëŠ” ê²½ìš°)
        if historical_context:
            recent_rsi_trend = historical_context.get('rsi_trend', 'neutral')
            if recent_rsi_trend == 'recovering' and price_change_pct > 0:
                confirmations.append("RSI íšŒë³µ + ê°€ê²© ìƒìŠ¹")
                confirmation_score += 2
        
        # ì»¨íŒ ì—¬ë¶€ ê²°ì •
        min_score_for_confirm = 3.0  # ìµœì†Œ 3ì  ì´ìƒ
        
        if confirmation_score >= min_score_for_confirm:
            adjusted_confidence = min(0.95, confidence + 0.1)  # ì‹ ë¢°ë„ 10% ì¦ê°€
            status = "CONFIRMED_BUY"
            reason = f"ì»¨íŒ ì„±ê³µ ({confirmation_score:.1f}ì ): {', '.join(confirmations[:3])}"
            
        elif confirmation_score >= 1.0:
            adjusted_confidence = confidence
            status = "WEAK_CONFIRMED_BUY"
            reason = f"ì•½í•œ ì»¨íŒ ({confirmation_score:.1f}ì ): {', '.join(confirmations[:2])}"
            
        else:
            adjusted_confidence = max(0.2, confidence - 0.15)  # ì‹ ë¢°ë„ 15% ê°ì†Œ
            status = "UNCONFIRMED_HOLD"
            reason = f"ì»¨íŒ ì‹¤íŒ¨ ({confirmation_score:.1f}ì ): {', '.join(confirmations[:2])}"
        
        print(f"ğŸ” ì»¨íŒ ìº”ë“¤ ë¶„ì„: {status}")
        print(f"  â””â”€ {reason}")
        
        return status, adjusted_confidence, reason


    def _analyze_price_clusters(self, ticker):
        """
        ê°€ê²© ë°€ì§‘ ì˜ì—­(Price Clusters) ë¶„ì„ì„ í†µí•œ ì§€ì§€ì„  ì‹ë³„
        ë°±í…ŒìŠ¤í„°ìš©ìœ¼ë¡œ ìˆ˜ì •: historical_data í™œìš©
        
        Args:
            ticker (str): í‹°ì»¤ (ì˜ˆ: KRW-BTC)
            
        Returns:
            list: ê°€ê²© í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì§€ì§€ì„  ëª©ë¡
        """
        try:
            # ë°±í…ŒìŠ¤í„°ì—ì„œ historical_data í™œìš©
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 30:
                return []
                
            # ìµœê·¼ ë°ì´í„°ë§Œ ì‚¬ìš© (60ì¼ ìƒë‹¹)
            recent_data = self.historical_data[-60:] if len(self.historical_data) > 60 else self.historical_data
            
            # ì €ê°€ ë°ì´í„° ì¶”ì¶œ
            lows = []
            for data in recent_data:
                if 'low' in data:
                    lows.append(data['low'])
                elif 'price' in data:  # ë°±í…ŒìŠ¤í„°ì—ì„œëŠ” ë‹¨ì¼ ê°€ê²©ë§Œ ìˆì„ ìˆ˜ ìˆìŒ
                    lows.append(data['price'])
                elif 'close' in data:
                    lows.append(data['close'])
            
            if len(lows) < 30:
                return []
            
            # ê°€ê²© ë²”ìœ„ ì„¤ì •
            price_min = min(lows) * 0.95
            price_max = max(lows) * 1.05
            
            # ê°€ê²© êµ¬ê°„ ì„¤ì • (100ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°)
            num_bins = 100
            
            # numpyë¥¼ ì‚¬ìš©í•˜ì—¬ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
            import numpy as np
            hist, bin_edges = np.histogram(lows, bins=num_bins, range=(price_min, price_max))
            
            # ê°€ê²© ë¹ˆë„ í‰ê·  ë° í‘œì¤€í¸ì°¨
            mean_freq = np.mean(hist)
            std_freq = np.std(hist)
            
            # í‰ê· ë³´ë‹¤ 1.5 í‘œì¤€í¸ì°¨ ì´ìƒ ë†’ì€ ë¹ˆë„ë¥¼ ê°€ì§„ ê°€ê²©ëŒ€ë¥¼ í´ëŸ¬ìŠ¤í„°ë¡œ ì‹ë³„
            clusters = []
            for i in range(len(hist)):
                if hist[i] > mean_freq + 1.5 * std_freq:
                    # í•´ë‹¹ êµ¬ê°„ì˜ ì¤‘ê°„ ê°€ê²©ì„ í´ëŸ¬ìŠ¤í„°ë¡œ ì¶”ê°€
                    cluster_price = (bin_edges[i] + bin_edges[i+1]) / 2
                    clusters.append(cluster_price)
            
            # í˜„ì¬ ê°€ê²© í™•ì¸
            current_price = None
            if len(recent_data) > 0:
                current_data = recent_data[-1]
                if 'price' in current_data:
                    current_price = current_data['price']
                elif 'close' in current_data:
                    current_price = current_data['close']
            
            # í˜„ì¬ ê°€ê²©ë³´ë‹¤ í¬ê²Œ ë†’ì§€ ì•Šì€ í´ëŸ¬ìŠ¤í„°ë§Œ ì„ íƒ (ì§€ì§€ì„ ì€ í˜„ì¬ ê°€ê²©ë³´ë‹¤ ë‚®ì•„ì•¼ í•¨)
            valid_clusters = []
            if current_price:
                for cluster in clusters:
                    # í˜„ì¬ ê°€ê²©ì˜ 105% ì´ë‚´ì¸ ê²½ìš°ë§Œ ìœ íš¨í•œ ì§€ì§€ì„ ìœ¼ë¡œ ê°„ì£¼
                    if cluster <= current_price * 1.05:
                        valid_clusters.append(cluster)
            else:
                valid_clusters = clusters
            
            if hasattr(self, 'debug_mode') and self.debug_mode:
                print(f"{ticker} ê°€ê²© í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼: {len(valid_clusters)}ê°œ ì‹ë³„")
            
            return valid_clusters
            
        except Exception as e:
            print(f"ê°€ê²© í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _check_near_support_level_enhanced(self, ticker, current_price):
        """ê°œì„ ëœ ì§€ì§€ì„  ê·¼ì²˜ ì—¬ë¶€ í™•ì¸ - ì¡°ê±´ ì™„í™”"""
        try:
            # ê°€ê²©ì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            if not current_price or current_price <= 0:
                return {
                    'is_near_support': False,
                    'closest_support': None,
                    'distance_percent': None,
                    'strength': 0.0
                }
            
            # ì§€ì§€ì„  ê³„ì‚°
            support_levels = self._calculate_enhanced_support_levels(ticker)
            
            if not support_levels:
                # ì§€ì§€ì„ ì´ ì—†ì„ ë•Œ ê¸°ë³¸ ì§€ì§€ì„  ìƒì„±
                basic_supports = [current_price * 0.98, current_price * 0.95, current_price * 0.90]
                return {
                    'is_near_support': current_price <= basic_supports[0],  # 2% í•˜ë½ ì‹œ ì§€ì§€ì„ 
                    'closest_support': basic_supports[0],
                    'distance_percent': ((current_price / basic_supports[0]) - 1) * 100,
                    'strength': 0.3  # ê¸°ë³¸ ê°•ë„
                }
            
            # ê°€ì¥ ê°€ê¹Œìš´ ì§€ì§€ì„  ì°¾ê¸°
            closest_support = None
            min_distance = float('inf')
            
            for support in support_levels:
                if support > 0:  # ìœ íš¨í•œ ì§€ì§€ì„ ë§Œ
                    distance = abs(current_price - support) / current_price * 100
                    if distance < min_distance and support <= current_price:  # í˜„ì¬ ê°€ê²© ì´í•˜ë§Œ
                        min_distance = distance
                        closest_support = support
            
            # ê°€ì¥ ê°€ê¹Œìš´ ì§€ì§€ì„ ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš©
            if closest_support is None and support_levels:
                closest_support = min(support_levels)
                min_distance = abs(current_price - closest_support) / current_price * 100
            
            # ê±°ë¦¬ë³„ ê°•ë„ ê³„ì‚° (ì¡°ê±´ ì™„í™”)
            distance_percent = min_distance
            
            if distance_percent <= 1.0:  # 1% ì´ë‚´: ë§¤ìš° ê°•í•¨
                strength = 1.0
            elif distance_percent <= 2.0:  # 2% ì´ë‚´: ê°•í•¨
                strength = 0.8
            elif distance_percent <= 3.0:  # 3% ì´ë‚´: ì¤‘ê°„
                strength = 0.6
            elif distance_percent <= 5.0:  # 5% ì´ë‚´: ì•½í•¨
                strength = 0.4
            elif distance_percent <= 8.0:  # 8% ì´ë‚´: ë§¤ìš° ì•½í•¨ (ê¸°ì¡´ 5% â†’ 8%ë¡œ ì™„í™”)
                strength = 0.2
            else:
                strength = 0.0
            
            # ê·¼ì²˜ ì§€ì§€ì„  ì—¬ë¶€ (ì¡°ê±´ ì™„í™”: 3% â†’ 5%)
            is_near = distance_percent <= 5.0
            
            # ë‹¤ì¤‘ ì§€ì§€ì„  ì—¬ë¶€ í™•ì¸
            nearby_supports_count = 0
            if closest_support:
                for support in support_levels:
                    if support != closest_support and support > 0:
                        support_distance = abs(support - closest_support) / closest_support * 100
                        if support_distance <= 3.0:
                            nearby_supports_count += 1
            
            # ë‹¤ì¤‘ ì§€ì§€ì„  ë³´ë„ˆìŠ¤
            if nearby_supports_count >= 1:
                strength = min(1.0, strength + 0.1)  # ê°•ë„ 10% ì¦ê°€
            
            # ë””ë²„ê·¸ ë¡œê·¸
            #if is_near:
            #    print(f"Support analysis - Near: {is_near}, Price: â‚©{current_price:,.0f}, Support: â‚©{closest_support:,.0f}, Distance: {distance_percent:.2f}%, Strength: {strength:.2f}")
            
            return {
                'is_near_support': is_near,
                'closest_support': closest_support,
                'distance_percent': distance_percent,
                'strength': strength,
                'nearby_supports_count': nearby_supports_count
            }
                        
        except Exception as e:
            print(f"Error in support check: {e}")
            return {
                'is_near_support': False,
                'closest_support': None, 
                'distance_percent': None,
                'strength': 0.0
            }
        


    def _calculate_standard_supports(self, df):
        """ê¸°ë³¸ ì§€ì§€ì„  ê³„ì‚° (ë°±í…ŒìŠ¤í„°ìš©)"""
        if df is None or df.empty:
            return []
        
        try:
            # ë¡œì»¬ ë¯¸ë‹ˆë©ˆ ì°¾ê¸°
            lows = df['close'] if 'close' in df.columns else df['price']
            supports = []
            
            for i in range(2, len(lows) - 2):
                if (lows.iloc[i] < lows.iloc[i-1] and lows.iloc[i] < lows.iloc[i-2] and
                    lows.iloc[i] < lows.iloc[i+1] and lows.iloc[i] < lows.iloc[i+2]):
                    supports.append(lows.iloc[i])
            
            return supports[-5:]  # ìµœê·¼ 5ê°œë§Œ ë°˜í™˜
        except:
            return []

    def _calculate_fibonacci_levels(self, ticker):
        """í”¼ë³´ë‚˜ì¹˜ ë˜ëŒë¦¼ ë ˆë²¨ ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 20:
                return []
            
            # ìµœê·¼ 20ì¼ ë°ì´í„°ì—ì„œ ê³ ì ê³¼ ì €ì  ì°¾ê¸°
            recent_data = self.historical_data[-20:]
            
            high = max(data.get('price', data.get('close', 0)) for data in recent_data)
            low = min(data.get('price', data.get('close', 0)) for data in recent_data)
            
            if high <= low:
                return []
            
            # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚°
            fib_levels = []
            ratios = [0.236, 0.382, 0.5, 0.618, 0.786]
            
            for ratio in ratios:
                level = high - (high - low) * ratio
                fib_levels.append(level)
            
            return fib_levels
        except:
            return []

    def _calculate_volume_weighted_supports(self, ticker):
        """ê±°ë˜ëŸ‰ ê°€ì¤‘ì¹˜ ì§€ì§€ì„  ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 20:
                return []
            
            # ê±°ë˜ëŸ‰ì´ ë†’ì€ ê°€ê²©ëŒ€ ì°¾ê¸°
            recent_data = self.historical_data[-20:]
            volume_supports = []
            
            for data in recent_data:
                if 'volume' in data and data['volume'] > 0:
                    # ê±°ë˜ëŸ‰ì´ í‰ê· ì˜ 1.5ë°° ì´ìƒì¸ ê°€ê²©ì„ ì§€ì§€ì„ ìœ¼ë¡œ ê°„ì£¼
                    avg_volume = sum(d.get('volume', 0) for d in recent_data) / len(recent_data)
                    if data['volume'] > avg_volume * 1.5:
                        price = data.get('price', data.get('close', 0))
                        if price > 0:
                            volume_supports.append(price)
            
            return volume_supports[-3:]  # ìµœê·¼ 3ê°œë§Œ ë°˜í™˜
        except:
            return []

    def _calculate_strong_supports(self, ticker):
        """ê°•í•œ ì§€ì§€ì„  ê³„ì‚° (ì—¬ëŸ¬ ë²ˆ í…ŒìŠ¤íŠ¸ëœ ë ˆë²¨)"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 30:
                return []
            
            # ê°™ì€ ê°€ê²©ëŒ€ë¥¼ ì—¬ëŸ¬ ë²ˆ ê±´ë“œë¦° ë ˆë²¨ ì°¾ê¸°
            recent_data = self.historical_data[-30:]
            price_counts = {}
            
            for data in recent_data:
                price = data.get('price', data.get('close', 0))
                if price > 0:
                    # ê°€ê²©ì„ 500 ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ê·¸ë£¹í™”
                    rounded_price = round(price / 500) * 500
                    price_counts[rounded_price] = price_counts.get(rounded_price, 0) + 1
            
            # 3íšŒ ì´ìƒ í„°ì¹˜ëœ ê°€ê²©ëŒ€ë¥¼ ê°•í•œ ì§€ì§€ì„ ìœ¼ë¡œ ê°„ì£¼
            strong_supports = []
            for price, count in price_counts.items():
                if count >= 3:
                    strong_supports.append(price)
            
            return strong_supports
        except:
            return []

    def _calculate_technical_indicator_supports(self, ticker):
        """ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ì§€ì§€ì„  ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 20:
                return []
            
            # DataFrame ìƒì„±
            data_for_analysis = []
            for item in self.historical_data[-30:]:
                data_for_analysis.append({
                    'close': item.get('price', item.get('close', 0)),
                    'volume': item.get('volume', 0)
                })
            
            df = pd.DataFrame(data_for_analysis)
            supports = []
            
            # ë³¼ë¦°ì € ë°´ë“œ í•˜ë‹¨ ê³„ì‚°
            if len(df) >= 20:
                ma20 = df['close'].rolling(window=20).mean()
                std20 = df['close'].rolling(window=20).std()
                lower_band = ma20 - (std20 * 2)
                bb_support = lower_band.iloc[-1]
                supports.append(bb_support)
            
            return supports
        except:
            return []

    def _calculate_ma_supports(self, ticker):
        """ì´ë™í‰ê· ì„  ê¸°ë°˜ ì§€ì§€ì„  ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 50:
                return []
            
            # DataFrame ìƒì„±
            data_for_analysis = []
            for item in self.historical_data[-50:]:
                data_for_analysis.append({
                    'close': item.get('price', item.get('close', 0))
                })
            
            df = pd.DataFrame(data_for_analysis)
            ma_supports = []
            
            # ì£¼ìš” ì´ë™í‰ê· ì„ ë“¤
            ma_periods = [(20, 1.2), (50, 1.5)]
            
            for period, weight in ma_periods:
                if len(df) >= period:
                    ma = df['close'].rolling(window=period).mean().iloc[-1]
                    ma_supports.append((ma, weight))
            
            return ma_supports
        except:
            return []








    def detect_market_trend(self, tech_indicators):
        """ê°œì„ ëœ ì‹œì¥ íŠ¸ë Œë“œ ê°ì§€ í•¨ìˆ˜ - ë” ëª…í™•í•œ ë°©í–¥ì„± ì œì‹œ"""
        try:
            # ê¸°ìˆ ì  ì§€í‘œì—ì„œ íŠ¸ë Œë“œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            rsi_value = 50  # ê¸°ë³¸ê°’
            ma_trend = "neutral"  # ê¸°ë³¸ê°’
            volume_trend = "stable"  # ê¸°ë³¸ê°’
            price_trend = "neutral"  # ê¸°ë³¸ê°’
            
            # RSI ê°’ ì¶”ì¶œ
            for key, value in tech_indicators.items():
                if 'rsi' in key.lower():
                    try:
                        if isinstance(value, (int, float)):
                            rsi_value = float(value)
                        elif isinstance(value, str):
                            rsi_value = float(value.replace(',', ''))
                    except:
                        pass
            
            # ì´ë™í‰ê· ì„  ì •ë³´ ì¶”ì¶œ
            ma_values = {}
            for key, value in tech_indicators.items():
                if 'ma' in key.lower() or 'moving' in key.lower() or 'average' in key.lower():
                    period = 0
                    try:
                        # í‚¤ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: MA50, SMA200, EMA20 ë“±)
                        for part in key.split():
                            if any(char.isdigit() for char in part):
                                period_str = ''.join(filter(str.isdigit, part))
                                period = int(period_str)
                                break
                        
                        # ê°’ ë³€í™˜
                        if isinstance(value, (int, float)):
                            ma_values[period] = float(value)
                        elif isinstance(value, str) and value.replace('.', '', 1).replace(',', '').isdigit():
                            ma_values[period] = float(value.replace(',', ''))
                    except:
                        pass
            
            # ì´ë™í‰ê· ì„  ê¸°ë°˜ íŠ¸ë Œë“œ ê³„ì‚°
            if len(ma_values) >= 2:
                # ë‹¨ê¸°(50ì¼ ì´í•˜) vs ì¥ê¸°(50ì¼ ì´ˆê³¼) ì´ë™í‰ê· ì„  ë¹„êµ
                short_mas = {k: v for k, v in ma_values.items() if k <= 50}
                long_mas = {k: v for k, v in ma_values.items() if k > 50}
                
                if short_mas and long_mas:
                    short_ma = sum(short_mas.values()) / len(short_mas)
                    long_ma = sum(long_mas.values()) / len(long_mas)
                    
                    if short_ma > long_ma * 1.02:  # 2% ì´ìƒ ë†’ì„ ë•Œ
                        ma_trend = "strong uptrend"
                    elif short_ma > long_ma:
                        ma_trend = "uptrend"
                    elif short_ma < long_ma * 0.98:  # 2% ì´ìƒ ë‚®ì„ ë•Œ
                        ma_trend = "strong downtrend"
                    elif short_ma < long_ma:
                        ma_trend = "downtrend"
                    else:
                        ma_trend = "consolidation"
            
            # ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ì¶”ì¶œ
            for key, value in tech_indicators.items():
                if 'volume' in key.lower() or 'vol' in key.lower():
                    if isinstance(value, str):
                        if 'increasing' in value.lower() or 'up' in value.lower():
                            volume_trend = "increasing"
                        elif 'decreasing' in value.lower() or 'down' in value.lower():
                            volume_trend = "decreasing"
                        elif 'high' in value.lower():
                            volume_trend = "high"
                        elif 'low' in value.lower():
                            volume_trend = "low"
                    break
            
            # ê°€ê²© íŠ¸ë Œë“œ ì •ë³´ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
            for key, value in tech_indicators.items():
                if 'trend' in key.lower() or 'direction' in key.lower():
                    if isinstance(value, str):
                        if 'up' in value.lower() or 'bull' in value.lower() or 'positive' in value.lower():
                            price_trend = "uptrend"
                        elif 'down' in value.lower() or 'bear' in value.lower() or 'negative' in value.lower():
                            price_trend = "downtrend"
                        elif 'sideways' in value.lower() or 'consolidation' in value.lower() or 'neutral' in value.lower():
                            price_trend = "sideways"
                    break
            
            # ì¶”ê°€ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ìµœê·¼ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ íŠ¸ë Œë“œ ì¶”ì¶œ
            recent_price_changes = []
            if hasattr(self, 'backtest_results') and len(self.backtest_results) > 3:
                for i in range(1, min(6, len(self.backtest_results))):
                    if 'price' in self.backtest_results[i] and 'price' in self.backtest_results[i-1]:
                        try:
                            daily_change = ((self.backtest_results[i]['price'] / self.backtest_results[i-1]['price']) - 1) * 100
                            recent_price_changes.append(daily_change)
                        except:
                            pass
            
            # ìµœê·¼ ê°€ê²© ë³€í™”ë¡œ íŠ¸ë Œë“œ íŒë‹¨
            if recent_price_changes:
                avg_change = sum(recent_price_changes) / len(recent_price_changes)
                up_days = sum(1 for change in recent_price_changes if change > 0)
                down_days = sum(1 for change in recent_price_changes if change < 0)
                
                if avg_change > 1.5:
                    price_trend = "strong uptrend"
                elif avg_change > 0.3 and up_days > down_days:
                    price_trend = "uptrend"
                elif avg_change < -1.5:
                    price_trend = "strong downtrend"
                elif avg_change < -0.3 and down_days > up_days:
                    price_trend = "downtrend"
                elif abs(avg_change) <= 0.3:
                    price_trend = "sideways"
            
            # ìµœì¢… íŠ¸ë Œë“œ íŒë‹¨
            if price_trend != "neutral":
                # ê°€ê²© íŠ¸ë Œë“œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ìš°ì„ ì‹œ
                primary_trend = price_trend
            elif ma_trend != "neutral":
                # ì´ë™í‰ê· ì„  íŠ¸ë Œë“œ ì •ë³´ ì‚¬ìš©
                primary_trend = ma_trend
            else:
                # RSI ê¸°ë°˜ íŒë‹¨
                if rsi_value > 70:
                    primary_trend = "potentially overbought"
                elif rsi_value > 60:
                    primary_trend = "bullish"
                elif rsi_value < 30:
                    primary_trend = "potentially oversold"
                elif rsi_value < 40:
                    primary_trend = "bearish"
                else:
                    primary_trend = "neutral"
            
            # ë³¼ë¥¨ ì •ë³´ ê²°í•©
            if volume_trend == "increasing" and "uptrend" in primary_trend:
                trend = f"{primary_trend} with increasing volume (strong bullish signal)"
            elif volume_trend == "decreasing" and "downtrend" in primary_trend:
                trend = f"{primary_trend} with decreasing volume (potential reversal)"
            elif volume_trend == "increasing" and "downtrend" in primary_trend:
                trend = f"{primary_trend} with increasing volume (strong bearish signal)"
            elif volume_trend == "decreasing" and "uptrend" in primary_trend:
                trend = f"{primary_trend} with decreasing volume (weakening momentum)"
            elif volume_trend == "high":
                trend = f"{primary_trend} with high volume (strong conviction)"
            elif volume_trend == "low":
                trend = f"{primary_trend} with low volume (weak conviction)"
            else:
                trend = primary_trend
            
            # RSI ìƒíƒœ ì¶”ê°€
            if rsi_value > 70 and "overbought" not in trend:
                trend += f" with overbought RSI ({rsi_value:.1f})"
            elif rsi_value < 30 and "oversold" not in trend:
                trend += f" with oversold RSI ({rsi_value:.1f})"
            
            return trend
        
        except Exception as e:
            print(f"Error detecting market trend: {str(e)}")
            return "Unknown market trend (insufficient data)"


    def __del__(self):
        """
        ê°ì²´ ì†Œë©¸ ì‹œ ì…€ë ˆë‹ˆì›€ ë“œë¼ì´ë²„ ì¢…ë£Œ
        """
        if self.selenium_driver is not None:
            try:
                self.selenium_driver.quit()
                print("Selenium driver closed")
            except:
                pass

    def _filter_news_for_timestamp(self, news_list, timestamp):
        """
        íŠ¹ì • íƒ€ì„ìŠ¤íƒ¬í”„ ì‹œì ì˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
        
        Args:
            news_list: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            timestamp: ê¸°ì¤€ íƒ€ì„ìŠ¤íƒ¬í”„
            
        Returns:
            list: í•„í„°ë§ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        relevant_news = []
        timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
        if isinstance(timestamp, str):
            timestamp = pd.to_datetime(timestamp)
        
        # íƒ€ì„ì¡´ ì²˜ë¦¬ - naive ê°ì²´ë¡œ í†µì¼
        if hasattr(timestamp, 'tz') and timestamp.tz is not None:
            timestamp = timestamp.tz_localize(None)
        
        # ë‰´ìŠ¤ í•„í„°ë§ - íŠ¹ì • ìº”ë“¤ ì‹œì ì— ê´€ë ¨ëœ ë‰´ìŠ¤ë§Œ ì„ íƒ
        # 1. ìº”ë“¤ ì‹œì  ì´ì „ 6ì‹œê°„ ë‚´ì— ë°œí–‰ëœ ë‰´ìŠ¤
        # 2. ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì´ì „ ë‚ ì§œì˜ ì¤‘ìš” ë‰´ìŠ¤
        for news in news_list:
            try:
                # ë‰´ìŠ¤ ë°œí–‰ ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜
                news_time = pd.to_datetime(news.get('publishedAt', ''))
                
                # íƒ€ì„ì¡´ ì²˜ë¦¬
                if hasattr(news_time, 'tz') and news_time.tz is not None:
                    news_time = news_time.tz_localize(None)
                
                # í˜„ì¬ ìº”ë“¤ ì‹œì  ì´ì „ 6ì‹œê°„ ì´ë‚´ì˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
                if news_time <= timestamp and news_time >= (timestamp - datetime.timedelta(hours=6)):
                    relevant_news.append(news)
                    
                # ë˜ëŠ” ê°ì„± ì ìˆ˜ê°€ ë†’ì€ ì¤‘ìš” ë‰´ìŠ¤ëŠ” 24ì‹œê°„ê¹Œì§€ í—ˆìš©
                elif (
                    news_time <= timestamp and 
                    news_time >= (timestamp - datetime.timedelta(hours=24)) and
                    abs(news.get('sentiment_score', 0)) > 0.6  # ê°ì„± ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                ):
                    relevant_news.append(news)
            except Exception as e:
                print(f"ë‰´ìŠ¤ í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        print(f"íƒ€ì„ìŠ¤íƒ¬í”„ {timestamp_str}ì— ëŒ€í•´ {len(relevant_news)}ê°œ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§ë¨")
        return relevant_news



    def _update_news_correlation(self, news_list, price_data, current_timestamp):
        """ë‰´ìŠ¤-ê°€ê²© ìƒê´€ê´€ê³„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ - ë””ë²„ê¹… ê°œì„ """
        if not hasattr(self, 'news_correlations'):
            self.news_correlations = {}
            print("news_correlations ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”")
        
        updated_correlations = 0
        
        print(f"ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œì‘: {len(news_list)}ê°œ ë‰´ìŠ¤, {len(price_data)}ê°œ ê°€ê²© ë°ì´í„°")
        
        for i, news in enumerate(news_list):
            try:
                # ë‰´ìŠ¤ ì‹ë³„ì ìƒì„±
                news_id = news.get('url', str(hash(news.get('title', ''))))
                
                # ì´ë¯¸ ë¶„ì„ëœ ë‰´ìŠ¤ëŠ” ê±´ë„ˆëœ€
                if news_id in self.news_correlations:
                    print(f"ì´ë¯¸ ë¶„ì„ëœ ë‰´ìŠ¤ ê±´ë„ˆëœ€: {news['title'][:30]}...")
                    continue
                
                # ë‰´ìŠ¤ ë°œìƒ ì‹œê°„
                news_time = pd.to_datetime(news.get('publishedAt', ''))
                
                # íƒ€ì„ì¡´ ì²˜ë¦¬
                if hasattr(news_time, 'tz') and news_time.tz is not None:
                    news_time = news_time.tz_localize(None)
                
                # ë‰´ìŠ¤ ê°ì„± ë¶„ì„
                print(f"ë‰´ìŠ¤ {i+1}/{len(news_list)} ê°ì„± ë¶„ì„ ì¤‘...")
                sentiment = self.analyze_news_sentiment([news])
                print(f"ê°ì„± ì ìˆ˜: {sentiment.get('sentiment_score', 0)}")
                
                # ê°€ê²© ì˜í–¥ ê³„ì‚° (1ì‹œê°„, 6ì‹œê°„, 24ì‹œê°„ ì´í›„)
                price_impacts = self._calculate_price_impacts_after_news(news_time, price_data)
                impact_str = ", ".join([f"{k}: {v:.2f}%" for k, v in price_impacts.items()])
                print(f"ê°€ê²© ì˜í–¥: {impact_str if impact_str else 'ë°ì´í„° ì—†ìŒ'}")
                
                # ë‰´ìŠ¤ ì£¼ì œ ì‹ë³„ 
                key_topics = sentiment.get('key_topics', [])
                
                # ìƒê´€ê´€ê³„ ì •ë³´ ì €ì¥
                self.news_correlations[news_id] = {
                    'news_id': news_id,
                    'timestamp': news_time.isoformat(),
                    'title': news.get('title', ''),
                    'sentiment_score': sentiment.get('sentiment_score', 0),
                    'themes': key_topics,
                    'price_impact_1h': price_impacts.get('1h', 0),
                    'price_impact_6h': price_impacts.get('6h', 0), 
                    'price_impact_24h': price_impacts.get('24h', 0),
                    'volume_impact': price_impacts.get('volume', 0),
                    'last_updated': current_timestamp.isoformat()
                }
                
                updated_correlations += 1
                print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë°ì´í„° ì¶”ê°€: {news['title'][:30]}...")
                
                # ì¤‘ê°„ ì €ì¥ (10ê°œë§ˆë‹¤)
                if updated_correlations % 10 == 0:
                    self.save_news_correlations()
                    print(f"ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {len(self.news_correlations)}ê°œ ìƒê´€ê´€ê³„ ë°ì´í„°")
                
            except Exception as e:
                print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        if updated_correlations > 0:
            print(f"{updated_correlations}ê°œ ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            # ìµœì¢… ì €ì¥
            self.save_news_correlations()
        
        return self.news_correlations



    def _filter_news_for_timestamp(self, news_list, timestamp):
        """íŠ¹ì • íƒ€ì„ìŠ¤íƒ¬í”„ ì‹œì ì˜ ë‰´ìŠ¤ í•„í„°ë§ - ì™„í™”ëœ ì¡°ê±´"""
        relevant_news = []
        timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜ ë° íƒ€ì„ì¡´ ì²˜ë¦¬
        if isinstance(timestamp, str):
            timestamp = pd.to_datetime(timestamp)
        if hasattr(timestamp, 'tz') and timestamp.tz is not None:
            timestamp = timestamp.tz_localize(None)
        
        # í•„í„°ë§ ì‹œê°„ ë²”ìœ„ í™•ì¥: ì´ì „ 12ì‹œê°„ + ì´í›„ 1ì‹œê°„
        window_start = timestamp - datetime.timedelta(hours=12)
        window_end = timestamp + datetime.timedelta(hours=1)
        
        print(f"ë‰´ìŠ¤ í•„í„°ë§ ì‹œê°„ ë²”ìœ„: {window_start} ~ {window_end}")
        
        # ë‰´ìŠ¤ í•„í„°ë§ - ì‹œê°„ ë²”ìœ„ ë‚´ì˜ ëª¨ë“  ë‰´ìŠ¤ í¬í•¨
        for news in news_list:
            try:
                # ë‰´ìŠ¤ ë°œí–‰ ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜
                news_time = pd.to_datetime(news.get('publishedAt', ''))
                
                # íƒ€ì„ì¡´ ì²˜ë¦¬
                if hasattr(news_time, 'tz') and news_time.tz is not None:
                    news_time = news_time.tz_localize(None)
                
                # ì‹œê°„ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                if window_start <= news_time <= window_end:
                    # ë‰´ìŠ¤ íƒ€ì´í‹€ì´ ìˆëŠ”ì§€ í™•ì¸
                    if 'title' in news and news['title']:
                        relevant_news.append(news)
                        print(f"ê´€ë ¨ ë‰´ìŠ¤ ì¶”ê°€: {news['title'][:50]}... ({news_time})")
                
            except Exception as e:
                print(f"ë‰´ìŠ¤ í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ê´€ë ¨ ë‰´ìŠ¤ê°€ ë¶€ì¡±í•˜ë©´ ìµœì‹  5ê°œ ë‰´ìŠ¤ ì¶”ê°€
        if len(relevant_news) < 5:
            print(f"ê´€ë ¨ ë‰´ìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì‹  ë‰´ìŠ¤ ì¶”ê°€...")
            
            # ëª¨ë“  ë‰´ìŠ¤ë¥¼ ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
            sorted_news = sorted(
                [n for n in news_list if 'publishedAt' in n], 
                key=lambda x: pd.to_datetime(x['publishedAt']), 
                reverse=True
            )
            
            # ì´ë¯¸ ì¶”ê°€ëœ ë‰´ìŠ¤ ì œì™¸í•˜ê³  ìµœì‹  5ê°œ ì¶”ê°€
            added_titles = set(n['title'] for n in relevant_news)
            for news in sorted_news:
                if news['title'] not in added_titles and len(relevant_news) < 5:
                    relevant_news.append(news)
                    print(f"ìµœì‹  ë‰´ìŠ¤ ì¶”ê°€: {news['title'][:50]}...")
                    added_titles.add(news['title'])
        
        print(f"íƒ€ì„ìŠ¤íƒ¬í”„ {timestamp_str}ì— ëŒ€í•´ {len(relevant_news)}ê°œ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§ë¨")
        return relevant_news


    def fetch_news_from_dataset(self, coin, date_from, date_to):
        """
        ë‹¤ì¤‘ ë°ì´í„°ì…‹ì—ì„œ ì•”í˜¸í™”í ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
        """
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        cache_path = self.get_news_cache_path(coin, date_from, date_to)
        print(f"Cache path: {cache_path}")
        
        # ìºì‹œ í™•ì¸
        if os.path.exists(cache_path):
            print(f"Cache file exists. Size: {os.path.getsize(cache_path)} bytes")
            with open(cache_path, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"Cache content preview: {content[:100]}")
                # ì „ì²´ ë‚´ìš©ì„ ë‹¤ì‹œ ì½ì–´ì„œ íŒŒì‹±
                f.seek(0)
                cached_data = json.load(f)
                print(f"Cached data count: {len(cached_data)}")
                
                # ìºì‹œëœ ë°ì´í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°ì—ë§Œ ë°˜í™˜
                min_required_news = 20
                if len(cached_data) >= min_required_news:
                    return cached_data
                else:
                    print(f"Cache has insufficient data ({len(cached_data)} < {min_required_news}), regenerating...")
        
        print(f"Available handlers: {len(self.news_handlers)}")
        
        # ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
        all_news = []
        for handler in self.news_handlers:
            news_list = handler.get_news_for_date_range(date_from, date_to)
            all_news.extend(news_list)
        
        print(f"All news collected: {len(all_news)}")
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        seen_urls = set()
        unique_news = []
        for news in all_news:
            # URLì´ ì—†ìœ¼ë©´ ì œëª©ê³¼ ë‚´ìš©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
            news_id = news.get('url', news.get('title', '') + news.get('description', ''))
            if news_id not in seen_urls:
                seen_urls.add(news_id)
                unique_news.append(news)
        
        print(f"Unique news: {len(unique_news)}")
        
        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        unique_news.sort(key=lambda x: x.get("publishedAt", ""))
        
        # ìµœì†Œ í•„ìš” ë‰´ìŠ¤ ìˆ˜ ì„¤ì •
        min_required_news = 20
        print(f"Minimum required news: {min_required_news}")
        
        # ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ì„ì‹œ ë‰´ìŠ¤ ìƒì„±
        if len(unique_news) < min_required_news:
            print(f"WARNING: Insufficient news found: only {len(unique_news)} articles. Creating placeholder news.")
            
            # ì„ì‹œ ë‰´ìŠ¤ ìƒì„±
            placeholder_news = []
            for i in range(min_required_news - len(unique_news)):
                placeholder_news.append({
                    "title": f"Placeholder Bitcoin News #{i+1}",
                    "url": f"https://example.com/news/{i+1}",
                    "description": f"Placeholder description for Bitcoin news #{i+1}",
                    "source": "Placeholder",
                    "publishedAt": date_from.strftime("%Y-%m-%dT%H:%M:%SZ")
                })
            
            unique_news.extend(placeholder_news)
            print(f"Added {len(placeholder_news)} placeholder news articles")
        
        print(f"Final news count: {len(unique_news)}")
        
        # ìºì‹œì— ì €ì¥
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(unique_news, f, ensure_ascii=False, indent=2)
            print(f"Saved {len(unique_news)} news articles to cache")
            
        return unique_news
    
    def fetch_news_from_api(self, coin, date_from, date_to):
        """
        CryptoCompare APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•”í˜¸í™”í ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „)
        """
        import requests
        import os
        from datetime import datetime, timedelta
        
        print("CryptoCompare APIì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œë„ ì¤‘...")
        
        # API í‚¤ ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ ë³€ìˆ˜ì—ì„œ)
        api_key = os.getenv("CRYPTOCOMPARE_API_KEY")
        if not api_key:
            print("CryptoCompare API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return []
        
        news_list = []
        try:
            # ì½”ì¸ ì‹¬ë³¼ ì²˜ë¦¬
            if isinstance(coin, str):
                if coin.startswith("KRW-"):
                    search_symbol = coin.split("-")[1]  # KRW-BTC -> BTC
                else:
                    search_symbol = coin
            else:
                search_symbol = str(coin)
                
            # CryptoCompare ë‰´ìŠ¤ API ì—”ë“œí¬ì¸íŠ¸
            url = "https://min-api.cryptocompare.com/data/v2/news/"
            
            # ìš”ì²­ íŒŒë¼ë¯¸í„° (ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¼ë°˜ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°)
            params = {
                'api_key': api_key,
                'lang': 'EN',                # ì˜ì–´ ë‰´ìŠ¤ë§Œ
                'sortOrder': 'latest',       # ìµœì‹ ìˆœ ì •ë ¬
                'feeds': 'cryptocompare,cointelegraph,coindesk'  # ì£¼ìš” ë‰´ìŠ¤ ì†ŒìŠ¤ë¡œ ì œí•œ
            }
            
            # API ìš”ì²­ ë° ì‘ë‹µ ë””ë²„ê¹…
            response = requests.get(url, params=params)
            print(f"API ìš”ì²­ URL: {response.url}")
            print(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                # ì‘ë‹µ ë°ì´í„° êµ¬ì¡° ë””ë²„ê¹…
                if 'Response' in data:
                    print(f"API ì‘ë‹µ ìƒíƒœ: {data['Response']}")
                if 'Message' in data:
                    print(f"API ë©”ì‹œì§€: {data['Message']}")
                if 'Data' in data:
                    print(f"ë°›ì€ ë‰´ìŠ¤ ìˆ˜: {len(data['Data'])}")
                    articles = data['Data']
                    
                    # ê° ê¸°ì‚¬ ì •ë³´ ì¶”ì¶œ
                    for article in articles:
                        # ê¸°ì‚¬ ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì½”ì¸ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
                        title = article.get('title', '').lower()
                        body = article.get('body', '').lower()
                        categories = article.get('categories', '').lower()
                        
                        # í•´ë‹¹ ì½”ì¸ ê´€ë ¨ ë‰´ìŠ¤ì¸ì§€ í™•ì¸ (ì œëª©, ë‚´ìš©, ì¹´í…Œê³ ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°)
                        coin_keywords = [search_symbol.lower(), 'bitcoin', 'btc', 'crypto', 'cryptocurrency']
                        is_relevant = False
                        for keyword in coin_keywords:
                            if keyword in title or keyword in body or keyword in categories:
                                is_relevant = True
                                break
                                
                        if not is_relevant:
                            continue  # ê´€ë ¨ ì—†ëŠ” ë‰´ìŠ¤ëŠ” ê±´ë„ˆë›°ê¸°
                        
                        # ë‚ ì§œ ì²˜ë¦¬
                        article_date = datetime.fromtimestamp(article.get('published_on', 0))
                        
                        # í˜„ì¬ ë°±í…ŒìŠ¤íŠ¸ëŠ” ê³¼ê±° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ ë¶€ë¶„ì€ ë¬´ì‹œí•˜ê³  ëª¨ë“  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                        # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ í™œì„±í™”
                        # if not (date_from <= article_date <= date_to):
                        #    continue
                        
                        # ê¸°ì‚¬ ì •ë³´ í¬ë§·íŒ…
                        news_item = {
                            'title': article.get('title', ''),
                            'description': article.get('body', '')[:200] + '...' if article.get('body') else '',
                            'publishedAt': article_date.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            'source': article.get('source_info', {}).get('name', 'CryptoCompare'),
                            'url': article.get('url', ''),
                            'categories': article.get('categories', ''),
                            'tags': article.get('tags', ''),
                            'from_api': True
                        }
                        news_list.append(news_item)
                    
                    print(f"CryptoCompare APIì—ì„œ {len(news_list)}ê°œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                else:
                    print("CryptoCompare API ì‘ë‹µì— 'Data' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"ì‘ë‹µ ë‚´ìš©: {data}")
            else:
                print(f"CryptoCompare API ìš”ì²­ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")
                print(f"ì‘ë‹µ: {response.text}")
        
        except Exception as e:
            print(f"CryptoCompare API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            print(traceback.format_exc())
        
        return news_list
    
    
    def _get_historical_news_cases(self, similar_patterns):
        """ê³¼ê±° ìœ ì‚¬ ë‰´ìŠ¤ ì‚¬ë¡€ ì¶”ì¶œ"""
        if not similar_patterns:
            return "No historical news cases found."
        
        cases = []
        for pattern in similar_patterns[:3]:  # ìƒìœ„ 3ê°œë§Œ
            if pattern.get('news_data') and pattern.get('trade_result', {}).get('completed'):
                news_summary = pattern.get('news_summary', '')
                profit = pattern.get('trade_result', {}).get('profit_pct', 0)
                date = pattern.get('date', '')
                
                if news_summary:
                    cases.append(f"â€¢ {date}: '{news_summary}' â†’ {profit:+.1f}% result")
        
        return "\n".join(cases) if cases else "No completed news cases found."



    def _analyze_article_sentiment(self, article):
        """
        ê¸°ì‚¬ ë‚´ìš©ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°ì„± ë¶„ì„ ìˆ˜í–‰
        """
        # ê¸°ì‚¬ ìì²´ì— ê°ì„± ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš° í™œìš©
        if 'sentiment' in article:
            return {
                'sentiment_score': article.get('sentiment', 0),
                'sentiment_type': 'positive' if article.get('sentiment', 0) > 0 else 
                                ('negative' if article.get('sentiment', 0) < 0 else 'neutral'),
                'impact_level': 'high' if abs(article.get('sentiment', 0)) > 0.5 else 
                            ('medium' if abs(article.get('sentiment', 0)) > 0.2 else 'low')
            }
        
        # ìì²´ ê°ì„± ë¶„ì„ ë¡œì§ (í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ êµ¬í˜„)
        title = article.get('title', '').lower()
        body = article.get('body', '').lower()
        
        positive_keywords = ['bull', 'bullish', 'surge', 'soar', 'rally', 'gain', 'grow', 'rise', 'positive', 'adoption']
        negative_keywords = ['bear', 'bearish', 'crash', 'fall', 'drop', 'decline', 'dump', 'negative', 'ban', 'regulation']
        
        sentiment_score = 0
        for keyword in positive_keywords:
            if keyword in title:
                sentiment_score += 0.2
            elif keyword in body:
                sentiment_score += 0.1
                
        for keyword in negative_keywords:
            if keyword in title:
                sentiment_score -= 0.2
            elif keyword in body:
                sentiment_score -= 0.1
        
        # ê°ì„± ì ìˆ˜ ë²”ìœ„ ì œí•œ (-1 ~ 1)
        sentiment_score = max(-1, min(1, sentiment_score))
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_type': 'positive' if sentiment_score > 0 else 
                            ('negative' if sentiment_score < 0 else 'neutral'),
            'impact_level': 'high' if abs(sentiment_score) > 0.5 else 
                        ('medium' if abs(sentiment_score) > 0.2 else 'low')
        }
    
    def fetch_historical_data(self, ticker, interval="day", count=100, to=None):
        """
        Fetch historical OHLCV data from Upbit and store in self.historical_data
        """
        try:
            if to:
                df = pyupbit.get_ohlcv(ticker, interval=interval, count=count, to=to)
            else:
                df = pyupbit.get_ohlcv(ticker, interval=interval, count=count)
            
            if df is not None and not df.empty:
                # ===== ì¤‘ìš” ì¶”ê°€: DataFrameì„ self.historical_dataì— ì €ì¥ =====
                self.historical_data = []  # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
                
                for timestamp, row in df.iterrows():
                    data_point = {
                        'date': timestamp.strftime('%Y-%m-%d'),
                        'datetime': timestamp,
                        'price': row['close'],
                        'close': row['close'],
                        'open': row['open'],
                        'high': row['high'],
                        'low': row['low'],
                        'volume': row['volume']
                    }
                    self.historical_data.append(data_point)
                
                print(f"Historical data stored: {len(self.historical_data)} records")
                
                # ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€
                if isinstance(df.index[0], pd.Timestamp):
                    df['date'] = df.index.strftime('%Y-%m-%d')
                
                return df
            else:
                print(f"Error fetching data for {ticker}: Empty dataframe returned")
                return None
        except Exception as e:
            print(f"Error fetching data for {ticker}: {str(e)}")
            return None

    def calculate_technical_indicators(self, df):
        """
        Calculate technical indicators for the given dataframe
        
        # ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•œ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        """
        if df is None or df.empty:
            return None, {}
        
        # ì…ë ¥ ë°ì´í„° í™•ì¸ ë° ì „ì²˜ë¦¬
        try:
            # 'close' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
            if 'close' not in df.columns:
                if 'price' in df.columns:
                    df['close'] = df['price']
                elif 'Close' in df.columns:
                    df['close'] = df['Close']
                else:
                    # ë°ì´í„°ê°€ ë‹¨ì¼ ì‹œë¦¬ì¦ˆì¸ ê²½ìš°
                    if isinstance(df, pd.Series):
                        df = pd.DataFrame(df)
                        df.columns = ['close']
                    else:
                        print("Cannot find price data for technical indicators")
                        return df, {}
        except Exception as e:
            print(f"Error preprocessing data for technical indicators: {str(e)}")
            return df, {}
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        tech_indicators = {}
        
        try:
            # RSI ê³„ì‚°
            delta = df['close'].diff()
            gain = delta.clip(lower=0).rolling(window=14).mean()
            loss = abs(delta.clip(upper=0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            if not pd.isna(rsi.iloc[-1]):
                tech_indicators["RSI(14)"] = round(rsi.iloc[-1], 2)
        except Exception as e:
            print(f"Error calculating RSI: {str(e)}")
        
        try:
            # MACD ê³„ì‚°
            exp1 = df['close'].ewm(span=12, adjust=False).mean()
            exp2 = df['close'].ewm(span=26, adjust=False).mean()
            macd = exp1 - exp2
            signal = macd.ewm(span=9, adjust=False).mean()
            
            if not (pd.isna(macd.iloc[-1]) or pd.isna(signal.iloc[-1])):
                if macd.iloc[-1] > signal.iloc[-1] and macd.iloc[-2] <= signal.iloc[-2]:
                    tech_indicators["MACD"] = "Bullish crossover (12, 26, 9)"
                elif macd.iloc[-1] < signal.iloc[-1] and macd.iloc[-2] >= signal.iloc[-2]:
                    tech_indicators["MACD"] = "Bearish crossover (12, 26, 9)"
                elif macd.iloc[-1] > signal.iloc[-1]:
                    tech_indicators["MACD"] = "Bullish (above signal line)"
                else:
                    tech_indicators["MACD"] = "Bearish (below signal line)"
        except Exception as e:
            print(f"Error calculating MACD: {str(e)}")
        
        try:
            # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
            ma20 = df['close'].rolling(window=20).mean()
            std20 = df['close'].rolling(window=20).std()
            upper_band = ma20 + (std20 * 2)
            lower_band = ma20 - (std20 * 2)
            
            if len(df) >= 20 and not pd.isna(ma20.iloc[-1]):
                current_close = df['close'].iloc[-1]
                if current_close >= upper_band.iloc[-1] * 0.98:
                    tech_indicators["Bollinger Bands"] = "Near upper band"
                elif current_close <= lower_band.iloc[-1] * 1.02:
                    tech_indicators["Bollinger Bands"] = "Near lower band"
                else:
                    tech_indicators["Bollinger Bands"] = "Between bands"
        except Exception as e:
            print(f"Error calculating Bollinger Bands: {str(e)}")
        
        try:
            # ì´ë™í‰ê· ì„  í™•ì¸
            if len(df) >= 20:
                ma5 = df['close'].rolling(window=5).mean().iloc[-1]
                ma10 = df['close'].rolling(window=10).mean().iloc[-1]
                ma20 = df['close'].rolling(window=20).mean().iloc[-1]
                
                if not (pd.isna(ma5) or pd.isna(ma10) or pd.isna(ma20)):
                    current_close = df['close'].iloc[-1]
                    
                    if current_close > ma5 > ma10 > ma20:
                        tech_indicators["Moving Averages"] = "Price > MA5 > MA10 > MA20"
                    elif ma5 > ma10 > ma20:
                        tech_indicators["Moving Averages"] = "MA5 > MA10 > MA20"
                    elif current_close < ma5 < ma10 < ma20:
                        tech_indicators["Moving Averages"] = "Price < MA5 < MA10 < MA20"
                    else:
                        tech_indicators["Moving Averages"] = "Mixed"
        except Exception as e:
            print(f"Error calculating Moving Averages: {str(e)}")
        
        try:
            # ê±°ë˜ëŸ‰ ë¶„ì„ (ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if 'volume' in df.columns and len(df) >= 6:
                avg_volume = df['volume'].iloc[-6:-1].mean()
                current_volume = df['volume'].iloc[-1]
                
                if not (pd.isna(avg_volume) or pd.isna(current_volume)):
                    if current_volume > avg_volume * 1.2:
                        tech_indicators["Volume"] = "Increasing trend"
                    elif current_volume < avg_volume * 0.8:
                        tech_indicators["Volume"] = "Decreasing trend"
                    else:
                        tech_indicators["Volume"] = "Stable"
        except Exception as e:
            print(f"Error calculating Volume analysis: {str(e)}")
        
        try:
            # ë³€ë™ì„± ê³„ì‚°
            if len(df) >= 5:
                returns = df['close'].pct_change().iloc[-5:]
                volatility = returns.std() * np.sqrt(252)  # ì—°í™˜ì‚° ë³€ë™ì„±
                if not pd.isna(volatility):
                    tech_indicators["Volatility"] = round(volatility * 100, 2)  # í¼ì„¼íŠ¸ë¡œ í‘œì‹œ
        except Exception as e:
            print(f"Error calculating Volatility: {str(e)}")
        
        return df, tech_indicators
    
    def get_recent_market_context(self, days=10):
        """í–¥ìƒëœ ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì œê³µ í•¨ìˆ˜"""
        try:
            # ìµœê·¼ ê°€ê²© ë°ì´í„° ì‚¬ìš© (ì¼ë³„ ê°€ê²© ë³€í™”, ë³¼ë¥¨ ë“±)
            recent_results = self.backtest_results[-days:] if hasattr(self, 'backtest_results') and len(self.backtest_results) > 0 else []
            
            # ì¶”ê°€ëœ ë¶€ë¶„: ì²˜ìŒ ì‹¤í–‰ ì‹œ ì´ˆê¸°í™” ì²˜ë¦¬
            if not recent_results and hasattr(self, 'historical_data') and len(self.historical_data) > 0:
                # ì´ì „ ë°ì´í„°ê°€ ì—†ì§€ë§Œ ê¸°ì¡´ íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                recent_results = self.historical_data[-days:] if len(self.historical_data) > days else self.historical_data
            
            if not recent_results:
                # ì—¬ì „íˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
                return """
    Market context: Limited historical data available. 
    Based on general Bitcoin patterns, the market frequently exhibits high volatility with rapid price changes. 
    Recent price action shows consolidation with potential for breakout depending on global macro factors and institutional adoption rates.
    Volume appears moderate with no extreme spikes to indicate major market shifts.
    Support and resistance levels are forming based on recent trading ranges.
    """
            
            # ê°€ê²© ë³€í™” ë° ì¶”ì„¸ íŒŒì•…
            context = "Recent market activity details:\n"
            
            # ê°€ê²© ë³€í™” ê³„ì‚°
            prices = []
            price_changes = []
            volumes = []
            
            for i, day in enumerate(recent_results):
                if 'price' in day:
                    prices.append(day['price'])
                    
                if i > 0 and 'price' in day and 'price' in recent_results[i-1]:
                    daily_change = ((day['price'] / recent_results[i-1]['price']) - 1) * 100
                    price_changes.append(daily_change)
                
                # ë³¼ë¥¨ ì •ë³´ í™•ì¸
                if 'technical_indicators' in day and day['technical_indicators']:
                    for key, value in day['technical_indicators'].items():
                        if 'volume' in key.lower() or 'vol' in key.lower():
                            volumes.append(value)
            
            # ê°€ê²© ì¶”ì„¸ ë¶„ì„
            if prices:
                avg_price = sum(prices) / len(prices)
                min_price = min(prices)
                max_price = max(prices)
                price_range = ((max_price - min_price) / min_price) * 100 if min_price > 0 else 0
                
                context += f"- Average price: â‚©{avg_price:,.0f} KRW\n"
                context += f"- Price range: {price_range:.2f}% (â‚©{min_price:,.0f} - â‚©{max_price:,.0f})\n"
            
            # ê°€ê²© ëª¨ë©˜í…€ ë¶„ì„
            if price_changes:
                up_days = sum(1 for change in price_changes if change > 0)
                down_days = sum(1 for change in price_changes if change < 0)
                flat_days = sum(1 for change in price_changes if abs(change) < 0.1)
                
                avg_change = sum(price_changes) / len(price_changes)
                
                # ì¶”ì„¸ ë°©í–¥ ê°ì§€
                if up_days > down_days and avg_change > 0.5:
                    trend = "Uptrend"
                elif down_days > up_days and avg_change < -0.5:
                    trend = "Downtrend"
                else:
                    trend = "Sideways/Consolidation"
                    
                context += f"- Market trend: {trend} ({up_days} up days, {down_days} down days, {flat_days} flat days)\n"
                context += f"- Average daily change: {avg_change:.2f}%\n"
                
                # ë³¼ë¼í‹¸ë¦¬í‹° ê³„ì‚°
                if len(price_changes) > 1:
                    volatility = sum((change - avg_change) ** 2 for change in price_changes) / len(price_changes)
                    volatility = volatility ** 0.5  # í‘œì¤€í¸ì°¨
                    context += f"- Volatility (std dev): {volatility:.2f}%\n"
                    
                    if volatility > 3:
                        context += "- High volatility market conditions\n"
                    elif volatility < 1:
                        context += "- Low volatility market conditions\n"
            
            # ë³¼ë¥¨ ë¶„ì„
            if volumes and len(volumes) > 1:
                try:
                    # ë³¼ë¥¨ ê°’ì„ ìˆ«ìë¡œ ë³€í™˜
                    numeric_volumes = []
                    for vol in volumes:
                        if isinstance(vol, (int, float)):
                            numeric_volumes.append(float(vol))
                        elif isinstance(vol, str):
                            # ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ ì‹œë„
                            vol_clean = vol.replace(',', '').replace('%', '')
                            try:
                                numeric_volumes.append(float(vol_clean))
                            except:
                                pass
                    
                    if numeric_volumes:
                        avg_volume = sum(numeric_volumes) / len(numeric_volumes)
                        last_volume = numeric_volumes[-1]
                        vol_change = ((last_volume / avg_volume) - 1) * 100
                        
                        context += f"- Volume trend: "
                        if vol_change > 20:
                            context += "Significantly increasing (potential trend acceleration)\n"
                        elif vol_change > 5:
                            context += "Moderately increasing\n"
                        elif vol_change < -20:
                            context += "Significantly decreasing (potential trend exhaustion)\n"
                        elif vol_change < -5:
                            context += "Moderately decreasing\n"
                        else:
                            context += "Stable\n"
                except Exception as e:
                    print(f"Error analyzing volume data: {str(e)}")
            
            # ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„
            rsi_values = []
            macd_values = []
            
            for day in recent_results:
                if 'technical_indicators' in day and day['technical_indicators']:
                    for key, value in day['technical_indicators'].items():
                        if 'rsi' in key.lower():
                            try:
                                if isinstance(value, (int, float)):
                                    rsi_values.append(float(value))
                                elif isinstance(value, str):
                                    rsi_values.append(float(value.replace(',', '')))
                            except:
                                pass
                        
                        if 'macd' in key.lower():
                            try:
                                if isinstance(value, (int, float)):
                                    macd_values.append(float(value))
                                elif isinstance(value, str):
                                    macd_values.append(float(value.replace(',', '')))
                            except:
                                pass
            
            # RSI ë¶„ì„
            if rsi_values:
                last_rsi = rsi_values[-1]
                context += f"- Current RSI: {last_rsi:.1f} - "
                
                if last_rsi > 70:
                    context += "Overbought conditions (potential reversal or continuation)\n"
                elif last_rsi < 30:
                    context += "Oversold conditions (potential reversal or continuation)\n"
                elif last_rsi > 50:
                    context += "Bullish momentum (moderate)\n"
                else:
                    context += "Bearish momentum (moderate)\n"
                
                # RSI ë°©í–¥ í™•ì¸
                if len(rsi_values) > 1:
                    rsi_direction = rsi_values[-1] - rsi_values[-2]
                    if rsi_direction > 3:
                        context += "- RSI: Strong upward momentum\n"
                    elif rsi_direction > 0:
                        context += "- RSI: Slight upward momentum\n"
                    elif rsi_direction < -3:
                        context += "- RSI: Strong downward momentum\n"
                    elif rsi_direction < 0:
                        context += "- RSI: Slight downward momentum\n"
            
            # MACD ë¶„ì„
            if macd_values and len(macd_values) > 1:
                macd_direction = macd_values[-1] - macd_values[-2]
                context += "- MACD: "
                
                if macd_values[-1] > 0 and macd_direction > 0:
                    context += "Strong bullish momentum (above zero and rising)\n"
                elif macd_values[-1] > 0 and macd_direction < 0:
                    context += "Weakening bullish momentum (above zero but falling)\n"
                elif macd_values[-1] < 0 and macd_direction > 0:
                    context += "Improving bearish momentum (below zero but rising)\n"
                elif macd_values[-1] < 0 and macd_direction < 0:
                    context += "Strong bearish momentum (below zero and falling)\n"
            
            # ì§€ì›/ì €í•­ ë ˆë²¨ ë¶„ì„ (ê°„ë‹¨í•œ ë°©ì‹)
            if prices and len(prices) > 5:
                # ê°„ë‹¨í•œ ì§€ì›/ì €í•­ ë ˆë²¨ ì‹ë³„
                sorted_prices = sorted(prices)
                resistance = sorted_prices[-1]  # ìµœê³ ê°€
                support = sorted_prices[0]      # ìµœì €ê°€
                
                # í˜„ì¬ ê°€ê²©ê³¼ì˜ ê±°ë¦¬ ê³„ì‚°
                current_price = prices[-1]
                dist_to_resistance = ((resistance / current_price) - 1) * 100
                dist_to_support = ((current_price / support) - 1) * 100
                
                context += f"- Current price is {dist_to_resistance:.2f}% below recent resistance (â‚©{resistance:,.0f})\n"
                context += f"- Current price is {dist_to_support:.2f}% above recent support (â‚©{support:,.0f})\n"
                
                # ê°€ê²© ìœ„ì¹˜ í•´ì„
                if dist_to_resistance < 1:
                    context += "- Price is testing resistance level (breakout potential)\n"
                elif dist_to_support < 1:
                    context += "- Price is testing support level (breakdown risk)\n"
            
            # íŠ¸ë ˆì´ë”© íŒ¨í„´ ë¶„ì„
            if price_changes and len(price_changes) >= 3:
                # ìµœê·¼ ë³€ë™ì„± í™•ì¸
                recent_volatility = sum(abs(change) for change in price_changes[-3:]) / 3
                
                if recent_volatility > 5:
                    context += "- Trading pattern: High volatility swings (whipsaw pattern)\n"
                elif all(abs(change) < 0.8 for change in price_changes[-3:]):
                    context += "- Trading pattern: Low volatility compression (potential breakout setup)\n"
                elif all(change > 0 for change in price_changes[-3:]):
                    context += "- Trading pattern: Consecutive up days (strong bullish momentum)\n"
                elif all(change < 0 for change in price_changes[-3:]):
                    context += "- Trading pattern: Consecutive down days (strong bearish pressure)\n"
                elif price_changes[-1] > 0 and price_changes[-2] < 0 and price_changes[-3] < 0:
                    context += "- Trading pattern: Potential bullish reversal after downtrend\n"
                elif price_changes[-1] < 0 and price_changes[-2] > 0 and price_changes[-3] > 0:
                    context += "- Trading pattern: Potential bearish reversal after uptrend\n"
                
            return context
        
        except Exception as e:
            print(f"Error creating market context: {str(e)}")
            return "Market context analysis encountered an error. Using limited information for decision making."

    def get_news_cache_path(self, coin, date_from, date_to):
        """
        íŠ¹ì • ë‚ ì§œ ë²”ìœ„ì˜ ë‰´ìŠ¤ì— ëŒ€í•œ ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
        
        Parameters:
        -----------
        coin : str
            ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: "KRW-BTC")
        date_from : datetime
            ì‹œì‘ ë‚ ì§œ
        date_to : datetime
            ì¢…ë£Œ ë‚ ì§œ
            
        Returns:
        --------
        str
            ìºì‹œ íŒŒì¼ ê²½ë¡œ
        """
        # ì½”ì¸ ì‹¬ë³¼ ì •ë¦¬
        if coin.startswith("KRW-"):
            symbol = coin.split("-")[1]
        else:
            symbol = coin
            
        date_from_str = date_from.strftime("%Y%m%d")
        date_to_str = date_to.strftime("%Y%m%d")
        
        return os.path.join(self.news_cache_dir, f"{symbol.lower()}_{date_from_str}_{date_to_str}.json")
    
    def fetch_news_with_selenium(self, coin, date_from, date_to):
        """
        ì…€ë ˆë‹ˆì›€ì„ ì‚¬ìš©í•˜ì—¬ ì•”í˜¸í™”í ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
        """
        if self.selenium_driver is None:
            print("Selenium driver not initialized")
            return []
            
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        cache_path = self.get_news_cache_path(coin, date_from, date_to)
        
        # ìºì‹œ í™•ì¸ (ë¹„ì–´ìˆëŠ” ìºì‹œë„ ì²´í¬)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    if cached_data and len(cached_data) > 0:  # ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                        print(f"Loading news from cache: {cache_path}")
                        return cached_data
                    else:
                        print(f"Empty cache file, regenerating...")
            except:
                print(f"Error reading cache, regenerating...")
        
        # ì½”ì¸ ì‹¬ë³¼ ì •ë¦¬
        if coin.startswith("KRW-"):
            symbol = coin.split("-")[1]
        else:
            symbol = coin
        
        news_list = []
        
        # 1. ë§¤ì¼ê²½ì œ ê²€ìƒ‰
        try:
            search_url = f"https://www.mk.co.kr/en/search?word={symbol.lower()}&dateType=direct&startDate={date_from.strftime('%Y-%m-%d')}&endDate={date_to.strftime('%Y-%m-%d')}"
            
            print(f"Fetching news from Maeil Business Newspaper: {search_url}")
            self.selenium_driver.get(search_url)
            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            # ë‰´ìŠ¤ ì•„í‹°í´ ìš”ì†Œ ì°¾ê¸°
            article_elements = self.selenium_driver.find_elements(By.CSS_SELECTOR, "article")
            
            for article in article_elements[:10]:  # ìµœëŒ€ 10ê°œ ë‰´ìŠ¤ë§Œ ê°€ì ¸ì˜´
                try:
                    # ì œëª© ì¶”ì¶œ
                    title_element = article.find_element(By.CSS_SELECTOR, "h2, h3")
                    title = title_element.text.strip()
                    
                    # ë§í¬ ì¶”ì¶œ
                    link_element = article.find_element(By.TAG_NAME, "a")
                    link = link_element.get_attribute("href")
                    
                    news_list.append({
                        "title": title,
                        "url": link,
                        "description": "",
                        "source": "Maeil Business",
                        "publishedAt": date_from.strftime("%Y-%m-%dT%H:%M:%SZ")
                    })
                except NoSuchElementException:
                    continue
            
            time.sleep(1)  # ìš”ì²­ ê°„ê²© ìœ ì§€
        except Exception as e:
            print(f"Error fetching news from Maeil Business: {str(e)}")
        
        # 2. BlockMedia ë‰´ìŠ¤ í¬ë¡¤ë§
        try:
            search_url = f"https://www.blockmedia.co.kr/search?q={symbol}"
            print(f"Fetching news from BlockMedia: {search_url}")
            self.selenium_driver.get(search_url)
            time.sleep(3)
            
            # ë‰´ìŠ¤ ì•„í‹°í´ ìš”ì†Œ ì°¾ê¸°
            article_elements = self.selenium_driver.find_elements(By.CSS_SELECTOR, ".article-list li, .news-item")[:15]
            
            for article in article_elements:
                try:
                    # ì œëª© ì¶”ì¶œ
                    title_element = article.find_element(By.CSS_SELECTOR, "h2, h3, .title")
                    title = title_element.text.strip()
                    
                    # ë§í¬ ì¶”ì¶œ
                    link_element = article.find_element(By.TAG_NAME, "a")
                    link = link_element.get_attribute("href")
                    
                    if title and link:
                        news_list.append({
                            "title": title,
                            "url": link,
                            "description": "",
                            "source": "BlockMedia",
                            "publishedAt": date_from.strftime("%Y-%m-%dT%H:%M:%SZ")
                        })
                except NoSuchElementException:
                    continue
                    
            time.sleep(1)  # ìš”ì²­ ê°„ê²© ìœ ì§€
            
        except Exception as e:
            print(f"Error fetching news from BlockMedia: {str(e)}")
        
        # 3. CoinTelegraph ë‰´ìŠ¤ í¬ë¡¤ë§
        try:
            search_url = f"https://cointelegraph.com/search?query={symbol.lower()}"
            print(f"Fetching news from CoinTelegraph: {search_url}")
            self.selenium_driver.get(search_url)
            time.sleep(3)
            
            # ê²€ìƒ‰ ê²°ê³¼ ì°¾ê¸°
            news_links = self.selenium_driver.find_elements(By.CSS_SELECTOR, ".post-card-inline a, .news-item a")[:15]
            
            for news_link in news_links:
                try:
                    title = news_link.text.strip()
                    url = news_link.get_attribute("href")
                    
                    if title and url:
                        news_list.append({
                            "title": title,
                            "url": url,
                            "description": "",
                            "source": "CoinTelegraph",
                            "publishedAt": date_from.strftime("%Y-%m-%dT%H:%M:%SZ")
                        })
                except NoSuchElementException:
                    continue
                    
            time.sleep(1)  # ìš”ì²­ ê°„ê²© ìœ ì§€
            
        except Exception as e:
            print(f"Error fetching news from CoinTelegraph: {str(e)}")
        
        # ì¤‘ë³µ ì œê±°
        unique_news = []
        seen_titles = set()
        for news in news_list:
            if news["title"] not in seen_titles:
                unique_news.append(news)
                seen_titles.add(news["title"])
        
        # ìµœì†Œ ë‰´ìŠ¤ ê°œìˆ˜ í™•ì¸
        min_news_count = 5  # ìµœì†Œí•œ 5ê°œì˜ ë‰´ìŠ¤ëŠ” í•„ìš”
        if len(unique_news) < min_news_count:
            print(f"Failed to fetch enough news. Only {len(unique_news)} news articles found.")
            # ì¬ì‹œë„ ë¡œì§ì´ë‚˜ ê¸°ë³¸ ë‰´ìŠ¤ ì¶”ê°€ ê°€ëŠ¥
            # ê¸°ë³¸ ë‰´ìŠ¤ ì¶”ê°€
            default_news = [
                {
                    "title": f"{symbol} market analysis",
                    "url": "",
                    "description": "",
                    "source": "Default",
                    "publishedAt": date_from.strftime("%Y-%m-%dT%H:%M:%SZ")
                } for _ in range(min_news_count - len(unique_news))
            ]
            unique_news.extend(default_news)
        
        # ìºì‹œì— ì €ì¥
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(unique_news, f, ensure_ascii=False, indent=2)
            
        return unique_news
    
    def fetch_news(self, coin, date_from, date_to):
        """
        ê°œì„ ëœ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ìºì‹± ê°œì„ 
        
        Args:
            coin: ì½”ì¸ ì‹¬ë³¼
            date_from: ì‹œì‘ ë‚ ì§œ
            date_to: ì¢…ë£Œ ë‚ ì§œ
            
        Returns:
            list: ë‰´ìŠ¤ ëª©ë¡
        """
        print(f"==== Fetching news for {coin} from {date_from} to {date_to} ====")
        
        # ë‚ ì§œ ê°ì²´ í™•ì¸ ë° ë³€í™˜
        if isinstance(date_from, str):
            try:
                date_from = pd.to_datetime(date_from)
            except:
                date_from = datetime.datetime.now() - datetime.timedelta(days=7)
        
        if isinstance(date_to, str):
            try:
                date_to = pd.to_datetime(date_to)
            except:
                date_to = datetime.datetime.now()
        
        # ìºì‹œ í™•ì¸
        cache_path = self.get_news_cache_path(coin, date_from, date_to)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_news = json.load(f)
                    if cached_news and len(cached_news) > 0:
                        print(f"Using cached news data: {len(cached_news)} articles")
                        return cached_news
            except Exception as e:
                print(f"Error reading cache: {str(e)}")
        
        news_list = []
        
        # 1. ë‰´ìŠ¤ ë°ì´í„°ì…‹ í•¸ë“¤ëŸ¬ ì‚¬ìš©
        if hasattr(self, 'news_handlers') and self.news_handlers:
            try:
                dataset_news = self.fetch_news_from_dataset(coin, date_from, date_to)
                if dataset_news:
                    news_list.extend(dataset_news)
                    print(f"Fetched {len(dataset_news)} news articles from datasets")
            except Exception as e:
                print(f"Error fetching news from datasets: {str(e)}")
        
        # 2. ì…€ë ˆë‹ˆì›€ ë‰´ìŠ¤ í¬ë¡¤ë§
        if hasattr(self, 'use_selenium') and self.use_selenium and hasattr(self, 'selenium_driver') and self.selenium_driver:
            try:
                selenium_news = self.fetch_news_with_selenium(coin, date_from, date_to)
                if selenium_news:
                    news_list.extend(selenium_news)
                    print(f"Fetched {len(selenium_news)} news articles from Selenium")
            except Exception as e:
                print(f"Error fetching news with Selenium: {str(e)}")
        
        # 3. NewsAPI ì‚¬ìš©
        if hasattr(self, 'news_api_key') and self.news_api_key:
            try:
                api_news = self.fetch_news_from_api(coin, date_from, date_to)
                if api_news:
                    news_list.extend(api_news)
                    print(f"Fetched {len(api_news)} news articles from NewsAPI")
            except Exception as e:
                print(f"Error fetching news from API: {str(e)}")
        
        # ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        if not news_list:
            print("No news found, generating sample news data")
            sample_news = self.generate_sample_news(coin, date_from, date_to)
            news_list.extend(sample_news)
        
        # ì¤‘ë³µ ì œê±°
        unique_news = []
        seen_titles = set()
        
        for news in news_list:
            title = news.get('title', '').strip()
            if title and title not in seen_titles:
                unique_news.append(news)
                seen_titles.add(title)
        
        # ë‰´ìŠ¤ë¥¼ ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        unique_news.sort(key=lambda x: x.get('publishedAt', ''), reverse=True)
        
        # ê²°ê³¼ ìºì‹±
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(unique_news, f, ensure_ascii=False, indent=2)
            print(f"Cached {len(unique_news)} news articles")
        except Exception as e:
            print(f"Error caching news: {str(e)}")
        
        print(f"Fetched {len(unique_news)} unique news for {coin}")
        return unique_news
    

    def save_news_correlations(self, file_path="news_correlations.pkl.gz"):
        """
        ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë°ì´í„° ì••ì¶• ì €ì¥
        
        Args:
            file_path: ì €ì¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'news_correlations') or not self.news_correlations:
            print("ì €ì¥í•  ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        try:
            import pickle
            import gzip
            with gzip.open(file_path, 'wb') as f:
                pickle.dump(self.news_correlations, f)
            print(f"{len(self.news_correlations)}ê°œ ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì •ë³´ ì €ì¥ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return False
        

    def visualize_news_correlations(self):
        """
        ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì‹œê°í™”
        
        Returns:
            matplotlib.figure.Figure: ì‹œê°í™” ê²°ê³¼ ê·¸ë˜í”„
        """
        if not hasattr(self, 'news_correlations') or not self.news_correlations:
            print("ì‹œê°í™”í•  ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            import matplotlib.pyplot as plt
            import numpy as np
            
            # ë°ì´í„° ì¶”ì¶œ
            sentiments = []
            price_impacts = []
            themes = []
            confidence = []
            
            for key, data in self.news_correlations.items():
                sentiment = data.get('sentiment_score', 0)
                impact = data.get('price_impact_6h', 0)
                
                if impact is not None and sentiment is not None:
                    sentiments.append(sentiment)
                    price_impacts.append(impact)
                    
                    # ì£¼ì œì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„
                    theme_list = data.get('themes', [])
                    if 'regulation' in theme_list:
                        themes.append('red')
                    elif 'adoption' in theme_list:
                        themes.append('green')
                    elif 'technology' in theme_list:
                        themes.append('blue')
                    else:
                        themes.append('gray')
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° êµ¬ë¶„
                    if abs(sentiment) > 0.5:
                        confidence.append(80)
                    elif abs(sentiment) > 0.3:
                        confidence.append(60)
                    else:
                        confidence.append(40)
            
            # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
            plt.figure(figsize=(12, 8))
            
            # ì‚°ì ë„
            scatter = plt.scatter(sentiments, price_impacts, c=themes, s=confidence, alpha=0.6)
            
            # ì¶”ì„¸ì„ 
            if len(sentiments) > 2:
                z = np.polyfit(sentiments, price_impacts, 1)
                p = np.poly1d(z)
                plt.plot(sorted(sentiments), p(sorted(sentiments)), "r--", alpha=0.7)
            
            # ì¢Œí‘œì¶•
            plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)
            plt.axvline(x=0, color='r', linestyle='-', alpha=0.3)
            
            # ê·¸ë˜í”„ ì„¤ì •
            plt.title('ë‰´ìŠ¤ ê°ì„±ê³¼ 6ì‹œê°„ í›„ ê°€ê²© ë³€í™” ê´€ê³„')
            plt.xlabel('ê°ì„± ì ìˆ˜')
            plt.ylabel('ê°€ê²© ë³€í™”ìœ¨ (%)')
            plt.grid(True, alpha=0.3)
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
            correlation = np.corrcoef(sentiments, price_impacts)[0, 1]
            plt.text(0.05, 0.95, f'ìƒê´€ê³„ìˆ˜: {correlation:.4f}', transform=plt.gca().transAxes,
                    bbox=dict(facecolor='white', alpha=0.7))
            
            # í†µê³„ ì •ë³´ í‘œì‹œ
            pos_count = sum(1 for i in price_impacts if i > 0)
            neg_count = sum(1 for i in price_impacts if i < 0)
            plt.text(0.05, 0.90, f'ê¸ì •ì˜í–¥/ë¶€ì •ì˜í–¥: {pos_count}/{neg_count}', transform=plt.gca().transAxes,
                    bbox=dict(facecolor='white', alpha=0.7))
            
            plt.tight_layout()
            
            # ì €ì¥
            plt.savefig('news_correlation_analysis.png', dpi=300)
            plt.show()
            
            return plt.gcf()
        
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì‹œê°í™” ì˜¤ë¥˜: {str(e)}")
            return None


    def load_news_correlations(self, file_path="news_correlations.pkl.gz"):
        """
        ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë°ì´í„° ë¡œë“œ
        
        Args:
            file_path: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pickle
            import gzip
            import os
            
            if not os.path.exists(file_path):
                print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                return False
            
            with gzip.open(file_path, 'rb') as f:
                self.news_correlations = pickle.load(f)
            
            print(f"{len(self.news_correlations)}ê°œ ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìƒê´€ê´€ê³„ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            self.news_correlations = {}
            return False
    

    def improve_rag_context(self, current_date, news_data, tech_indicators):
        """í–¥ìƒëœ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ - ë§ˆì¼“ ë§ˆì´í¬ë¡œ êµ¬ì¡° ë° ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„"""
        try:
            # ë‰´ìŠ¤ ë°ì´í„° sentiment ë¶„ì„
            news_sentiment = 0
            news_impact = "neutral"
            key_topics = []
            
            if news_data and len(news_data) > 0:
                # ë‰´ìŠ¤ ì œëª© ë° ë‚´ìš©ì—ì„œ ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ê²€ìƒ‰
                positive_keywords = ["rally", "surge", "soar", "gain", "bullish", "optimistic", "adoption", "regulatory clarity"]
                negative_keywords = ["crash", "fall", "drop", "ban", "regulation", "bearish", "sell-off", "hack", "security"]
                
                positive_count = 0
                negative_count = 0
                
                # ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                for news in news_data:
                    title = news.get('title', '').lower()
                    desc = news.get('description', '').lower()
                    
                    # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
                    for keyword in positive_keywords:
                        if keyword in title or keyword in desc:
                            positive_count += 1
                    
                    for keyword in negative_keywords:
                        if keyword in title or keyword in desc:
                            negative_count += 1
                    
                    # í•µì‹¬ í† í”½ ì¶”ì¶œ
                    topics = ["regulation", "adoption", "institutional", "technology", "mining", "defi", "nft", "security"]
                    for topic in topics:
                        if topic in title or topic in desc:
                            if topic not in key_topics:
                                key_topics.append(topic)
                
                # ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ ê³„ì‚°
                if positive_count + negative_count > 0:
                    news_sentiment = (positive_count - negative_count) / (positive_count + negative_count)
                
                # ì˜í–¥ë ¥ íŒë‹¨
                if len(news_data) > 5:
                    news_impact = "high"
                elif len(news_data) > 2:
                    news_impact = "medium"
                else:
                    news_impact = "low"
            
            # ê±°ë˜ëŸ‰ ëŒ€ë¹„ ê°€ê²© ë³€ë™ì„± ë¶„ì„
            volume_price_ratio = "normal"
            if tech_indicators and 'Volume' in tech_indicators and any(key for key in tech_indicators.keys() if 'volatility' in key.lower()):
                try:
                    volume_key = 'Volume'
                    volatility_key = next(key for key in tech_indicators.keys() if 'volatility' in key.lower())
                    
                    volume = tech_indicators[volume_key]
                    volatility = tech_indicators[volatility_key]
                    
                    # ë¬¸ìì—´ ì²˜ë¦¬
                    if isinstance(volume, str):
                        volume = float(volume.replace(',', '').replace('%', ''))
                    if isinstance(volatility, str):
                        volatility = float(volatility.replace(',', '').replace('%', ''))
                    
                    # ë¹„ìœ¨ ê³„ì‚°
                    if isinstance(volume, (int, float)) and isinstance(volatility, (int, float)) and volume > 0:
                        vp_ratio = volatility / volume
                        
                        if vp_ratio > 2:
                            volume_price_ratio = "high volatility with low volume (potential manipulation)"
                        elif vp_ratio < 0.5:
                            volume_price_ratio = "low volatility with high volume (accumulation/distribution)"
                except:
                    pass
            
            # ë§ˆì¼“ ë§ˆì´í¬ë¡œ êµ¬ì¡° ë¶„ì„
            market_structure = "neutral"
            
            rsi_value = 50  # ê¸°ë³¸ê°’
            for key, value in tech_indicators.items():
                if 'rsi' in key.lower():
                    try:
                        if isinstance(value, (int, float)):
                            rsi_value = float(value)
                        elif isinstance(value, str):
                            rsi_value = float(value.replace(',', ''))
                    except:
                        pass
            
            # ì‹œì¥ ì‹¬ë¦¬ ì§€í‘œ
            if rsi_value > 80:
                market_structure = "extreme greed (potential bubble)"
            elif rsi_value > 70:
                market_structure = "overbought (greed phase)"
            elif rsi_value < 20:
                market_structure = "extreme fear (potential bottom)"
            elif rsi_value < 30:
                market_structure = "oversold (fear phase)"
            
            # í˜„ì¬ ë§ˆì¼“ ìƒí™© ì¢…í•© ë¶„ì„
            current_market_state = f"""
    Market Microstructure Analysis:
    - News sentiment: {"Positive" if news_sentiment > 0.3 else "Negative" if news_sentiment < -0.3 else "Neutral"} with {news_impact} impact
    - Key market topics: {', '.join(key_topics) if key_topics else "None identified"}
    - Volume-price dynamics: {volume_price_ratio}
    - Market psychology: {market_structure}
    - Current date: {current_date}

    Trading Implications:
    """
            # íŠ¸ë ˆì´ë”© ì‹œì‚¬ì  ì¶”ê°€
            if rsi_value > 70 and news_sentiment > 0.3:
                current_market_state += "- Bullish sentiment with overbought conditions - consider taking profits or setting tighter trailing stops"
            elif rsi_value < 30 and news_sentiment < -0.3:
                current_market_state += "- Bearish sentiment with oversold conditions - watch for potential capitulation followed by reversal"
            elif rsi_value > 50 and news_sentiment > 0:
                current_market_state += "- Positive sentiment with bullish momentum - potential for continuation"
            elif rsi_value < 50 and news_sentiment < 0:
                current_market_state += "- Negative sentiment with bearish momentum - consider defensive positioning"
            elif abs(news_sentiment) < 0.2 and 40 < rsi_value < 60:
                current_market_state += "- Neutral conditions with balanced sentiment - range-bound trading likely"
                
            # íŠ¹ë³„ ì£¼ì˜ì‚¬í•­ (ìˆëŠ” ê²½ìš°)
            if "extreme" in market_structure:
                current_market_state += "\n- CAUTION: Extreme market psychology detected - high risk of sharp reversal"
            
            return current_market_state
        
        except Exception as e:
            print(f"Error improving RAG context: {str(e)}")
            return "Limited enhanced market context available due to analysis error."
    
    def find_similar_patterns(self, current_indicators, lookback_days=30, success_weight=False, time_decay=False):
        """í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° íŒ¨í„´ ê²€ìƒ‰ - ì„±ê³µ íŒ¨í„´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
        
        Args:
            current_indicators: í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ
            lookback_days: ê²€ìƒ‰í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ (ì¼)
            success_weight: ì„±ê³µ íŒ¨í„´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì—¬ë¶€
            time_decay: ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê°ì†Œ ì ìš© ì—¬ë¶€
        
        Returns:
            list: ìœ ì‚¬ íŒ¨í„´ ëª©ë¡ (ìœ ì‚¬ë„ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
        """
        similar_contexts = []
        
        # document_storeê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì´ˆê¸°í™”
        if not hasattr(self, 'document_store') or not self.document_store:
            self.document_store = []
            return []
        
        # í˜„ì¬ ì‹œì  í™•ì¸
        current_date = datetime.datetime.now()
        
        # ê²€ìƒ‰ ë¡œì§
        for doc in self.document_store[-lookback_days*3:]:  # ë°ì´í„°ëŸ‰ ì¦ê°€
            # ê¸°ë³¸ ìœ ì‚¬ë„ ì ìˆ˜ ì´ˆê¸°í™”
            similarity_score = 0
            matching_points = 0
            
            # 1. RSI ìœ ì‚¬ë„ ì²´í¬
            if 'RSI(14)' in doc.get('indicators', {}) and 'RSI(14)' in current_indicators:
                try:
                    doc_rsi = float(str(doc['indicators']['RSI(14)']).replace(',', ''))
                    current_rsi = float(str(current_indicators['RSI(14)']).replace(',', ''))
                    rsi_diff = abs(doc_rsi - current_rsi)
                    
                    if rsi_diff < 5:
                        similarity_score += 3  # ë§¤ìš° ìœ ì‚¬
                        matching_points += 1
                    elif rsi_diff < 10:
                        similarity_score += 2  # ìœ ì‚¬
                        matching_points += 1
                    elif rsi_diff < 15:
                        similarity_score += 1  # ì•½ê°„ ìœ ì‚¬
                        matching_points += 1
                except:
                    pass
            
            # 2. MACD ìœ ì‚¬ë„ ì²´í¬
            if 'MACD' in doc.get('indicators', {}) and 'MACD' in current_indicators:
                doc_macd = doc['indicators']['MACD']
                current_macd = current_indicators['MACD']
                
                if doc_macd == current_macd:
                    similarity_score += 2
                    matching_points += 1
                elif ("Bullish" in doc_macd and "Bullish" in current_macd) or \
                    ("Bearish" in doc_macd and "Bearish" in current_macd):
                    similarity_score += 1
                    matching_points += 1
            
            # 3. ë³¼ë¦°ì € ë°´ë“œ ìœ ì‚¬ë„ ì²´í¬
            if 'Bollinger Bands' in doc.get('indicators', {}) and 'Bollinger Bands' in current_indicators:
                if doc['indicators']['Bollinger Bands'] == current_indicators['Bollinger Bands']:
                    similarity_score += 2
                    matching_points += 1
            
            # 4. ì´ë™í‰ê· ì„  ìœ ì‚¬ë„ ì²´í¬
            if 'Moving Averages' in doc.get('indicators', {}) and 'Moving Averages' in current_indicators:
                if doc['indicators']['Moving Averages'] == current_indicators['Moving Averages']:
                    similarity_score += 2
                    matching_points += 1
                elif ("Price >" in doc['indicators']['Moving Averages'] and "Price >" in current_indicators['Moving Averages']) or \
                    ("Price <" in doc['indicators']['Moving Averages'] and "Price <" in current_indicators['Moving Averages']):
                    similarity_score += 1
                    matching_points += 1
            
            # 5. ì‹œì¥ ì¶”ì„¸ ìœ ì‚¬ë„ ì²´í¬
            doc_trend = doc.get('market_trend', '')
            current_trend = self.detect_market_trend(current_indicators)
            
            if doc_trend and current_trend:
                if doc_trend == current_trend:
                    similarity_score += 3
                    matching_points += 1
                elif ("uptrend" in doc_trend and "uptrend" in current_trend) or \
                    ("downtrend" in doc_trend and "downtrend" in current_trend):
                    similarity_score += 2
                    matching_points += 1
            
            # 6. ì§€ì§€ì„  ìœ ì‚¬ë„ ì²´í¬
            if 'support_analysis' in doc:
                doc_support = doc.get('support_analysis', {})
                
                current_price = None
                if hasattr(self, 'historical_data') and len(self.historical_data) > 0:
                    current_price = self.historical_data[-1].get('price', self.historical_data[-1].get('close'))
                
                if current_price:
                    current_support = self._check_near_support_level_enhanced("KRW-BTC", current_price)
                    
                    # ì§€ì§€ì„  ê·¼ì²˜ ì—¬ë¶€ ë§¤ì¹­
                    if doc_support.get('is_near_support') == current_support.get('is_near_support'):
                        similarity_score += 1.5
                        matching_points += 1
                    
                    # ì§€ì§€ì„  ê°•ë„ ìœ ì‚¬ë„
                    if doc_support.get('strength') and current_support.get('strength'):
                        strength_diff = abs(doc_support['strength'] - current_support['strength'])
                        if strength_diff < 0.1:
                            similarity_score += 2
                            matching_points += 1
                        elif strength_diff < 0.2:
                            similarity_score += 1
                            matching_points += 1
            
            # 7. ì„±ê³µ íŒ¨í„´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ì‹ ê·œ)
            success_msg = "Pattern without result data"
            if success_weight and 'trade_result' in doc:
                # ê±°ë˜ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                if doc['trade_result'].get('completed', False):
                    # ì„±ê³µì ì¸ ê±°ë˜ì˜€ëŠ”ì§€ í™•ì¸
                    if doc['trade_result'].get('success', False):
                        profit_pct = doc['trade_result'].get('profit_pct', 0)
                        
                        # ìˆ˜ìµë¥ ì— ë”°ë¥¸ ì¶”ê°€ ê°€ì¤‘ì¹˜
                        if profit_pct > 10:  # ë§¤ìš° ì„±ê³µì ì¸ ê±°ë˜
                            similarity_score *= 1.5
                        elif profit_pct > 5:  # ì„±ê³µì ì¸ ê±°ë˜
                            similarity_score *= 1.3
                        else:  # ì•½ê°„ ì„±ê³µì ì¸ ê±°ë˜
                            similarity_score *= 1.1
                        
                        success_msg = f"Successful pattern with {profit_pct:.1f}% profit"
                    else:
                        # ì‹¤íŒ¨í•œ ê±°ë˜ëŠ” ê°€ì¤‘ì¹˜ ê°ì†Œ
                        similarity_score *= 0.8
                        loss_pct = abs(doc['trade_result'].get('profit_pct', 0))
                        success_msg = f"Failed pattern with {loss_pct:.1f}% loss"
            
            # 8. ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê°ì†Œ (ì‹ ê·œ)
            if time_decay and 'timestamp' in doc:
                try:
                    doc_date = doc['timestamp'] if isinstance(doc['timestamp'], datetime.datetime) else pd.to_datetime(doc['timestamp'])
                    days_old = (current_date - doc_date).days
                    
                    # ìµœëŒ€ 180ì¼ê¹Œì§€ ê°€ì¤‘ì¹˜ ê°ì†Œ (0.5ê¹Œì§€)
                    if days_old > 0:
                        time_decay_factor = max(0.5, 1 - (days_old / 360))
                        similarity_score *= time_decay_factor
                except:
                    pass
            
            # ìµœì†Œ ë§¤ì¹­ í¬ì¸íŠ¸ì™€ ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€
            if matching_points >= 2 and similarity_score >= 4:
                # íŒ¨í„´ ì‚¬ìš© íšŸìˆ˜ ì¦ê°€ (ì°¸ì¡° ê¸°ë¡)
                if 'pattern_metrics' in doc:
                    doc['pattern_metrics']['usage_count'] = doc['pattern_metrics'].get('usage_count', 0) + 1
                
                pattern_info = {
                    'pattern_id': doc.get('pattern_id', ''),
                    'date': doc.get('date', ''),
                    'timestamp': doc.get('timestamp', ''),
                    'similarity_score': similarity_score,
                    'content': doc.get('content', ''),
                    'indicators': doc.get('indicators', {}),
                    'support_analysis': doc.get('support_analysis', {}),
                    'ai_decision': doc.get('ai_decision', 'UNKNOWN'),
                    'trade_result': doc.get('trade_result', {}) if 'trade_result' in doc else {},
                    'success_message': success_msg,
                    'pattern_metrics': doc.get('pattern_metrics', {}) if 'pattern_metrics' in doc else {}
                }
                
                similar_contexts.append(pattern_info)
            
        # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬
        similar_contexts.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜ (ê¸°ì¡´ 5ê°œì—ì„œ ì¦ê°€)
        top_patterns = similar_contexts[:10]
        
        # ë””ë²„ê·¸ ë©”ì‹œì§€
        print(f"Found {len(top_patterns)} similar patterns from {len(self.document_store)} total patterns")
        for i, pattern in enumerate(top_patterns[:3]):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
            status = "Success" if pattern.get('trade_result', {}).get('success', False) else "Failed" 
            profit = pattern.get('trade_result', {}).get('profit_pct', 0)
            if profit is None:
                profit = 0.0
            print(f"Pattern {i+1}: Date={pattern.get('date', 'unknown')}, Score={pattern['similarity_score']:.2f}, Status={status}, Profit={profit:.2f}%")
        
        return top_patterns
    
    def get_pattern_based_advice(self, similar_patterns):
        """ìœ ì‚¬ íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ê±°ë˜ ì¡°ì–¸ ìƒì„±
        
        Args:
            similar_patterns: ìœ ì‚¬ íŒ¨í„´ ëª©ë¡
        
        Returns:
            dict: íŒ¨í„´ ê¸°ë°˜ ê±°ë˜ ì¡°ì–¸
        """
        if not similar_patterns:
            return {
                'recommendation': 'INSUFFICIENT_DATA',
                'confidence': 0.0,
                'reasoning': 'No similar patterns found',
                'profit_expectation': 0.0,
                'params': {
                    'profit_target': 5.0,
                    'stop_loss': -2.0,
                    'trailing_stop': 1.0
                }
            }
        
        # 1. ì™„ë£Œëœ ê±°ë˜ë§Œ í•„í„°ë§
        completed_patterns = [p for p in similar_patterns if p.get('trade_result', {}).get('completed', False)]
        
        if not completed_patterns:
            print("Warning: No completed trades in similar patterns")
            return {
                'recommendation': 'INSUFFICIENT_DATA',
                'confidence': 0.0,
                'reasoning': 'Similar patterns found but no completed trades',
                'profit_expectation': 0.0,
                'params': {
                    'profit_target': 5.0,
                    'stop_loss': -2.0,
                    'trailing_stop': 1.0
                }
            }
        
        # 2. íŒ¨í„´ í†µê³„ ê³„ì‚°
        successful_patterns = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
        failed_patterns = [p for p in completed_patterns if not p.get('trade_result', {}).get('success', False)]
        
        # ìŠ¹ë¥  ê³„ì‚°
        win_rate = len(successful_patterns) / len(completed_patterns) if completed_patterns else 0
        
        # í‰ê·  ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°
        avg_profit = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in successful_patterns) / len(successful_patterns) if successful_patterns else 0
        avg_loss = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in failed_patterns) / len(failed_patterns) if failed_patterns else 0
        
        # ê¸°ëŒ€ ìˆ˜ìµ ê³„ì‚°
        expected_profit = (win_rate * avg_profit) + ((1 - win_rate) * avg_loss)
        
        # 3. ê²°ì • ê·œì¹™
        # ìŠ¹ë¥ ì´ 50% ì´ìƒì´ê³  ê¸°ëŒ€ ìˆ˜ìµì´ ì–‘ìˆ˜ë©´ BUY
        if win_rate >= 0.5 and expected_profit > 0:
            recommendation = 'BUY'
            confidence = min(0.95, win_rate + (expected_profit / 20))  # ìµœëŒ€ 0.95
            reasoning = f"Based on {len(completed_patterns)} similar patterns with {win_rate:.0%} win rate and {expected_profit:.2f}% expected profit"
        # ìŠ¹ë¥ ì´ ë‚®ì§€ë§Œ ê¸°ëŒ€ ìˆ˜ìµì´ ë†’ì€ ê²½ìš° (ë†’ì€ ë¦¬ìŠ¤í¬/ë¦¬ì›Œë“œ)
        elif win_rate < 0.5 and expected_profit > 1.5:
            recommendation = 'BUY'
            confidence = 0.5 + (expected_profit / 30)  # ì¤‘ê°„ ì •ë„ í™•ì‹ 
            reasoning = f"High risk/reward opportunity based on {len(completed_patterns)} similar patterns with {expected_profit:.2f}% expected profit despite {win_rate:.0%} win rate"
        # ìŠ¹ë¥ ì´ ë‚®ê³  ê¸°ëŒ€ ìˆ˜ìµë„ ë‚®ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš°
        else:
            recommendation = 'HOLD'
            confidence = 0.5 + (abs(expected_profit) / 20) if expected_profit < 0 else 0.5
            reasoning = f"Avoiding risk based on {len(completed_patterns)} similar patterns with {win_rate:.0%} win rate and {expected_profit:.2f}% expected profit"
        
        # 4. ìµœì  íŒŒë¼ë¯¸í„° ê³„ì‚°
        # ìˆ˜ìµ íŒ¨í„´ì—ì„œ ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        if successful_patterns:
            # ê°€ì¥ ìˆ˜ìµì´ ì¢‹ì•˜ë˜ ìƒìœ„ 3ê°œ íŒ¨í„´ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            top_patterns = sorted(successful_patterns, key=lambda p: p.get('trade_result', {}).get('profit_pct', 0), reverse=True)[:3]
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            total_weight = sum(p.get('trade_result', {}).get('profit_pct', 0) for p in top_patterns)
            profit_targets = []
            stop_losses = []
            trailing_stops = []
            
            for p in top_patterns:
                profit_pct = p.get('trade_result', {}).get('profit_pct', 0)
                weight = profit_pct / total_weight if total_weight > 0 else 1/len(top_patterns)
                
                # ì›ë˜ ëª©í‘œ íŒŒë¼ë¯¸í„° ì¶”ì •
                exit_reason = p.get('trade_result', {}).get('exit_reason', '')
                
                if exit_reason == 'PROFIT':
                    # ìµì ˆ ëª©í‘œëŠ” ì‹¤ì œ ìˆ˜ìµë³´ë‹¤ ì•½ê°„ ë†’ê²Œ ì„¤ì •
                    profit_targets.append((profit_pct * 1.1) * weight)
                elif exit_reason == 'TRAILING':
                    # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ì€ ì‹¤ì œ ìˆ˜ìµì˜ ë¹„ìœ¨ë¡œ ì¶”ì •
                    trailing_stops.append((profit_pct * 0.3) * weight)
                
                # ì†ì ˆë§¤ëŠ” í‰ê·  ì†ì‹¤ì—ì„œ ì¶”ì •
                if failed_patterns:
                    avg_failed = abs(sum(p.get('trade_result', {}).get('profit_pct', 0) for p in failed_patterns) / len(failed_patterns))
                    stop_losses.append(-avg_failed * 1.2 * weight)  # ì•½ê°„ ì—¬ìœ ìˆê²Œ ì„¤ì •
                else:
                    stop_losses.append(-2.0 * weight)  # ê¸°ë³¸ê°’
            
            # ìµœì¢… íŒŒë¼ë¯¸í„° ê³„ì‚°
            optimized_params = {
                'profit_target': sum(profit_targets) if profit_targets else 5.0,
                'stop_loss': sum(stop_losses) if stop_losses else -2.0,
                'trailing_stop': sum(trailing_stops) if trailing_stops else 1.0
            }
        else:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            optimized_params = {
                'profit_target': 5.0,
                'stop_loss': -2.0,
                'trailing_stop': 1.0
            }
        
        # 5. ìµœì¢… ì¡°ì–¸ êµ¬ì„±
        advice = {
            'recommendation': recommendation,
            'confidence': confidence,
            'reasoning': reasoning,
            'win_rate': win_rate,
            'avg_profit': avg_profit,
            'avg_loss': avg_loss,
            'profit_expectation': expected_profit,
            'similar_patterns_count': len(completed_patterns),
            'params': optimized_params
        }
        
        return advice
    
    def store_market_pattern(self, current_indicators, price, decision, context_date=None):
        """ì‹œì¥ íŒ¨í„´ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - ì„±ê³µ íŒ¨í„´ í•™ìŠµì„ ìœ„í•´ ê°œì„ ë¨
        
        Args:
            current_indicators: í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ
            price: í˜„ì¬ ê°€ê²©
            decision: AI ê²°ì • ('BUY', 'SELL', 'HOLD')
            context_date: ì»¨í…ìŠ¤íŠ¸ ë‚ ì§œ (ê¸°ë³¸ê°’: í˜„ì¬)
        """
        # í˜„ì¬ ì‹œì¥ ì¶”ì„¸ ê°ì§€
        market_trend = self.detect_market_trend(current_indicators)
        
        # ì§€ì§€ì„  ì •ë³´ ì¶”ê°€
        if price:
            support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
        else:
            support_analysis = {}
        
        # í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ì„¤ì •
        if context_date is None:
            current_datetime = datetime.datetime.now()
        else:
            current_datetime = context_date if isinstance(context_date, datetime.datetime) else pd.to_datetime(context_date)
        
        # íŒ¨í„´ ID ìƒì„±
        pattern_id = f"{current_datetime.strftime('%Y%m%d%H%M%S')}_{hash(str(current_indicators))}"
        
        # íŒ¨í„´ ì €ì¥ ê°ì²´ ìƒì„±
        new_context = {
            'pattern_id': pattern_id,
            'date': current_datetime.strftime("%Y-%m-%d"),
            'timestamp': current_datetime,
            'indicators': current_indicators,
            'price': price,
            'market_trend': market_trend,
            'support_analysis': support_analysis,
            'ai_decision': decision,
            'content': f"Market shows {market_trend} with RSI at {current_indicators.get('RSI(14)', 'N/A')}. "
                    f"MACD is {current_indicators.get('MACD', 'N/A')}. "
                    f"Bollinger Bands: {current_indicators.get('Bollinger Bands', 'N/A')}. "
                    f"Moving Averages: {current_indicators.get('Moving Averages', 'N/A')}. "
                    f"Support level nearby: {support_analysis.get('is_near_support', False)}, "
                    f"Support strength: {support_analysis.get('strength', 0):.2f}.",
            'trade_result': {
                'completed': False,
                'entry_price': price if decision == 'BUY' else None,
                'exit_price': None,
                'profit_pct': None,
                'success': None,
                'exit_reason': None,
                'holding_days': None
            },
            'pattern_metrics': {
                'success_count': 0,
                'failure_count': 0,
                'total_profit': 0,
                'avg_profit': 0,
                'success_rate': 0,
                'last_update': current_datetime.strftime("%Y-%m-%d"),
                'usage_count': 0
            }
        }
        
        # document_store ì´ˆê¸°í™” í™•ì¸
        if not hasattr(self, 'document_store'):
            self.document_store = []
            
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì‚¬
        existing_index = -1
        for i, doc in enumerate(self.document_store):
            if doc.get('pattern_id') == pattern_id:
                existing_index = i
                break
        
        if existing_index >= 0:
            # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            self.document_store[existing_index] = new_context
            print(f"Pattern {pattern_id} updated in document store")
        else:
            # ìƒˆ í•­ëª© ì¶”ê°€
            self.document_store.append(new_context)
            print(f"New pattern {pattern_id} added to document store")
        
        return pattern_id


    def manage_consecutive_losses(self, profit_pct, i):
        """
        íŒ¨í„´ í•™ìŠµìš© ì—°ì† ì†ì‹¤ ê´€ë¦¬ - ì¿¨ë‹¤ìš´ ì—†ìŒ
        """
        if not hasattr(self, 'consecutive_losses'):
            self.consecutive_losses = 0
        if not hasattr(self, 'consecutive_wins'):
            self.consecutive_wins = 0
        if not hasattr(self, 'stop_loss_streak'):
            self.stop_loss_streak = 0
        if not hasattr(self, 'cooldown_until'):
            self.cooldown_until = -1  # í•­ìƒ ë¹„í™œì„±í™”
        if not hasattr(self, 'recovery_factor'):
            self.recovery_factor = 1.0
        
        if profit_pct > 0:
            # ìˆ˜ìµì´ ë°œìƒí•œ ê²½ìš°
            self.consecutive_wins += 1
            self.consecutive_losses = max(0, self.consecutive_losses - 1)
            self.stop_loss_streak = 0
            
            # ì—°ì† ì„±ê³µ ì‹œ íšŒë³µ ê³„ìˆ˜ ì ì§„ì  ì¦ê°€
            if self.consecutive_wins >= 3:
                self.recovery_factor = min(1.0, self.recovery_factor + 0.1)
            
            # íŒ¨í„´ í•™ìŠµ ëª¨ë“œ: ì¿¨ë‹¤ìš´ ì—†ìŒ
            self.cooldown_until = -1
        else:
            # ì†ì‹¤ì´ ë°œìƒí•œ ê²½ìš°
            self.consecutive_losses += 1
            self.consecutive_wins = 0
            
            # ì†ì ˆë§¤ë¡œ ì¸í•œ ì†ì‹¤ì¸ ê²½ìš°
            if profit_pct <= -1.0:
                self.stop_loss_streak += 1
            
            # íšŒë³µ ê³„ìˆ˜ ê°ì†Œ (í•˜ì§€ë§Œ ì¿¨ë‹¤ìš´ì€ ì—†ìŒ)
            self.recovery_factor = max(0.3, self.recovery_factor - 0.15)
            
            # íŒ¨í„´ í•™ìŠµ ëª¨ë“œ: ì¿¨ë‹¤ìš´ ì—†ì´ ìƒíƒœë§Œ ë¡œê¹…
            if self.consecutive_losses >= 3:
                print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ: ì—°ì† {self.consecutive_losses}íšŒ ì†ì‹¤ ë°œìƒ - ê³„ì† í•™ìŠµ ì¤‘")
            
            if self.stop_loss_streak >= 2:
                print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ: ì†ì ˆë§¤ {self.stop_loss_streak}íšŒ ì—°ì† ë°œìƒ - ê³„ì† í•™ìŠµ ì¤‘")
            
            # ì¿¨ë‹¤ìš´ì€ ì ìš©í•˜ì§€ ì•ŠìŒ
            self.cooldown_until = -1
        
        # í˜„ì¬ ìƒíƒœ ë¡œê¹… ë° ë°˜í™˜
        status = {
            "consecutive_losses": self.consecutive_losses,
            "consecutive_wins": self.consecutive_wins,
            "stop_loss_streak": self.stop_loss_streak,
            "cooldown_until": -1,  # í•­ìƒ -1 (ì¿¨ë‹¤ìš´ ì—†ìŒ)
            "recovery_factor": self.recovery_factor
        }
        
        if self.consecutive_losses > 0 or self.consecutive_wins > 0:
            print(f"ğŸ“Š íŒ¨í„´í•™ìŠµ ìƒíƒœ: ì—°ì†ì†ì‹¤={self.consecutive_losses}, ì—°ì†ì„±ê³µ={self.consecutive_wins}, íšŒë³µê³„ìˆ˜={self.recovery_factor:.2f}")
        
        return status
    
    def set_adaptive_trailing_stop(self, price, market_trend, volatility):
        """ì‹œì¥ ì¡°ê±´ì— ë§ëŠ” íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì„¤ì • - ë” ë™ì ì¸ ì¡°ì •"""
        # ê¸°ë³¸ íŠ¸ë ˆì¼ë§ ê°’ ì„¤ì •
        base_trailing = 1.0
        
        # ì‹œì¥ ì¶”ì„¸ì— ë”°ë¥¸ ê¸°ë³¸ ì¡°ì •
        if "Strong uptrend" in market_trend:
            # ê°•í•œ ìƒìŠ¹ì¥ì—ì„œëŠ” ë” ë„“ì€ íŠ¸ë ˆì¼ë§ (ë” ë§ì€ ì´ìµ í™•ë³´)
            base_trailing = 1.2
        elif "Moderate uptrend" in market_trend or "Possible uptrend" in market_trend:
            base_trailing = 1.0
        elif "Mixed/Sideways" in market_trend:
            # íš¡ë³´ì¥ì—ì„œëŠ” ì¤‘ê°„ ìˆ˜ì¤€ì˜ íŠ¸ë ˆì¼ë§
            base_trailing = 0.8
        elif "Moderate downtrend" in market_trend or "Possible downtrend" in market_trend:
            # ì•½í•œ í•˜ë½ì¥ì—ì„œëŠ” íƒ€ì´íŠ¸í•œ íŠ¸ë ˆì¼ë§
            base_trailing = 0.6
        elif "Strong downtrend" in market_trend:
            # ê°•í•œ í•˜ë½ì¥ì—ì„œëŠ” ë§¤ìš° íƒ€ì´íŠ¸í•œ íŠ¸ë ˆì¼ë§
            base_trailing = 0.5
        
        # ë³€ë™ì„±ì— ë”°ë¥¸ ì¡°ì • - ë” ì„¸ë°€í•˜ê²Œ ë¶„ë¥˜
        if volatility < 0.02:  # ë§¤ìš° ë‚®ì€ ë³€ë™ì„±
            volatility_factor = 0.8
        elif volatility < 0.04:  # ë‚®ì€ ë³€ë™ì„±
            volatility_factor = 1.0
        elif volatility < 0.06:  # ì¤‘ê°„ ë³€ë™ì„±
            volatility_factor = 1.2
        elif volatility < 0.08:  # ë†’ì€ ë³€ë™ì„±
            volatility_factor = 1.5
        else:  # ë§¤ìš° ë†’ì€ ë³€ë™ì„±
            volatility_factor = 2.0
        
        # RSI ìƒíƒœì— ë”°ë¥¸ ì¶”ê°€ ì¡°ì •
        try:
            # tech_indicatorsê°€ ì „ë‹¬ëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
            if hasattr(self, 'tech_indicators') and self.tech_indicators:
                rsi_str = self.tech_indicators.get("RSI(14)", "50")
                rsi = float(str(rsi_str).replace(',', '')) if isinstance(rsi_str, (int, float, str)) else 50
                
                # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ìƒíƒœì—ì„œì˜ ì¡°ì •
                if rsi > 75:  # ê³¼ë§¤ìˆ˜
                    rsi_factor = 0.7  # íƒ€ì´íŠ¸í•˜ê²Œ ì¡°ì •
                elif rsi < 25:  # ê³¼ë§¤ë„
                    rsi_factor = 1.3  # ì—¬ìœ ë¡­ê²Œ ì¡°ì •
                else:
                    rsi_factor = 1.0  # ì¤‘ë¦½
                    
                # ìµœì¢… ê³„ì‚°ì— RSI íŒ©í„° ì ìš©
                base_trailing *= rsi_factor
        except:
            pass  # RSI ì •ë³´ê°€ ì—†ìœ¼ë©´ ì´ ì¡°ì •ì€ ê±´ë„ˆëœ€
        
        # ìµœì¢… íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê³„ì‚°
        final_trailing = base_trailing * volatility_factor
        
        # í•œê³„ê°’ ì„¤ì • (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì§€ ì•Šë„ë¡)
        final_trailing = max(0.3, min(final_trailing, 3.0))
        
        # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê°€ê²© ê³„ì‚°
        trailing_stop_price = price * (1 - final_trailing/100)
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ë¡œê¹…
        if hasattr(self, 'debug_mode') and self.debug_mode:
            print(f"Adaptive Trailing Stop: {final_trailing}% (Base: {base_trailing}, Volatility Factor: {volatility_factor})")
            print(f"Price: {price}, Stop Price: {trailing_stop_price}")
        
        return trailing_stop_price
    
    def update_pattern_with_trade_result(self, pattern_id, exit_price, exit_date, exit_reason):
        """ê±°ë˜ ê²°ê³¼ë¡œ íŒ¨í„´ ì •ë³´ ì—…ë°ì´íŠ¸
        
        Args:
            pattern_id: íŒ¨í„´ ê³ ìœ  ID
            exit_price: ë§¤ë„ ê°€ê²©
            exit_date: ë§¤ë„ ë‚ ì§œ
            exit_reason: ë§¤ë„ ì´ìœ  ('PROFIT', 'STOPLOSS', 'TRAILING', 'MANUAL')
        
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'document_store'):
            print("Warning: document_store not initialized")
            return False
        
        # í•´ë‹¹ íŒ¨í„´ ì°¾ê¸°
        target_pattern = None
        pattern_index = -1
        
        for i, pattern in enumerate(self.document_store):
            if pattern.get('pattern_id') == pattern_id:
                target_pattern = pattern
                pattern_index = i
                break
        
        if target_pattern is None:
            print(f"Pattern {pattern_id} not found in document store")
            return False
        
        # ì´ë¯¸ ì™„ë£Œëœ ê±°ë˜ì¸ì§€ í™•ì¸
        if target_pattern.get('trade_result', {}).get('completed', False):
            print(f"Trade for pattern {pattern_id} already completed")
            return False
        
        # ì§„ì… ê°€ê²© í™•ì¸
        entry_price = target_pattern['trade_result'].get('entry_price')
        if entry_price is None:
            print(f"No entry price for pattern {pattern_id}")
            entry_price = target_pattern['price']  # íŒ¨í„´ ì €ì¥ ì‹œ ê°€ê²© ì‚¬ìš©
        
        # ê²°ê³¼ ê³„ì‚°
        if entry_price > 0 and exit_price > 0:
            profit_pct = ((exit_price / entry_price) - 1) * 100
            success = profit_pct > 0
            
            # ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸
            target_pattern['trade_result'].update({
                'completed': True,
                'exit_price': exit_price,
                'profit_pct': profit_pct,
                'success': success,
                'exit_reason': exit_reason,
                'exit_date': exit_date.strftime("%Y-%m-%d") if isinstance(exit_date, datetime.datetime) else str(exit_date),
                'holding_days': self.calculate_holding_days(target_pattern['date'], str(exit_date))
            })
            
            # íŒ¨í„´ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            target_pattern['pattern_metrics'].update({
                'success_count': target_pattern['pattern_metrics']['success_count'] + (1 if success else 0),
                'failure_count': target_pattern['pattern_metrics']['failure_count'] + (0 if success else 1),
                'total_profit': target_pattern['pattern_metrics']['total_profit'] + profit_pct,
                'last_update': datetime.datetime.now().strftime("%Y-%m-%d")
            })
            
            # í‰ê·  ìˆ˜ìµ ë° ì„±ê³µë¥  ì¬ê³„ì‚°
            total_trades = target_pattern['pattern_metrics']['success_count'] + target_pattern['pattern_metrics']['failure_count']
            if total_trades > 0:
                target_pattern['pattern_metrics']['avg_profit'] = target_pattern['pattern_metrics']['total_profit'] / total_trades
                target_pattern['pattern_metrics']['success_rate'] = target_pattern['pattern_metrics']['success_count'] / total_trades * 100
            
            # ë¬¸ì„œ ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
            self.document_store[pattern_index] = target_pattern
            print(f"Pattern {pattern_id} updated with trade result: profit={profit_pct:.2f}%, success={success}")
            
            # RAG ë°ì´í„° ì €ì¥
            try:
                import pickle
                import gzip
                with gzip.open('rag_pattern_store.pkl.gz', 'wb') as f:
                    pickle.dump(self.document_store, f)
                print("RAG pattern store saved to compressed file")
            except Exception as e:
                print(f"Failed to save RAG pattern store: {str(e)}")
            
            return True
        else:
            print(f"Invalid prices for pattern {pattern_id}")
            return False

    def save_rag_patterns(self, file_path="rag_pattern_store.pkl.gz"):
        """RAG íŒ¨í„´ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì—¬ ì €ì¥
        
        Args:
            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not hasattr(self, 'document_store') or not self.document_store:
            print("Warning: No patterns to save")
            return False
        
        try:
            import pickle
            import gzip
            with gzip.open(file_path, 'wb') as f:
                pickle.dump(self.document_store, f)
            print(f"Successfully saved {len(self.document_store)} patterns to {file_path}")
            return True
        except Exception as e:
            print(f"Error saving RAG patterns: {str(e)}")
            return False

    def load_rag_patterns(self, file_path="rag_pattern_store.pkl.gz"):
        """ì €ì¥ëœ RAG íŒ¨í„´ ë°ì´í„° ë¡œë“œ
        
        Args:
            file_path: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pickle
            import gzip
            import os
            
            if not os.path.exists(file_path):
                print(f"RAG pattern file {file_path} not found")
                return False
            
            with gzip.open(file_path, 'rb') as f:
                self.document_store = pickle.load(f)
            
            print(f"Successfully loaded {len(self.document_store)} patterns from {file_path}")
            
            # íŒ¨í„´ í†µê³„ ì¶œë ¥
            completed_patterns = [p for p in self.document_store if p.get('trade_result', {}).get('completed', False)]
            successful_patterns = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
            
            if completed_patterns:
                win_rate = len(successful_patterns) / len(completed_patterns) * 100
                print(f"Pattern stats: {len(completed_patterns)} completed trades, {win_rate:.1f}% win rate")
                
                # ê°€ì¥ ì„±ê³µì ì¸ íŒ¨í„´ ì •ë³´
                if successful_patterns:
                    best_pattern = max(successful_patterns, key=lambda p: p.get('trade_result', {}).get('profit_pct', 0))
                    best_profit = best_pattern.get('trade_result', {}).get('profit_pct', 0)
                    print(f"Best pattern: {best_profit:.2f}% profit on {best_pattern.get('date', 'unknown date')}")
            
            return True
        except Exception as e:
            print(f"Error loading RAG patterns: {str(e)}")
            return False

    def calculate_volatility(self, data, period=5):
        """ë³€ë™ì„± ê³„ì‚° - ë‹¤ì–‘í•œ ë°ì´í„° í˜•ì‹ ì²˜ë¦¬ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ """
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if data is None:
            return 0.05  # ê¸°ë³¸ê°’
        
        try:
            # pandas DataFrameì¸ ê²½ìš°
            if isinstance(data, pd.DataFrame):
                if data.empty or len(data) < period:
                    return 0.05
                
                # 'close' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'close' not in data.columns:
                    # ê°€ëŠ¥í•œ ëŒ€ì²´ ì¹¼ëŸ¼ ì°¾ê¸°
                    possible_columns = ['Close', 'price', 'Price']
                    for col in possible_columns:
                        if col in data.columns:
                            prices = data[col].tolist()
                            break
                    else:
                        # ëŒ€ì²´ ì¹¼ëŸ¼ë„ ì—†ëŠ” ê²½ìš°
                        return 0.05
                else:
                    # Close ê°€ê²© ì‚¬ìš©
                    prices = data['close'].tolist()
            
            # ë¦¬ìŠ¤íŠ¸ë‚˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (backtest_results)
            elif isinstance(data, list):
                if not data or len(data) < period:
                    return 0.05
                
                # ê°€ê²© ì¶”ì¶œ ì‹œë„
                try:
                    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                    if isinstance(data[0], dict):
                        # ê°€ëŠ¥í•œ ê°€ê²© í‚¤ ëª©ë¡
                        price_keys = ['price', 'close', 'Close', 'closing_price']
                        
                        # ì¡´ì¬í•˜ëŠ” í‚¤ ì‚¬ìš©
                        for key in price_keys:
                            if key in data[0]:
                                prices = [float(str(item[key]).replace(',', '')) for item in data]
                                break
                        else:
                            # ì í•©í•œ í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
                            return 0.05
                    else:
                        # ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì •
                        prices = [float(str(item).replace(',', '')) if isinstance(item, (int, float, str)) else 0 for item in data]
                except (TypeError, ValueError, KeyError):
                    return 0.05
            else:
                return 0.05  # ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° í˜•ì‹
            
            # ëª¨ë“  ìˆ«ìë¥¼ floatë¡œ ë³€í™˜ í™•ì¸
            clean_prices = []
            for p in prices:
                try:
                    if isinstance(p, str):
                        clean_prices.append(float(p.replace(',', '')))
                    else:
                        clean_prices.append(float(p))
                except (ValueError, TypeError):
                    # ì˜ëª»ëœ ê°’ì€ ì œì™¸
                    continue
                    
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
            if len(clean_prices) < period:
                return 0.05
                
            # ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°
            returns = []
            for i in range(1, len(clean_prices)):
                if clean_prices[i-1] > 0:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                    ret = (clean_prices[i] / clean_prices[i-1]) - 1
                    returns.append(ret)
            
            if not returns:
                return 0.05
            
            # ìµœê·¼ period ê¸°ê°„ì˜ í‘œì¤€í¸ì°¨ ê³„ì‚°
            recent_returns = returns[-period:] if len(returns) >= period else returns
            volatility = np.std(recent_returns) * (252**0.5)  # ì—°í™˜ì‚°
            
            return volatility if volatility > 0 else 0.05
            
        except Exception as e:
            if hasattr(self, 'debug_mode') and self.debug_mode:
                print(f"Error calculating volatility: {str(e)}")
            return 0.05  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜


    def analyze_news_sentiment(self, news_data):
        """
        ë‰´ìŠ¤ ê°ì„± ë¶„ì„ - í‚¤ì›Œë“œ ë° ê°ì„± ì ìˆ˜ ì¶”ì¶œ
        
        Args:
            news_data: ë‰´ìŠ¤ ë°ì´í„° ëª©ë¡
            
        Returns:
            dict: ê°ì„± ë¶„ì„ ê²°ê³¼
        """
        if not news_data or len(news_data) == 0:
            return {"sentiment_score": 0, "key_topics": [], "impact_level": "neutral"}
        
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ì‚¬ì „
        bullish_keywords = ['bullish', 'surge', 'rally', 'breakout', 'adoption', 'institutional', 'upgrade', 
                            'growth', 'positive', 'uptrend', 'support', 'partnership', 'development']
        bearish_keywords = ['bearish', 'crash', 'ban', 'regulation', 'hack', 'exploit', 'downgrade', 
                            'restriction', 'crackdown', 'sell-off', 'bearish', 'resistance', 'negative']
        
        # ê°ì„± ì ìˆ˜ ê³„ì‚°
        sentiment_score = 0
        key_topics = []
        
        for news in news_data:
            title = news.get('title', '').lower()
            description = news.get('description', '').lower()
            content = title + " " + description
            
            # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ í™•ì¸
            bull_count = sum(1 for word in bullish_keywords if word in content)
            bear_count = sum(1 for word in bearish_keywords if word in content)
            
            # ê°œë³„ ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° (ë²”ìœ„: -1.0 ~ 1.0)
            news_score = 0
            if bull_count + bear_count > 0:
                news_score = (bull_count - bear_count) / max(1, bull_count + bear_count)
            sentiment_score += news_score
            
            # ì£¼ìš” í† í”½ ì¶”ì¶œ
            if 'regulation' in content or 'compliance' in content or 'legal' in content:
                key_topics.append('regulation')
            if 'adoption' in content or 'institutional' in content or 'invest' in content:
                key_topics.append('adoption')
            if 'technology' in content or 'upgrade' in content or 'development' in content:
                key_topics.append('technology')
            if 'market' in content or 'trading' in content or 'volume' in content:
                key_topics.append('market')
            if 'hack' in content or 'security' in content or 'breach' in content:
                key_topics.append('security')
        
        # ì „ì²´ ê°ì„± ì ìˆ˜ ì •ê·œí™”
        if len(news_data) > 0:
            sentiment_score = sentiment_score / len(news_data)
        
        # ì˜í–¥ë„ íŒë‹¨
        if abs(sentiment_score) < 0.2:
            impact_level = "low"
        elif abs(sentiment_score) < 0.5:
            impact_level = "medium"
        else:
            impact_level = "high"
            
        return {
            "sentiment_score": sentiment_score,
            "key_topics": list(set(key_topics)),
            "impact_level": impact_level,
            "news_count": len(news_data)
        }
    


    def optimize_parameters(self, data, parameter_ranges):
        """íŒŒë¼ë¯¸í„° ìµœì í™” - ìˆ˜ìµë¥  ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜"""
        best_profit = -float('inf')
        best_params = {}
        results = []
        
        # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        param_combinations = []
        for profit_target in parameter_ranges['profit_target']:
            for stop_loss in parameter_ranges['stop_loss']:
                for trailing_stop in parameter_ranges['trailing_stop']:
                    for rsi_threshold in parameter_ranges['rsi_threshold']:
                        param_combinations.append({
                            'profit_target': profit_target,
                            'stop_loss': stop_loss,
                            'trailing_stop': trailing_stop,
                            'rsi_threshold': rsi_threshold
                        })
        
        print(f"ì´ {len(param_combinations)}ê°œ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ìµœì í™” ì‹œì‘...")
        
        # ê° íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for params in tqdm(param_combinations):
            # íŒŒë¼ë¯¸í„° ì„¤ì •
            self.default_profit_target = params['profit_target']
            self.default_stop_loss = params['stop_loss']
            self.default_trailing_stop = params['trailing_stop']
            self.rsi_threshold = params['rsi_threshold']
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            backtest_results = self.run_backtest(
                data, 
                test_mode=False, 
                llm_mode=True,
                initial_position=False
            )
            
            # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‰ê°€
            evaluation = self.evaluate_backtest(backtest_results)
            
            # ê²°ê³¼ ì €ì¥
            result = {
                'parameters': params.copy(),
                'total_return': evaluation['total_return_pct'],
                'max_drawdown': evaluation['max_drawdown_pct'],
                'win_rate': evaluation['win_rate'],
                'trade_count': evaluation['trade_count'],
                'sharpe_ratio': evaluation.get('sharpe_ratio', 0)
            }
            results.append(result)
            
            # ìµœê³  ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸
            if result['total_return'] > best_profit:
                best_profit = result['total_return']
                best_params = params.copy()
                print(f"ìƒˆë¡œìš´ ìµœì  íŒŒë¼ë¯¸í„° ë°œê²¬: {best_params}, ìˆ˜ìµë¥ : {best_profit:.2f}%")
        
        # ê²°ê³¼ ì €ì¥
        try:
            with open(f"backtest_results/optimization_results.json", 'w', encoding='utf-8') as f:
                json.dump({
                    'best_params': best_params,
                    'best_profit': best_profit,
                    'all_results': results
                }, f, indent=2)
            print(f"ìµœì í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: backtest_results/optimization_results.json")
        except Exception as e:
            print(f"ìµœì í™” ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        return best_params, results



    def identify_profitable_patterns(self, backtest_results):
        """ìˆ˜ìµì„± ë†’ì€ íŠ¸ë ˆì´ë”© íŒ¨í„´ ì‹ë³„"""
        profitable_patterns = []
        
        # ìˆ˜ìµì„± ìˆëŠ” ê±°ë˜ í•„í„°ë§
        profitable_trades = []
        current_position = None
        
        for i, day in enumerate(backtest_results):
            # ë§¤ìˆ˜ í¬ì§€ì…˜ ì‹œì‘
            if day.get('actual_decision') == 'BUY':
                current_position = {
                    'entry_date': day.get('date'),
                    'entry_price': day.get('price'),
                    'tech_indicators': day.get('technical_indicators', {}).copy() if day.get('technical_indicators') else {},
                    'news_sentiment': day.get('news_sentiment', {}),
                    'market_trend': day.get('market_trend', 'Unknown')
                }
            
            # ë§¤ë„ë¡œ í¬ì§€ì…˜ ì¢…ë£Œ
            elif day.get('actual_decision') in ['SELL', 'SELL_PROFIT', 'SELL_TRAILING', 'SELL_STOPLOSS'] and current_position:
                profit_pct = ((day.get('price', 0) / current_position['entry_price']) - 1) * 100
                
                # ìˆ˜ìµì´ ë‚¬ë‹¤ë©´ íŒ¨í„´ ë¶„ì„
                if profit_pct > 3.0:  # 3% ì´ìƒ ìˆ˜ìµ
                    trade_info = {
                        'entry_date': current_position['entry_date'],
                        'exit_date': day.get('date'),
                        'profit_pct': profit_pct,
                        'holding_days': self.calculate_holding_days(current_position['entry_date'], day.get('date')),
                        'entry_indicators': current_position['tech_indicators'],
                        'exit_indicators': day.get('technical_indicators', {}),
                        'entry_news': current_position.get('news_sentiment', {}),
                        'market_trend': current_position['market_trend']
                    }
                    profitable_trades.append(trade_info)
                
                current_position = None
        
        # íŒ¨í„´ ë¶„ì„ - ê¸°ìˆ ì  ì§€í‘œ íŒ¨í„´
        pattern_clusters = {}
        
        for trade in profitable_trades:
            # RSI ë²”ìœ„ ê·¸ë£¹í™”
            rsi_entry = 0
            try:
                rsi_entry = float(str(trade['entry_indicators'].get('RSI(14)', 50)).replace(',', ''))
            except:
                rsi_entry = 50
                
            rsi_group = "low" if rsi_entry < 30 else "high" if rsi_entry > 70 else "medium"
            
            # ì‹œì¥ ì¶”ì„¸ ê·¸ë£¹í™”
            trend = trade['market_trend']
            
            # ë‰´ìŠ¤ ê°ì„± ê·¸ë£¹í™”
            news_sentiment = "positive" if trade.get('entry_news', {}).get('sentiment_score', 0) > 0.2 else \
                            "negative" if trade.get('entry_news', {}).get('sentiment_score', 0) < -0.2 else "neutral"
            
            # íŒ¨í„´ í‚¤ ìƒì„±
            pattern_key = f"{rsi_group}_{trend}_{news_sentiment}"
            
            if pattern_key not in pattern_clusters:
                pattern_clusters[pattern_key] = {
                    'trades': [],
                    'avg_profit': 0,
                    'trade_count': 0,
                    'description': f"RSI: {rsi_group}, ì‹œì¥ ì¶”ì„¸: {trend}, ë‰´ìŠ¤ ê°ì„±: {news_sentiment}"
                }
            
            pattern_clusters[pattern_key]['trades'].append(trade)
            pattern_clusters[pattern_key]['trade_count'] += 1
        
        # ê° íŒ¨í„´ ê·¸ë£¹ì˜ í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°
        for key, cluster in pattern_clusters.items():
            if cluster['trade_count'] > 0:
                total_profit = sum(trade['profit_pct'] for trade in cluster['trades'])
                cluster['avg_profit'] = total_profit / cluster['trade_count']
                
                # 3% ì´ìƒì˜ í‰ê·  ìˆ˜ìµë¥ ì„ ê°€ì§„ íŒ¨í„´ë§Œ ì„ íƒ
                if cluster['avg_profit'] >= 3.0 and cluster['trade_count'] >= 3:
                    profitable_patterns.append({
                        'pattern': key,
                        'description': cluster['description'],
                        'avg_profit': cluster['avg_profit'],
                        'trade_count': cluster['trade_count']
                    })
        
        # ìˆ˜ìµë¥  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        profitable_patterns.sort(key=lambda x: x['avg_profit'], reverse=True)
        
        # íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ì €ì¥
        try:
            with open(f"backtest_results/profitable_patterns.json", 'w', encoding='utf-8') as f:
                json.dump(profitable_patterns, f, indent=2)
            print(f"ìˆ˜ìµì„± íŒ¨í„´ ë¶„ì„ ì €ì¥ ì™„ë£Œ: backtest_results/profitable_patterns.json")
        except Exception as e:
            print(f"ìˆ˜ìµì„± íŒ¨í„´ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        return profitable_patterns



    def format_support_info(self, support_analysis):
        """ì§€ì§€ì„  ì •ë³´ë¥¼ ê¹”ë”í•˜ê²Œ í¬ë§·íŒ…"""
        is_near = support_analysis.get('is_near_support', False)
        closest = support_analysis.get('closest_support')
        distance = support_analysis.get('distance_percent')
        strength = support_analysis.get('strength', 0)
        nearby_count = support_analysis.get('nearby_supports_count', 0)
        
        # ì•ˆì „í•œ í¬ë§·íŒ…
        closest_str = f"â‚©{closest:,.0f} KRW" if closest is not None else "N/A"
        distance_str = f"{distance:.2f}%" if distance is not None else "N/A"
        
        return f"""
    Support Level Analysis:
    - Is near support: {is_near}
    - Closest support: {closest_str}
    - Distance: {distance_str}
    - Support strength: {strength:.2f}
    - Nearby supports: {nearby_count}

    """


    def __del__(self):
        """
        ê°ì²´ ì†Œë©¸ ì‹œ ì…€ë ˆë‹ˆì›€ ë“œë¼ì´ë²„ ì¢…ë£Œ ë° íŒŒì„œ ìºì‹œ ì •ë¦¬
        """
        if self.selenium_driver is not None:
            try:
                self.selenium_driver.quit()
                print("Selenium driver closed")
            except:
                pass
        
        # íŒŒì„œ ìºì‹œ ì •ë¦¬ (ì¶”ê°€)
        if hasattr(self, 'trading_parser') and self.trading_parser:
            try:
                self.trading_parser.clear_cache()
                print("Trading parser cache cleared")
            except:
                pass


    def _parse_response_basic(self, response_text):
        """íŒŒì„œê°€ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ íŒŒì‹± ë¡œì§"""
        decision = "HOLD"
        profit_target = 5.0
        stop_loss = -2.0
        trailing_stop = 1.0
        confidence = 0.5
        confidence_text = "MEDIUM"
        reasoning = ""
        
        # ì •ê·œì‹ ê¸°ë°˜ ê¸°ë³¸ íŒŒì‹±
        import re
        
        # ê²°ì • ì¶”ì¶œ
        decision_patterns = [
            r'recommend\s+a?\s*(BUY|SELL|HOLD)', 
            r'I\s+recommend\s+(BUY|SELL|HOLD)',
            r'(?:signal|decision).*?(BUY|SELL|HOLD)'
        ]
        
        for pattern in decision_patterns:
            match = re.search(pattern, response_text, re.IGNORECASE)
            if match:
                decision = match.group(1).upper()
                break
        
        # ë°±ë¶„ìœ¨ ì¶”ì¶œ
        profit_matches = re.findall(r'(?:profit|target).*?(\d+\.?\d*)\%', response_text, re.IGNORECASE)
        if profit_matches:
            try:
                profit_target = float(profit_matches[0])
            except:
                pass
        
        stop_matches = re.findall(r'(?:stop|loss).*?-?(\d+\.?\d*)\%', response_text, re.IGNORECASE)
        if stop_matches:
            try:
                stop_loss = -abs(float(stop_matches[0]))
            except:
                pass
        
        trail_matches = re.findall(r'(?:trailing|trail).*?(\d+\.?\d*)\%', response_text, re.IGNORECASE)
        if trail_matches:
            try:
                trailing_stop = float(trail_matches[0])
            except:
                pass
        
        # ê°„ë‹¨í•œ ì¶”ë¡  ìƒì„±
        reasoning = f"Market analysis completed. {decision} decision based on technical indicators."
        
        return decision, profit_target, stop_loss, trailing_stop, confidence, confidence_text, reasoning
    

    def calculate_atr(self, period=14):
        """ATR (Average True Range) ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < period + 1:
                return 0.05  # ê¸°ë³¸ê°’
            
            # ìµœê·¼ ë°ì´í„°ì—ì„œ TR(True Range) ê³„ì‚°
            recent_data = self.historical_data[-(period + 1):]
            true_ranges = []
            
            for i in range(1, len(recent_data)):
                high = recent_data[i].get('high', recent_data[i].get('close', 0))
                low = recent_data[i].get('low', recent_data[i].get('close', 0))
                prev_close = recent_data[i-1].get('close', 0)
                
                if high > 0 and low > 0 and prev_close > 0:
                    tr1 = high - low
                    tr2 = abs(high - prev_close)
                    tr3 = abs(low - prev_close)
                    true_range = max(tr1, tr2, tr3)
                    true_ranges.append(true_range)
            
            if not true_ranges:
                return 0.05
            
            # ATR = TRë“¤ì˜ í‰ê· 
            atr = sum(true_ranges) / len(true_ranges)
            return atr
            
        except Exception as e:
            print(f"ATR ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.05
        
    def calculate_bollinger_band_position(self, current_price, period=20):
        """ë³¼ë¦°ì € ë°´ë“œ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < period:
                return 0.5, 0, 0  # ì¤‘ê°„ ìœ„ì¹˜, ìƒë‹¨, í•˜ë‹¨
            
            # ìµœê·¼ ê¸°ê°„ì˜ ì¢…ê°€ë“¤
            recent_closes = []
            for data in self.historical_data[-period:]:
                close = data.get('close', data.get('price', 0))
                if close > 0:
                    recent_closes.append(close)
            
            if len(recent_closes) < period:
                return 0.5, 0, 0
            
            # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
            import numpy as np
            closes = np.array(recent_closes)
            sma = np.mean(closes)
            std = np.std(closes)
            
            upper_band = sma + (std * 2)
            lower_band = sma - (std * 2)
            
            # í˜„ì¬ ê°€ê²©ì˜ ë°´ë“œ ë‚´ ìœ„ì¹˜ (0=í•˜ë‹¨, 0.5=ì¤‘ê°„, 1=ìƒë‹¨)
            if upper_band > lower_band:
                bb_position = (current_price - lower_band) / (upper_band - lower_band)
            else:
                bb_position = 0.5
            
            return bb_position, upper_band, lower_band
            
        except Exception as e:
            print(f"ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.5, 0, 0


    def calculate_volume_surge(self, current_volume, period=10):
        """ê±°ë˜ëŸ‰ ê¸‰ì¦ ì—¬ë¶€ ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < period:
                return 1.0  # ê¸°ë³¸ê°’
            
            # ìµœê·¼ ê±°ë˜ëŸ‰ë“¤
            recent_volumes = []
            for data in self.historical_data[-period:]:
                volume = data.get('volume', 0)
                if volume > 0:
                    recent_volumes.append(volume)
            
            if not recent_volumes or current_volume <= 0:
                return 1.0
            
            avg_volume = sum(recent_volumes) / len(recent_volumes)
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1.0
            
            return volume_ratio
            
        except Exception as e:
            print(f"ê±°ë˜ëŸ‰ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return 1.0
        

    def calculate_price_momentum(self, current_price, period=5):
        """ìµœê·¼ ê°€ê²© ëª¨ë©˜í…€ ê³„ì‚°"""
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < period:
                return 0.0
            
            # ìµœê·¼ ê°€ê²©ë“¤
            recent_prices = []
            for data in self.historical_data[-period:]:
                price = data.get('close', data.get('price', 0))
                if price > 0:
                    recent_prices.append(price)
            
            if len(recent_prices) < 2:
                return 0.0
            
            # ê°€ê²© ë³€í™”ìœ¨ ê³„ì‚°
            price_changes = []
            for i in range(1, len(recent_prices)):
                change = (recent_prices[i] / recent_prices[i-1] - 1) * 100
                price_changes.append(change)
            
            if not price_changes:
                return 0.0
            
            # í‰ê·  ëª¨ë©˜í…€
            momentum = sum(price_changes) / len(price_changes)
            return momentum
            
        except Exception as e:
            print(f"ëª¨ë©˜í…€ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
        

    def check_volatility_breakout_trigger(self, current_price, timestamp, current_volume=0):
        """
        ë³€ë™ì„± ëŒíŒŒ ê¸°ë°˜ íŠ¸ë¦¬ê±° ì²´í¬ (ê¸°ì¡´ check_support_trigger ëŒ€ì²´)
        
        Returns:
            bool: ë³€ë™ì„± ëŒíŒŒ íŠ¸ë¦¬ê±° ë°œìƒ ì‹œ True
        """
        try:
            if not hasattr(self, 'historical_data') or len(self.historical_data) < 20:
                return False
            
            print(f"ğŸ” ë³€ë™ì„± ëŒíŒŒ ë¶„ì„ ì¤‘: {timestamp}")
            
            # 1. ATR ê¸°ë°˜ ë³€ë™ì„± ì²´í¬
            current_atr = self.calculate_atr(14)
            baseline_atr = self.calculate_atr(30)  # ë” ê¸´ ê¸°ê°„ì˜ ê¸°ì¤€ì„ 
            
            atr_ratio = current_atr / baseline_atr if baseline_atr > 0 else 1.0
            
            # 2. ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜ ì²´í¬
            bb_position, upper_band, lower_band = self.calculate_bollinger_band_position(current_price)
            
            # 3. ê±°ë˜ëŸ‰ ê¸‰ì¦ ì²´í¬
            volume_ratio = self.calculate_volume_surge(current_volume)
            
            # 4. ê°€ê²© ëª¨ë©˜í…€ ì²´í¬
            momentum = self.calculate_price_momentum(current_price)
            
            # 5. ë³€ë™ì„± ì••ì¶• ì²´í¬ (ë³¼ë¦°ì € ë°´ë“œ í­)
            bb_width = (upper_band - lower_band) / current_price * 100 if current_price > 0 else 0
            
            # íŠ¸ë¦¬ê±° ì¡°ê±´ë“¤
            triggers = []
            trigger_score = 0
            
            # ì¡°ê±´ 1: ATR ê¸‰ì¦ (ê°€ì¥ ê°•í•œ ì‹ í˜¸)
            if atr_ratio >= 2.0:
                triggers.append(f"ATR ê¸‰ì¦ {atr_ratio:.2f}x")
                trigger_score += 3
            elif atr_ratio >= 1.5:
                triggers.append(f"ATR ìƒìŠ¹ {atr_ratio:.2f}x")
                trigger_score += 2
            
            # ì¡°ê±´ 2: ë³¼ë¦°ì € ë°´ë“œ ëŒíŒŒ
            if bb_position >= 1.02:  # ìƒë‹¨ ëŒíŒŒ
                triggers.append(f"ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ ({bb_position:.2f})")
                trigger_score += 2
            elif bb_position <= -0.02:  # í•˜ë‹¨ ëŒíŒŒ
                triggers.append(f"ë³¼ë¦°ì € í•˜ë‹¨ ëŒíŒŒ ({bb_position:.2f})")
                trigger_score += 2
            elif bb_position >= 0.95:  # ìƒë‹¨ ê·¼ì ‘
                triggers.append(f"ë³¼ë¦°ì € ìƒë‹¨ ê·¼ì ‘ ({bb_position:.2f})")
                trigger_score += 1
            elif bb_position <= 0.05:  # í•˜ë‹¨ ê·¼ì ‘
                triggers.append(f"ë³¼ë¦°ì € í•˜ë‹¨ ê·¼ì ‘ ({bb_position:.2f})")
                trigger_score += 1
            
            # ì¡°ê±´ 3: ê±°ë˜ëŸ‰ ê¸‰ì¦
            if volume_ratio >= 3.0:
                triggers.append(f"ê±°ë˜ëŸ‰ ê¸‰ì¦ {volume_ratio:.1f}x")
                trigger_score += 2
            elif volume_ratio >= 2.0:
                triggers.append(f"ê±°ë˜ëŸ‰ ì¦ê°€ {volume_ratio:.1f}x")
                trigger_score += 1
            
            # ì¡°ê±´ 4: ê°€ê²© ëª¨ë©˜í…€
            if abs(momentum) >= 3.0:
                direction = "ìƒìŠ¹" if momentum > 0 else "í•˜ë½"
                triggers.append(f"ê°•í•œ {direction} ëª¨ë©˜í…€ {momentum:+.1f}%")
                trigger_score += 2
            elif abs(momentum) >= 1.5:
                direction = "ìƒìŠ¹" if momentum > 0 else "í•˜ë½"
                triggers.append(f"{direction} ëª¨ë©˜í…€ {momentum:+.1f}%")
                trigger_score += 1
            
            # ì¡°ê±´ 5: ë³€ë™ì„± ì••ì¶• í›„ í™•ì¥
            if bb_width < 2.0 and atr_ratio > 1.2:  # ì••ì¶• í›„ í™•ì¥
                triggers.append(f"ë³€ë™ì„± ì••ì¶•â†’í™•ì¥ (í­:{bb_width:.1f}%)")
                trigger_score += 2
            
            # ìµœì¢… íŠ¸ë¦¬ê±° íŒë‹¨ (ê¸°ì¡´ê³¼ ë¹„ìŠ·í•œ ë¹ˆë„ ìœ ì§€)
            trigger_threshold = 2  # 2ì  ì´ìƒì´ë©´ íŠ¸ë¦¬ê±°
            is_triggered = trigger_score >= trigger_threshold
            
            if is_triggered:
                print(f"ğŸ¯ [ë³€ë™ì„± ëŒíŒŒ íŠ¸ë¦¬ê±°] ì ìˆ˜: {trigger_score}ì ")
                print(f"  ğŸ“Š ì„¸ë¶€ ì¡°ê±´: {', '.join(triggers)}")
                print(f"  ğŸ“ˆ ATR ë¹„ìœ¨: {atr_ratio:.2f}x")
                print(f"  ğŸª ë³¼ë¦°ì € ìœ„ì¹˜: {bb_position:.2f}")
                print(f"  ğŸ“¢ ê±°ë˜ëŸ‰ ë¹„ìœ¨: {volume_ratio:.1f}x")
                print(f"  ğŸš€ ëª¨ë©˜í…€: {momentum:+.1f}%")
            else:
                # 5% í™•ë¥ ë¡œ ë‚®ì€ ì ìˆ˜ë„ ë¡œê¹… (ë””ë²„ê¹…ìš©)
                if trigger_score > 0 and hash(str(timestamp)) % 20 == 0:
                    print(f"ğŸ“Š ë³€ë™ì„± ë¶„ì„: {trigger_score}ì  (ì„ê³„ê°’ ë¯¸ë‹¬)")
                    print(f"  ì¡°ê±´: {', '.join(triggers) if triggers else 'ì—†ìŒ'}")
            
            return is_triggered
            
        except Exception as e:
            print(f"ë³€ë™ì„± ëŒíŒŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return False

    def get_volatility_context_for_ai(self, current_price, current_volume=0):
        """AI ë¶„ì„ìš© ë³€ë™ì„± ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            atr_ratio = self.calculate_atr(14) / max(self.calculate_atr(30), 0.001)
            bb_position, upper_band, lower_band = self.calculate_bollinger_band_position(current_price)
            volume_ratio = self.calculate_volume_surge(current_volume)
            momentum = self.calculate_price_momentum(current_price)
            
            context = f"""
    Volatility Analysis Results:
    - ATR change: {atr_ratio:.2f}x (relative to baseline)
    - Bollinger band position: {bb_position:.2f} (0=bottom, 1=top)
    - Top band: â‚©{upper_band:.0f}, Bottom band: â‚©{lower_band:,.0f}
    - Trading volume change: {volume_ratio:.1f}x (compared to average)
    - Price Momentum: {momentum:+.1f}% (last five-day average)

    Variability Interpretation:
    """

            if atr_ratio >= 2.0:
                context += "- Very high volatility: significant market changes in progress\n"
            elif atr_ratio >= 1.5:
                context += "- high volatility: market movement active\n"
            elif atr_ratio <= 0.7:
                context += "- low volatility: market stability or compression\n"

            if bb_position >= 1.0:
                context += "- Bollinger band top break: strong upward pressure\n"
            elif bb_position <= 0.0:
                context += "- Breaking the bottom of the bolinger band: strong downward pressure\n"
            elif bb_position >= 0.8:
                context += "- close to the top of the bolinger band: likely overbought\n"
            elif bb_position <= 0.2:
                context += "- close to the bottom of the bolinger band: likely oversold\n"

            if volume_ratio >= 3.0:
                context += "- Volume Surge: Strong Market Interest\n"
            elif volume_ratio >= 2.0:
                context += "- Trading volume increase: market activation\n"
            elif volume_ratio <= 0.5:
                context += "- volume decline: market interest also low\n"

            return context
            
        except Exception as e:
            return f"ë³€ë™ì„± ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}"


    def summarize_news_with_ai(self, news_context):
        """Step 1: Detailed news analysis and summarization"""
        if not news_context or not news_context.get('top_news'):
            print("ğŸ“° NEWS ANALYSIS: No significant news")
            return "No significant news impact on market"
        
        print("ğŸ“° NEWS ANALYSIS STAGE 1...")
        print(f"  - Processing {len(news_context['top_news'])} news articles")
        print(f"  - Overall Sentiment: {news_context.get('sentiment_summary', 'neutral')}")
        print(f"  - Total News Count: {news_context.get('news_count', 0)}")
        
        system_msg = """You are a Bitcoin news analyst. Provide comprehensive news impact analysis including:
    1. Overall market sentiment from news
    2. Key developments and their potential impact
    3. Short-term and medium-term implications
    4. Risk factors from news

    Create a detailed 2-3 sentence analysis focusing on market-moving factors."""
        
        # ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ êµ¬ì„±
        news_details = []
        for i, news in enumerate(news_context['top_news'][:5]):
            sentiment_score = news.get('sentiment', 0)
            predicted_impact = news.get('predicted_impact', {})
            
            news_details.append(f"{i+1}. {news['title'][:100]}")
            news_details.append(f"   Sentiment: {sentiment_score:.2f}, Impact: {predicted_impact.get('direction', 'neutral')}")
        
        user_msg = f"""Bitcoin News Analysis:

    NEWS ARTICLES:
    {chr(10).join(news_details)}

    AGGREGATE DATA:
    - Overall Sentiment: {news_context.get('sentiment_summary', 'neutral')}
    - Sentiment Score: {news_context.get('overall_sentiment', 0):.2f}
    - News Count: {news_context.get('news_count', 0)}
    - Key Themes: {', '.join(news_context.get('top_news', [{}])[0].get('themes', []))}

    Provide comprehensive market impact analysis:"""
        
        try:
            response = self.llm(f"{system_msg}\n\n{user_msg}", max_tokens=150, temperature=0.3)
            summary = response["choices"][0]["text"].strip()
            
            print("ğŸ“° DETAILED NEWS ANALYSIS:")
            print(f"  â”œâ”€ Raw sentiment: {news_context.get('sentiment_summary', 'neutral')}")
            print(f"  â”œâ”€ Sentiment Score: {news_context.get('overall_sentiment', 0):.2f}")
            print(f"  â””â”€ AI Analysis: {summary}")
            print()
            
            return summary
        except Exception as e:
            print(f"  âš ï¸  News analysis error: {str(e)}")
            return f"News sentiment: {news_context.get('sentiment_summary', 'neutral')} with {news_context.get('news_count', 0)} articles"
    

    def _apply_dynamic_parameters_for_backtest(self, profit_target, stop_loss, trailing_stop, confluence_signals, market_regime, analysis_context):
        """ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œìš© ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • í•¨ìˆ˜"""
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì¡°ì • (ì¼ë°˜ ì ìš© íŒŒë¼ë¯¸í„° ì¡°ì •)
        profit_target, stop_loss, trailing_stop = self._apply_dynamic_parameters(
            profit_target, stop_loss, trailing_stop, confluence_signals, market_regime, {}
        )
        
        # ë°±í…ŒìŠ¤íŠ¸ íŠ¹í™” ì¡°ì • (í•„ìš”ì‹œ ì¶”ê°€ ì¡°ì •)
        # ì˜ˆ: ë°±í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì¢€ ë” ë³´ìˆ˜ì ì¸ ì„¤ì • ì ìš©
        
        # ë§¤ìš° ì˜¤ë˜ëœ ë°ì´í„°ì¸ ê²½ìš° (2021ë…„ ì´ì „)
        current_date = analysis_context.get('current_date', '')
        if current_date and '2020' in current_date:
            # 2020ë…„ ì´ì „ ë°ì´í„°ëŠ” ë³€ë™ì„±ì´ ë‹¬ëìœ¼ë¯€ë¡œ ì¡°ì •
            profit_target = max(3.0, profit_target * 0.9)  # ìˆ˜ìµ íƒ€ê²Ÿ ì•½ê°„ ê°ì†Œ
            stop_loss = min(-1.0, stop_loss * 0.9)  # ì†ì ˆ ë²”ìœ„ ê°ì†Œ (ëœ ê³µê²©ì )
        
        # íŠ¹ì • ì‹œì¥ í™˜ê²½ì— ë”°ë¥¸ ì¶”ê°€ ì¡°ì •
        regime = market_regime.get('regime', '')
        if 'HIGH_VOLATILITY' in regime:
            # ê³ ë³€ë™ì„± í™˜ê²½ì—ì„œëŠ” íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê°•í™”
            trailing_stop = min(2.0, trailing_stop * 1.2)
        
        return profit_target, stop_loss, trailing_stop


    def comprehensive_analysis_with_ai_with_context(self, coin, price, tech_indicators, news_summary, support_analysis, analysis_context):
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì™€ íŒ¨í„´ ë¶„ì„ì„ í¬í•¨í•œ ì¢…í•© ë¶„ì„ í•¨ìˆ˜"""
        
        print("ğŸ” COMPREHENSIVE ANALYSIS STAGE 2 WITH CONTEXT...")
        print(f"  - Current Price: â‚©{price:,}")
        print(f"  - Support Strength: {support_analysis.get('strength', 0):.2f}")
        print(f"  - Context Date: {analysis_context.get('current_date', 'N/A')}")
        
        # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰ ë° íŒ¨í„´ ê¸°ë°˜ ì¡°ì–¸ ìƒì„±
        similar_patterns = self.find_similar_patterns(tech_indicators, success_weight=True, time_decay=True)
        pattern_advice = self.get_pattern_based_advice(similar_patterns)
        
        # â†“ ê³¼ê±° ë‰´ìŠ¤ ì‚¬ë¡€ ì¶”ê°€
        historical_news_cases = self._get_historical_news_cases(similar_patterns)



        print(f"Pattern-based advice: {pattern_advice['recommendation']} (confidence: {pattern_advice['confidence']:.2f})")
        print(f"Expected profit: {pattern_advice['profit_expectation']:.2f}%, Win rate: {pattern_advice.get('win_rate', 0):.0%}")
        
        system_msg = """You are the world's best Bitcoin trader. Provide comprehensive analysis using ALL provided data.
        Pay special attention to PATTERN-BASED ADVICE which contains historical performance of similar market conditions.
        End with specific trading recommendation in this format:

        DECISION: BUY/SELL/HOLD
        PROFIT_TARGET: X%
        STOP_LOSS: -X% 
        TRAILING_STOP: X%
        CONFIDENCE: 0.X"""
        
        # ê¸°ìˆ ì  ì§€í‘œ ë° ê¸°íƒ€ ë¶„ì„ ê¸°ì¡´ ìœ ì§€...
        rsi = tech_indicators.get('RSI(14)', 'N/A')
        macd = tech_indicators.get('MACD', 'N/A')
        bb = tech_indicators.get('Bollinger Bands', 'N/A')
        ma = tech_indicators.get('Moving Averages', 'N/A')
        volume = tech_indicators.get('Volume', 'N/A')
        volatility = tech_indicators.get('Volatility', 'N/A')
        
        # ê¸°ì¡´ í•¨ìˆ˜ë“¤ í˜¸ì¶œ
        market_trend = self.detect_market_trend(tech_indicators)
        news_sentiment = self.analyze_news_sentiment([])  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ í˜¸ì¶œ
        
        # Confluence ì ìˆ˜ ê³„ì‚°
        confluence_signals = self._calculate_confluence_score(tech_indicators, news_sentiment, support_analysis, market_trend)
        
        # ì‹œì¥ í™˜ê²½ ë¶„ì„
        market_regime = self._detect_market_regime(tech_indicators, self.get_recent_market_context())
        
        # ê±°ë˜ëŸ‰-ê°€ê²© ê´€ê³„
        volume_analysis = self._analyze_volume_price_relationship(tech_indicators, price)
        
        # ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­
        risk_metrics = self._calculate_dynamic_risk_metrics(confluence_signals, market_regime, volume_analysis)
        
        # ìµœì  ë¦¬ìŠ¤í¬-ë¦¬ì›Œë“œ
        optimal_rr = self._calculate_optimal_risk_reward(price, support_analysis, market_regime)

        # ë³€ë™ì„± ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ê¸°ì¡´ user_msgì— ì¶”ê°€)
        volatility_context = analysis_context.get('volatility_context', '')
        
        # ì§€ì§€ì„  ìƒì„¸ ì •ë³´
        support_strength = support_analysis.get('strength', 0)
        support_distance = support_analysis.get('distance_percent', 0)
        is_near_support = support_analysis.get('is_near_support', False)
        closest_support = support_analysis.get('closest_support', 0)
        
        # íŒ¨í„´ ë¶„ì„ ìš”ì•½ êµ¬ì„±
        pattern_summary = "No similar patterns found"
        if similar_patterns:
            completed_patterns = [p for p in similar_patterns if p.get('trade_result', {}).get('completed', False)]
            if completed_patterns:
                successful = [p for p in completed_patterns if p.get('trade_result', {}).get('success', False)]
                win_rate = len(successful) / len(completed_patterns) if completed_patterns else 0
                
                pattern_summary = f"Found {len(completed_patterns)} similar historical patterns with {win_rate:.0%} win rate. "
                pattern_summary += f"Expected profit: {pattern_advice['profit_expectation']:.2f}%. "
                pattern_summary += f"Pattern-based recommendation: {pattern_advice['recommendation']} "
                pattern_summary += f"(confidence: {pattern_advice['confidence']:.2f})"
                
                # ìƒìœ„ íŒ¨í„´ ì„¸ë¶€ ì •ë³´ ì¶”ê°€
                if successful:
                    best_pattern = max(successful, key=lambda p: p.get('trade_result', {}).get('profit_pct', 0))
                    best_profit = best_pattern.get('trade_result', {}).get('profit_pct', 0)
                    pattern_summary += f". Best similar pattern resulted in {best_profit:.2f}% profit."
            else:
                pattern_summary = f"Found {len(similar_patterns)} similar patterns, but none have completed trades yet."
        
        # í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ì •ë³´ í¬í•¨
        current_date = analysis_context.get('current_date', 'Unknown')
        current_time = analysis_context.get('current_time', 'Unknown')
        backtest_mode = analysis_context.get('backtest_mode', False)
        
        user_msg = f"""Bitcoin Comprehensive Analysis - â‚©{price:,.0f}
        TIMESTAMP: {current_date} {current_time}
        ANALYSIS_MODE: {"Backtest" if backtest_mode else "Real-time"}

        TECHNICAL INDICATORS:
        - RSI: {rsi}
        - MACD: {macd}
        - Bollinger Bands: {bb}
        - Moving Averages: {ma}
        - Volume: {volume}
        - Volatility: {volatility}%

        VOLATILITY BREAKOUT ANALYSIS:  
        {volatility_context}

        SUPPORT/RESISTANCE ANALYSIS:
        - Near Support: {is_near_support}
        - Support Level: â‚©{closest_support:,.0f}
        - Support Strength: {support_strength:.1f}/1.0
        - Distance to Support: {support_distance:.1f}%

        NEWS IMPACT ANALYSIS:
        {news_summary}

        MARKET REGIME & CONFLUENCE:
        - Market Regime: {market_regime['regime']} (Confidence: {market_regime['confidence']:.2f})
        - Market Trend: {market_trend}
        - Confluence Score: {confluence_signals['total_score']:.1f}/10
        - Bullish Signals: {confluence_signals['bullish_signals']}
        - Bearish Signals: {confluence_signals['bearish_signals']}

        VOLUME & RISK ANALYSIS:
        - Volume-Price Relationship: {volume_analysis}
        - Position Size Recommendation: {risk_metrics['position_size']:.0f}%
        - Max Loss Tolerance: {risk_metrics['max_loss']:.1f}%
        - Expected Value: {risk_metrics['expected_value']:.2f}%

        PATTERN-BASED ADVICE:
        {pattern_summary}
        Optimized parameters from successful patterns:
        - Recommended profit target: {pattern_advice['params']['profit_target']:.1f}%
        - Recommended stop loss: {pattern_advice['params']['stop_loss']:.1f}%
        - Recommended trailing stop: {pattern_advice['params']['trailing_stop']:.1f}%
        Reasoning: {pattern_advice['reasoning']}

        HISTORICAL PATTERNS:
        - Optimal Risk-Reward Ratio: {optimal_rr['ratio']}:1

        RECENT MARKET CONTEXT:
        {self.get_recent_market_context(days=5)}

        HISTORICAL NEWS IMPACT ANALYSIS:
        {historical_news_cases}

        Based on this comprehensive analysis, provide your detailed reasoning and specific trading recommendation:"""
        
        try:
            response = self.llm(f"{system_msg}\n\n{user_msg}", max_tokens=400, temperature=0.75)
            analysis_text = response["choices"][0]["text"].strip()
            
            print("ğŸ” COMPREHENSIVE ANALYSIS RESULT:")
            print("â”€" * 80)
            print(analysis_text)
            print("â”€" * 80)
            print()
            
            return analysis_text
        except Exception as e:
            print(f"  âš ï¸  Analysis error: {str(e)}")
            return f"Analysis error: {str(e)}"



    def comprehensive_analysis_with_ai(self, coin, price, tech_indicators, news_summary, support_analysis):
        """Step 2: Comprehensive analysis with ALL available data"""
        
        print("ğŸ” COMPREHENSIVE ANALYSIS STAGE 2...")
        print(f"  - Current Price: â‚©{price:,}")
        print(f"  - Support Strength: {support_analysis.get('strength', 0):.2f}")
        print(f"  - News Summary: {news_summary[:50]}...")
        
        system_msg = """You are the world's best Bitcoin trader. Provide comprehensive analysis using ALL provided data.
    End with specific trading recommendation in this format:

    DECISION: BUY/SELL/HOLD
    PROFIT_TARGET: X%
    STOP_LOSS: -X% 
    TRAILING_STOP: X%
    CONFIDENCE: 0.X"""
        
        # === ê¸°ìˆ ì  ì§€í‘œ ìƒì„¸ ë¶„ì„ ===
        rsi = tech_indicators.get('RSI(14)', 'N/A')
        macd = tech_indicators.get('MACD', 'N/A')
        bb = tech_indicators.get('Bollinger Bands', 'N/A')
        ma = tech_indicators.get('Moving Averages', 'N/A')
        volume = tech_indicators.get('Volume', 'N/A')
        volatility = tech_indicators.get('Volatility', 'N/A')
        
        # === ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ë“¤ ===
        # ê¸°ì¡´ í•¨ìˆ˜ë“¤ í˜¸ì¶œ
        market_trend = self.detect_market_trend(tech_indicators)
        news_sentiment = self.analyze_news_sentiment([])  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ í˜¸ì¶œ
        
        # Confluence ì ìˆ˜ ê³„ì‚°
        confluence_signals = self._calculate_confluence_score(tech_indicators, news_sentiment, support_analysis, market_trend)
        
        # ì‹œì¥ í™˜ê²½ ë¶„ì„
        market_regime = self._detect_market_regime(tech_indicators, self.get_recent_market_context())
        
        # ê±°ë˜ëŸ‰-ê°€ê²© ê´€ê³„
        volume_analysis = self._analyze_volume_price_relationship(tech_indicators, price)
        
        # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
        similar_patterns = self.find_similar_patterns(tech_indicators)
        
        # ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­
        risk_metrics = self._calculate_dynamic_risk_metrics(confluence_signals, market_regime, volume_analysis)
        
        # ìµœì  ë¦¬ìŠ¤í¬-ë¦¬ì›Œë“œ
        optimal_rr = self._calculate_optimal_risk_reward(price, support_analysis, market_regime)
        
        # ì§€ì§€ì„  ìƒì„¸ ì •ë³´
        support_strength = support_analysis.get('strength', 0)
        support_distance = support_analysis.get('distance_percent', 0)
        is_near_support = support_analysis.get('is_near_support', False)
        closest_support = support_analysis.get('closest_support', 0)
        
        # ìœ ì‚¬ íŒ¨í„´ ìš”ì•½
        pattern_summary = "No similar patterns found"
        if similar_patterns:
            pattern_summary = f"Found {len(similar_patterns)} similar patterns with avg similarity {sum(p.get('similarity_score', 0) for p in similar_patterns)/len(similar_patterns):.2f}"
        
        user_msg = f"""Bitcoin Comprehensive Analysis - â‚©{price:,.0f}

    TECHNICAL INDICATORS:
    - RSI: {rsi}
    - MACD: {macd}
    - Bollinger Bands: {bb}
    - Moving Averages: {ma}
    - Volume: {volume}
    - Volatility: {volatility}%

    SUPPORT/RESISTANCE ANALYSIS:
    - Near Support: {is_near_support}
    - Support Level: â‚©{closest_support:,.0f}
    - Support Strength: {support_strength:.1f}/1.0
    - Distance to Support: {support_distance:.1f}%

    NEWS IMPACT ANALYSIS:
    {news_summary}

    MARKET REGIME & CONFLUENCE:
    - Market Regime: {market_regime['regime']} (Confidence: {market_regime['confidence']:.2f})
    - Market Trend: {market_trend}
    - Confluence Score: {confluence_signals['total_score']:.1f}/10
    - Bullish Signals: {confluence_signals['bullish_signals']}
    - Bearish Signals: {confluence_signals['bearish_signals']}

    VOLUME & RISK ANALYSIS:
    - Volume-Price Relationship: {volume_analysis}
    - Position Size Recommendation: {risk_metrics['position_size']:.0f}%
    - Max Loss Tolerance: {risk_metrics['max_loss']:.1f}%
    - Expected Value: {risk_metrics['expected_value']:.2f}%

    HISTORICAL PATTERNS:
    - {pattern_summary}
    - Optimal Risk-Reward Ratio: {optimal_rr['ratio']}:1

    RECENT MARKET CONTEXT:
    {self.get_recent_market_context(days=5)}

    Based on this comprehensive analysis, provide your detailed reasoning and specific trading recommendation:"""
        
        try:
            response = self.llm(f"{system_msg}\n\n{user_msg}", max_tokens=400, temperature=0.75)
            analysis_text = response["choices"][0]["text"].strip()
            
            print("ğŸ” COMPREHENSIVE ANALYSIS RESULT:")
            print("â”€" * 80)
            print(analysis_text)
            print("â”€" * 80)
            print()
            
            return analysis_text
        except Exception as e:
            print(f"  âš ï¸  Analysis error: {str(e)}")
            return f"Analysis error: {str(e)}"

    def extract_trading_decision(self, analysis_text):
        """Step 3: Extract trading decision from analysis"""
        
        print("âš™ï¸  DECISION EXTRACTION STAGE 3...")
        
        # ì •ê·œì‹ìœ¼ë¡œ ë°”ë¡œ íŒŒì‹± (2ë‹¨ê³„ ê²°ê³¼ê°€ ì´ë¯¸ ì™„ë²½í•¨)
        import re
        
        decision = re.search(r'DECISION:\s*(BUY|SELL|HOLD)', analysis_text, re.IGNORECASE)
        profit = re.search(r'PROFIT_TARGET:\s*(\d+\.?\d*)%?', analysis_text, re.IGNORECASE)
        stop = re.search(r'STOP_LOSS:\s*-?(\d+\.?\d*)%?', analysis_text, re.IGNORECASE)
        trailing = re.search(r'TRAILING_STOP:\s*(\d+\.?\d*)%?', analysis_text, re.IGNORECASE)
        confidence = re.search(r'CONFIDENCE:\s*(\d+\.?\d*)', analysis_text, re.IGNORECASE)
        
        result = {
            "decision": decision.group(1).upper() if decision else "HOLD",
            "profit_target": float(profit.group(1)) if profit else 5.0,
            "stop_loss": -abs(float(stop.group(1))) if stop else -2.0,
            "trailing_stop": float(trailing.group(1)) if trailing else 1.0,
            "confidence": float(confidence.group(1)) if confidence else 0.5,
            "reasoning": "Extracted from comprehensive analysis"
        }
        
        print("âœ… REGEX PARSING SUCCESS:")
        print(f"  â”œâ”€ Decision: {result['decision']}")
        print(f"  â”œâ”€ Profit Target: {result['profit_target']}%")
        print(f"  â”œâ”€ Stop Loss: {result['stop_loss']}%")
        print(f"  â”œâ”€ Trailing Stop: {result['trailing_stop']}%")
        print(f"  â””â”€ Confidence: {result['confidence']:.2f}")
        print()
        
        return result



    def analyze_with_llm(self, coin, price, tech_indicators, news_data, test_mode=False):
        """3-stage AI analysis with complete output visibility"""
        if not self.llm:
            return {"signal": "ERROR", "analysis": "LLM not initialized", "confidence": 0}

        print("\n" + "="*70)
        print(f"ğŸš€ STARTING 3-STAGE AI ANALYSIS - {coin}")
        print("="*70)

        # ê¸°ì¡´ ë¶„ì„ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€)
        market_trend = self.detect_market_trend(tech_indicators)
        news_sentiment = self.analyze_news_sentiment(news_data)
        support_analysis = self._check_near_support_level_enhanced(coin, price)

        # í˜„ì¬ ì‹œì  í™•ì¸ - ë°±í…ŒìŠ¤íŠ¸ ì¤‘ì¸ ê²½ìš° ì˜¬ë°”ë¥¸ ì‹œì  ì‚¬ìš©
        current_datetime = datetime.datetime.now()
        
        # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ì‹œì  ê°€ì ¸ì˜¤ê¸° (ìµœìš°ì„ )
        if hasattr(self, 'backtest_results') and self.backtest_results:
            last_result = self.backtest_results[-1]
            if 'timestamp' in last_result:
                current_datetime = pd.to_datetime(last_result['timestamp'])
            elif 'date' in last_result:
                # ë‚ ì§œ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬
                if isinstance(last_result['date'], str):
                    current_datetime = pd.to_datetime(last_result['date'])
                else:
                    current_datetime = last_result['date']
            elif 'datetime' in last_result:
                current_datetime = last_result['datetime']
        
        # historical_dataì—ì„œ ì‹œì  ê°€ì ¸ì˜¤ê¸° (ëŒ€ì•ˆ)
        elif hasattr(self, 'historical_data') and self.historical_data:
            last_data = self.historical_data[-1]
            if 'datetime' in last_data:
                current_datetime = last_data['datetime']
            elif 'date' in last_data:
                current_datetime = pd.to_datetime(last_data['date'])
        
        print(f"[CONTEXT] Using datetime: {current_datetime.strftime('%Y-%m-%d %H:%M:%S')}")

        # === 1ë‹¨ê³„: ë‰´ìŠ¤ ìš”ì•½ ===
        news_context = self.get_news_context_for_ai(current_datetime, lookback_days=3)
        news_summary = self.summarize_news_with_ai(news_context)

        # === 2ë‹¨ê³„: ì¢…í•© ë¶„ì„ + ê²°ì • ===
        comprehensive_analysis = self.comprehensive_analysis_with_ai(
            coin, price, tech_indicators, news_summary, support_analysis
        )

        # === 3ë‹¨ê³„: JSON ì¶”ì¶œ ===
        decision_result = self.extract_trading_decision(comprehensive_analysis)

        # === ê²°ê³¼ ì²˜ë¦¬ ===
        decision = decision_result.get('decision', 'HOLD')
        profit_target = decision_result.get('profit_target', 5.0)
        stop_loss = decision_result.get('stop_loss', -2.0)
        trailing_stop = decision_result.get('trailing_stop', 1.0)
        confidence = decision_result.get('confidence', 0.5)
        reasoning = decision_result.get('reasoning', 'AI 3-stage analysis completed')

        # ì†ì ˆê°€ ìŒìˆ˜ ê²€ì¦
        if stop_loss > 0:
            print(f"WARNING: Stop loss was positive ({stop_loss}%), converting to negative")
            stop_loss = -abs(stop_loss)

        # ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • (ê¸°ì¡´ ì½”ë“œ)
        confluence_signals = self._calculate_confluence_score(tech_indicators, news_sentiment, support_analysis, market_trend)
        market_regime = self._detect_market_regime(tech_indicators, self.get_recent_market_context())

        profit_target, stop_loss, trailing_stop = self._apply_dynamic_parameters(
            profit_target, stop_loss, trailing_stop, 
            confluence_signals, market_regime, {}
        )

        # === ìµœì¢… ê²°ê³¼ ì¶œë ¥ ===
        print("ğŸ¯ FINAL TRADING DECISION:")
        print("="*70)
        print(f"SIGNAL: {decision}")
        print(f"CONFIDENCE: {confidence:.2f}")
        print(f"PROFIT TARGET: {profit_target}%")
        print(f"STOP LOSS: {stop_loss}%")
        print(f"TRAILING STOP: {trailing_stop}%")
        print(f"MARKET TREND: {market_trend}")
        print(f"NEWS SUMMARY: {news_summary[:100]}...")
        print("="*70)
        print()

        # í˜„ì¬ íŒ¨í„´ì„ document_storeì— ì¶”ê°€ (RAG í•™ìŠµ)
        if tech_indicators:
            # í˜„ì¬ ì‹œì¥ ì¶”ì„¸ ê°ì§€
            market_trend = self.detect_market_trend(tech_indicators)
            
            # ì§€ì§€ì„  ì •ë³´ ì¶”ê°€
            current_price_val = None
            if hasattr(self, 'historical_data') and len(self.historical_data) > 0:
                current_price_val = self.historical_data[-1].get('price', self.historical_data[-1].get('close'))
            else:
                current_price_val = price
            
            if current_price_val:
                support_analysis_for_rag = self._check_near_support_level_enhanced(coin, current_price_val)
            else:
                support_analysis_for_rag = {}
            
            new_context = {
                'date': current_datetime.strftime("%Y-%m-%d"),
                'indicators': tech_indicators,
                'market_trend': market_trend,
                'support_analysis': support_analysis_for_rag,
                'content': f"Market shows {market_trend} with RSI at {tech_indicators.get('RSI(14)', 'N/A')}. "
                        f"MACD is {tech_indicators.get('MACD', 'N/A')}. "
                        f"Bollinger Bands: {tech_indicators.get('Bollinger Bands', 'N/A')}. "
                        f"Moving Averages: {tech_indicators.get('Moving Averages', 'N/A')}. "
                        f"Support level nearby: {support_analysis_for_rag.get('is_near_support', False)}, "
                        f"Support strength: {support_analysis_for_rag.get('strength', 0):.2f}."
            }
            
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì‚¬
            existing_index = -1
            for i, doc in enumerate(self.document_store):
                if doc.get('date') == new_context['date']:
                    existing_index = i
                    break
            
            if existing_index >= 0:
                # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
                self.document_store[existing_index] = new_context
            else:
                # ìƒˆ í•­ëª© ì¶”ê°€
                self.document_store.append(new_context)

        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "signal": decision,
            "profit_target": profit_target,
            "stop_loss": stop_loss,
            "trailing_stop": trailing_stop,
            "analysis": comprehensive_analysis,  # 2ë‹¨ê³„ ì „ì²´ í…ìŠ¤íŠ¸
            "confidence": confidence,
            "market_trend": market_trend,
            "news_sentiment": news_sentiment,
            "reasoning": reasoning,
            "support_analysis": support_analysis,
            "news_summary": news_summary,  # 1ë‹¨ê³„ ê²°ê³¼
            "confluence_score": confluence_signals.get('total_score', 0),
            "market_regime": market_regime
        }

    # ê³ ê¸‰ íˆ¬ìì „ëµ ì§€ì› í•¨ìˆ˜ë“¤

    def _assess_support_risk(self, closest_support, current_price, strength):
        """ì§€ì§€ì„  ê¸°ë°˜ ë¦¬ìŠ¤í¬ í‰ê°€"""
        if closest_support <= 0:
            return "No clear support - HIGH RISK"
        
        distance_pct = abs((current_price - closest_support) / current_price) * 100
        
        # ê±°ë¦¬ì™€ ê°•ë„ë¥¼ ì¢…í•©í•œ ë¦¬ìŠ¤í¬ í‰ê°€
        if strength >= 0.8 and distance_pct <= 2.0:
            return "VERY LOW RISK - Strong nearby support"
        elif strength >= 0.6 and distance_pct <= 3.0:
            return "LOW RISK - Good support level"
        elif strength >= 0.4 and distance_pct <= 5.0:
            return "MEDIUM RISK - Moderate support"
        elif distance_pct > 10.0:
            return "HIGH RISK - Support too far away"
        else:
            return "HIGH RISK - Weak support level"

    def _format_similar_patterns(self, similar_patterns):
        """ìœ ì‚¬ íŒ¨í„´ì„ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        if not similar_patterns or len(similar_patterns) == 0:
            return "No matching patterns found in historical data"
        
        formatted = "Historical Patterns (Most Similar):\n"
        for i, pattern in enumerate(similar_patterns[:3]):  # ìƒìœ„ 3ê°œë§Œ
            date = pattern.get('date', 'Unknown')
            score = pattern.get('similarity_score', 0)
            content = pattern.get('content', '')
            
            # íŒ¨í„´ ë‚´ìš©ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
            if 'uptrend' in content.lower() or 'bullish' in content.lower():
                signal_hint = "BULLISH"
            elif 'downtrend' in content.lower() or 'bearish' in content.lower():
                signal_hint = "BEARISH"
            else:
                signal_hint = "NEUTRAL"
            
            formatted += f"  {i+1}. Date: {date}, Similarity: {score:.1f}, Signal: {signal_hint}\n"
            formatted += f"     Pattern: {content[:100]}{'...' if len(content) > 100 else ''}\n"
        
        return formatted

    def _synthesize_patterns_and_context(self, similar_patterns, context_string):
        """íŒ¨í„´ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ì œê³µ"""
        synthesis = "INTEGRATED ANALYSIS:\n"
        
        # íŒ¨í„´ ë¶„ì„
        if similar_patterns and len(similar_patterns) > 0:
            bullish_patterns = 0
            bearish_patterns = 0
            
            for pattern in similar_patterns[:5]:
                content = pattern.get('content', '').lower()
                if 'bullish' in content or 'uptrend' in content or 'buy' in content:
                    bullish_patterns += 1
                elif 'bearish' in content or 'downtrend' in content or 'sell' in content:
                    bearish_patterns += 1
            
            if bullish_patterns > bearish_patterns:
                synthesis += f"- Historical Pattern Bias: BULLISH ({bullish_patterns} vs {bearish_patterns})\n"
            elif bearish_patterns > bullish_patterns:
                synthesis += f"- Historical Pattern Bias: BEARISH ({bearish_patterns} vs {bullish_patterns})\n"
            else:
                synthesis += f"- Historical Pattern Bias: NEUTRAL ({bullish_patterns} vs {bearish_patterns})\n"
        else:
            synthesis += "- Historical Patterns: No clear precedent found\n"
        
        # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        if context_string:
            # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            context_lower = context_string.lower()
            
            if 'strong bullish' in context_lower or 'bullish signal' in context_lower:
                synthesis += "- Market Context: Strong bullish indicators detected\n"
            elif 'bearish' in context_lower:
                synthesis += "- Market Context: Bearish conditions present\n"
            elif 'neutral' in context_lower:
                synthesis += "- Market Context: Neutral market conditions\n"
            else:
                synthesis += "- Market Context: Mixed signals requiring careful analysis\n"
            
            # ë³¼ë¥¨ ë° ì¶”ì„¸ ì •ë³´ ì¶”ì¶œ
            if 'increasing volume' in context_lower:
                synthesis += "- Volume Context: Rising volume supports current move\n"
            elif 'decreasing volume' in context_lower:
                synthesis += "- Volume Context: Declining volume shows weak conviction\n"
        else:
            synthesis += "- Enhanced Context: Limited additional context available\n"
        
        # ì¢…í•© ê²°ë¡ 
        synthesis += "\nCONTEXT-PATTERN CONCLUSION:\n"
        synthesis += "Integrating historical patterns with current market context for optimal decision making."
        
        return synthesis




    def _calculate_confluence_score(self, tech_indicators, news_sentiment, support_analysis, market_trend):
        """ë‹¤ì¤‘ ì‹ í˜¸ ì ìˆ˜ ê³„ì‚° ì‹œìŠ¤í…œ"""
        score = {
            'technical_score': 0.0,
            'fundamental_score': 0.0,
            'risk_score': 0.0,
            'bullish_signals': 0,
            'bearish_signals': 0,
            'total_score': 0.0
        }
        
        # Technical Score (5ì  ë§Œì )
        rsi_value = tech_indicators.get('RSI(14)', 50)
        try:
            rsi_num = float(str(rsi_value).replace(',', ''))
            if rsi_num < 30:
                score['technical_score'] += 1.5
                score['bullish_signals'] += 1
            elif rsi_num > 70:
                score['technical_score'] -= 1.5
                score['bearish_signals'] += 1
        except:
            pass
        
        macd = tech_indicators.get('MACD', '')
        if 'Bullish' in str(macd):
            score['technical_score'] += 1.0
            score['bullish_signals'] += 1
        elif 'Bearish' in str(macd):
            score['technical_score'] -= 1.0
            score['bearish_signals'] += 1
        
        bb = tech_indicators.get('Bollinger Bands', '')
        if 'lower' in str(bb).lower():
            score['technical_score'] += 0.8
            score['bullish_signals'] += 1
        elif 'upper' in str(bb).lower():
            score['technical_score'] -= 0.8
            score['bearish_signals'] += 1
        
        # Moving Average Analysis
        ma = tech_indicators.get('Moving Averages', '')
        if 'Price > MA' in str(ma):
            score['technical_score'] += 0.7
            score['bullish_signals'] += 1
        elif 'Price < MA' in str(ma):
            score['technical_score'] -= 0.7
            score['bearish_signals'] += 1
        
        # Fundamental Score (3ì  ë§Œì )
        sentiment_score = news_sentiment.get('sentiment_score', 0)
        if sentiment_score > 0.3:
            score['fundamental_score'] += 1.5
            score['bullish_signals'] += 1
        elif sentiment_score < -0.3:
            score['fundamental_score'] -= 1.5
            score['bearish_signals'] += 1
        
        # Support Analysis
        if support_analysis.get('is_near_support', False):
            strength = support_analysis.get('strength', 0)
            score['fundamental_score'] += strength * 1.5
            if strength > 0.6:
                score['bullish_signals'] += 1
        
        # Risk Score (2ì  ë§Œì )
        if 'uptrend' in market_trend.lower():
            score['risk_score'] += 1.0
        elif 'downtrend' in market_trend.lower():
            score['risk_score'] -= 1.0
        
        # Volume confirmation
        volume = tech_indicators.get('Volume', '')
        if 'increasing' in str(volume).lower():
            score['risk_score'] += 1.0
            score['bullish_signals'] += 1
        elif 'decreasing' in str(volume).lower():
            score['risk_score'] -= 0.5
        
        # Calculate total score (normalized to 10)
        raw_total = score['technical_score'] + score['fundamental_score'] + score['risk_score']
        score['total_score'] = max(0, min(10, (raw_total + 5) * 2))  # Normalize to 0-10 scale
        
        return score

    def _detect_market_regime(self, tech_indicators, recent_context):
        """ì‹œì¥ í™˜ê²½ ê°ì§€"""
        regime = {
            'regime': 'RANGING',
            'confidence': 0.5,
            'characteristics': []
        }
        
        # Volatility analysis
        volatility = tech_indicators.get('Volatility', 0)
        try:
            vol_num = float(str(volatility).replace(',', ''))
            if vol_num > 50:
                regime['regime'] = 'HIGH_VOLATILITY'
                regime['characteristics'].append('Extreme volatility')
                regime['confidence'] += 0.2
            elif vol_num < 20:
                regime['regime'] = 'LOW_VOLATILITY'
                regime['characteristics'].append('Consolidation phase')
                regime['confidence'] += 0.1
        except:
            pass
        
        # Trend strength analysis
        ma_data = tech_indicators.get('Moving Averages', '')
        if 'Price > MA5 > MA10 > MA20' in str(ma_data):
            regime['regime'] = 'STRONG_UPTREND'
            regime['confidence'] = 0.9
            regime['characteristics'].append('Strong bullish alignment')
        elif 'Price < MA5 < MA10 < MA20' in str(ma_data):
            regime['regime'] = 'STRONG_DOWNTREND'
            regime['confidence'] = 0.9
            regime['characteristics'].append('Strong bearish alignment')
        
        # Recent context analysis
        if recent_context and 'uptrend' in recent_context.lower():
            if regime['regime'] == 'RANGING':
                regime['regime'] = 'EMERGING_UPTREND'
            regime['confidence'] += 0.2
        elif recent_context and 'downtrend' in recent_context.lower():
            if regime['regime'] == 'RANGING':
                regime['regime'] = 'EMERGING_DOWNTREND'
            regime['confidence'] += 0.2
        
        regime['confidence'] = min(1.0, max(0.0, regime['confidence']))
        return regime

    def _analyze_volume_price_relationship(self, tech_indicators, price):
        """ê±°ë˜ëŸ‰-ê°€ê²© ê´€ê³„ ë¶„ì„"""
        volume_info = tech_indicators.get('Volume', 'Unknown')
        
        if 'increasing' in str(volume_info).lower():
            return "Price rising with increasing volume - Strong bullish confirmation"
        elif 'decreasing' in str(volume_info).lower():
            return "Volume declining - Weak price action, potential reversal"
        elif 'high' in str(volume_info).lower():
            return "High volume present - Significant market interest"
        else:
            return "Normal volume conditions"

    def _calculate_dynamic_risk_metrics(self, confluence_signals, market_regime, volume_analysis):
        """ë™ì  ìœ„í—˜ ê´€ë¦¬ ë©”íŠ¸ë¦­"""
        metrics = {
            'position_size': 100.0,  # Default 100%
            'max_loss': 2.0,         # Default 2%
            'expected_value': 0.0
        }
        
        # Adjust position size based on confluence score
        confluence_score = confluence_signals['total_score']
        if confluence_score >= 8.0:
            metrics['position_size'] = 100.0  # Full position
        elif confluence_score >= 6.0:
            metrics['position_size'] = 75.0   # 3/4 position
        elif confluence_score >= 4.0:
            metrics['position_size'] = 50.0   # Half position
        else:
            metrics['position_size'] = 25.0   # Quarter position
        
        # Adjust max loss based on market regime
        if market_regime['regime'] in ['STRONG_UPTREND', 'STRONG_DOWNTREND']:
            metrics['max_loss'] = 1.5  # Tighter stop in trending markets
        elif market_regime['regime'] == 'HIGH_VOLATILITY':
            metrics['max_loss'] = 3.0  # Wider stop in volatile markets
        
        # Calculate expected value (simplified)
        win_rate = 0.4 + (confluence_score / 25.0)  # Base 40% + confluence bonus
        avg_win = 3.0    # Average 3% win
        avg_loss = metrics['max_loss']
        metrics['expected_value'] = (win_rate * avg_win) - ((1 - win_rate) * avg_loss)
        
        return metrics

    def _analyze_rsi_advanced(self, rsi_value, price):
        """ê³ ê¸‰ RSI ë¶„ì„ (ë‹¤ì´ë²„ì „ìŠ¤ í¬í•¨)"""
        if rsi_value < 20:
            return "EXTREME OVERSOLD - High probability reversal", "VERY_STRONG"
        elif rsi_value < 30:
            return "OVERSOLD - Bullish signal", "STRONG"
        elif rsi_value > 80:
            return "EXTREME OVERBOUGHT - High probability reversal", "VERY_STRONG"
        elif rsi_value > 70:
            return "OVERBOUGHT - Bearish signal", "STRONG"
        elif 30 <= rsi_value <= 70:
            return "NEUTRAL - No clear signal", "WEAK"
        else:
            return "UNDEFINED", "NONE"

    def _analyze_macd_advanced(self, macd):
        """ê³ ê¸‰ MACD ë¶„ì„ (ëª¨ë©˜í…€ í¬í•¨)"""
        if 'Bullish crossover' in str(macd):
            return "STRONG BUY - Fresh bullish momentum", "ACCELERATING"
        elif 'Bearish crossover' in str(macd):
            return "STRONG SELL - Fresh bearish momentum", "DECELERATING"
        elif 'Bullish' in str(macd):
            return "BUY - Above signal line", "POSITIVE"
        elif 'Bearish' in str(macd):
            return "SELL - Below signal line", "NEGATIVE"
        else:
            return "NEUTRAL", "FLAT"

    def _analyze_bollinger_advanced(self, bb, price):
        """ê³ ê¸‰ ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„ (ìŠ¤í€´ì¦ˆ ê°ì§€ í¬í•¨)"""
        if 'lower' in str(bb).lower():
            return "BUY SIGNAL - Near lower band", "POTENTIAL_REVERSAL"
        elif 'upper' in str(bb).lower():
            return "SELL SIGNAL - Near upper band", "POTENTIAL_REVERSAL"
        elif 'between' in str(bb).lower():
            return "NEUTRAL - Between bands", "NORMAL_RANGE"
        else:
            return "ANALYSIS_NEEDED", "UNKNOWN"

    def _calculate_sentiment_momentum(self, news_data):
        """ë‰´ìŠ¤ ê°ì„± ëª¨ë©˜í…€ ê³„ì‚°"""
        if len(news_data) < 2:
            return "INSUFFICIENT_DATA"
        
        # Simple momentum calculation based on recent vs older news
        recent_news = news_data[:len(news_data)//2]
        older_news = news_data[len(news_data)//2:]
        
        # This is a simplified version - would need actual sentiment scores per article
        if len(recent_news) > len(older_news):
            return "INCREASING"
        elif len(recent_news) < len(older_news):
            return "DECREASING"
        else:
            return "STABLE"

    def _news_to_signal(self, sentiment_score, momentum):
        """ë‰´ìŠ¤ ê°ì„±ì„ ê±°ë˜ ì‹ í˜¸ë¡œ ë³€í™˜"""
        if sentiment_score > 0.3:
            if momentum == "INCREASING":
                return "STRONG BUY"
            else:
                return "BUY"
        elif sentiment_score < -0.3:
            if momentum == "INCREASING":
                return "STRONG SELL"
            else:
                return "SELL"
        else:
            return "NEUTRAL"

    def _analyze_support_zones(self, support_analysis, price):
        """ì§€ì§€ì„  êµ¬ê°„ ë¶„ì„"""
        if not support_analysis.get('is_near_support', False):
            return "No significant support zones detected"
        
        strength = support_analysis.get('strength', 0)
        distance = support_analysis.get('distance_percent', 0)
        
        if strength >= 0.8 and distance <= 1.0:
            return "CRITICAL SUPPORT ZONE - Very high probability of bounce"
        elif strength >= 0.6 and distance <= 2.0:
            return "STRONG SUPPORT ZONE - High probability of bounce"
        elif strength >= 0.4 and distance <= 3.0:
            return "MODERATE SUPPORT ZONE - Watch for bounce"
        else:
            return "WEAK SUPPORT ZONE - May not hold"

    def _analyze_market_structure(self, confluence_signals, market_regime):
        """ì‹œì¥ êµ¬ì¡° ë¶„ì„"""
        structure = ""
        
        total_score = confluence_signals['total_score']
        bullish_signals = confluence_signals['bullish_signals']
        bearish_signals = confluence_signals['bearish_signals']
        
        if bullish_signals > bearish_signals + 2:
            structure = "BULLISH MARKET STRUCTURE - Multiple confirming signals"
        elif bearish_signals > bullish_signals + 2:
            structure = "BEARISH MARKET STRUCTURE - Multiple warning signals"
        else:
            structure = "MIXED MARKET STRUCTURE - Conflicting signals"
        
        regime_type = market_regime['regime']
        if regime_type in ['STRONG_UPTREND', 'STRONG_DOWNTREND']:
            structure += f" in {regime_type.replace('_', ' ').title()} regime"
        
        return structure

    def _calculate_optimal_risk_reward(self, price, support_analysis, market_regime):
        """ìµœì  ë¦¬ìŠ¤í¬-ë¦¬ì›Œë“œ ë¹„ìœ¨ ê³„ì‚°"""
        # Default 2:1 ratio
        optimal_ratio = {
            'ratio': 2.0,
            'reasoning': "Standard risk-reward ratio"
        }
        
        # Adjust based on support strength
        if support_analysis.get('is_near_support', False):
            strength = support_analysis.get('strength', 0)
            if strength >= 0.8:
                optimal_ratio['ratio'] = 3.0
                optimal_ratio['reasoning'] = "Strong support allows for better risk-reward"
            elif strength >= 0.6:
                optimal_ratio['ratio'] = 2.5
                optimal_ratio['reasoning'] = "Good support provides favorable risk-reward"
        
        # Adjust based on market regime
        if market_regime['regime'] == 'STRONG_UPTREND':
            optimal_ratio['ratio'] = min(4.0, optimal_ratio['ratio'] + 1.0)
            optimal_ratio['reasoning'] += " - Trending market allows extended targets"
        elif market_regime['regime'] == 'HIGH_VOLATILITY':
            optimal_ratio['ratio'] = max(1.5, optimal_ratio['ratio'] - 0.5)
            optimal_ratio['reasoning'] += " - Volatile conditions require tighter management"
        
        return optimal_ratio

    def _apply_dynamic_parameters(self, profit_target, stop_loss, trailing_stop, confluence_signals, market_regime, risk_metrics):
        """ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì •"""
        # Adjust based on confluence score
        score = confluence_signals['total_score']
        
        if score >= 8.0:
            # High confidence - extend targets
            profit_target = min(15.0, profit_target * 1.2)
            stop_loss = max(-3.0, stop_loss * 0.8)  # Tighter stop
            trailing_stop = min(2.5, trailing_stop * 1.1)
        elif score <= 3.0:
            # Low confidence - conservative targets
            profit_target = max(2.0, profit_target * 0.7)
            stop_loss = min(-1.0, stop_loss * 1.2)  # Wider stop
            trailing_stop = max(0.5, trailing_stop * 0.9)
        
        # Adjust based on market regime
        regime = market_regime['regime']
        if regime == 'STRONG_UPTREND':
            profit_target = min(20.0, profit_target * 1.1)
            trailing_stop = min(3.0, trailing_stop * 1.2)
        elif regime == 'HIGH_VOLATILITY':
            stop_loss = max(-5.0, stop_loss * 1.5)
            trailing_stop = min(3.0, trailing_stop * 1.3)
        
        return profit_target, stop_loss, trailing_stop
    

    def run_backtest(self, start_date=None, end_date=None, data=None, timeframe=None, 
                    test_mode=False, llm_mode=True, initial_position=False):
        """
        ì™„ì „íˆ ìˆ˜ì •ëœ ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ - ë§¤ìˆ˜ ë¬¸ì œ í•´ê²°
        """
        
        # ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„± ìœ ì§€
        if data is not None:
            print("ê¸°ì¡´ ë°±í…ŒìŠ¤íŠ¸ ë°©ì‹ ì‚¬ìš© (ì „ì²´ ë°ì´í„° ì¼ê´„ ë¡œë“œ)")
            return self._run_backtest_legacy_enhanced(data, test_mode, llm_mode, initial_position)
        
        # ìƒˆë¡œìš´ ë°©ì‹: í•˜ë£¨ ë‹¨ìœ„ + ê°•í™”ëœ ì „ëµ
        if start_date is None or end_date is None:
            raise ValueError("start_dateì™€ end_dateëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤")
        
        try:
            current_date = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)
            print(f"ğŸš€ ì™„ì „ ê°•í™”ëœ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘: {current_date.strftime('%Y-%m-%d')} ~ {end_dt.strftime('%Y-%m-%d')}")
        except Exception as e:
            raise ValueError(f"ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {str(e)}")
        
        # ğŸš¨ 1. ì´ˆê°„ë‹¨ ë§¤ë„ í•¨ìˆ˜ ì •ì˜ (ëˆ„ë½ëœ í•¨ìˆ˜)
        def simple_exit_strategy_fixed(current_price, entry_price, entry_date, current_date, 
                                    market_trend, profit_target, stop_loss, confidence,
                                    position_adjustments=None):
            """âœ… AI ì¡°ê±´ ìš°ì„  ì ìš©"""
            
            profit_pct = ((current_price / entry_price) - 1) * 100
            
            # âœ… 1ìˆœìœ„: AI ì†ì ˆ ì¡°ê±´
            if profit_pct <= stop_loss:
                return "SELL_STOPLOSS", f"AI ì†ì ˆë§¤ ({profit_pct:.2f}% â‰¤ {stop_loss:.2f}%)"
            
            # âœ… 2ìˆœìœ„: AI ìµì ˆ ì¡°ê±´  
            if profit_pct >= profit_target:
                return "SELL_PROFIT", f"AI ìµì ˆ ({profit_pct:.2f}% â‰¥ {profit_target:.2f}%)"
            
            # âœ… 3ìˆœìœ„: ì‹œê°„ ì²­ì‚° (ë” ê¸¸ê²Œ, ì‹ ë¢°ë„ ê³ ë ¤)
            try:
                entry_dt = pd.to_datetime(entry_date)
                current_dt = pd.to_datetime(current_date)
                days_held = (current_dt - entry_dt).days
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ë™ì  ë³´ìœ  ê¸°ê°„
                max_hold_days = max(7, int(confidence * 14))  # 7-14ì¼
                
                if days_held >= max_hold_days:
                    return "SELL_TIMEOUT", f"{max_hold_days}ì¼ ê²½ê³¼ ì²­ì‚° ({profit_pct:.2f}%)"
            except:
                pass
            
            return "HOLD", f"ë³´ìœ  ì¤‘ ({profit_pct:.2f}%, ëª©í‘œ: {profit_target:.1f}%, ì†ì ˆ: {stop_loss:.1f}%)"
        
        # ğŸš¨ 2. ê°„ë‹¨í•œ í†µí•© ê²°ì • ì‹œìŠ¤í…œ
        def simple_integrated_decision(analysis_result, pattern_advice, news_sentiment, market_trend, confluence_signals):
            """ê°„ë‹¨í•œ ë§¤ìˆ˜ ê²°ì • - ë„ˆë¬´ ê¹Œë‹¤ë¡­ì§€ ì•Šê²Œ"""
            
            ai_decision = analysis_result.get('signal', 'HOLD')
            confidence = analysis_result.get('confidence', 0.5)
            
            print(f"ğŸ” í†µí•©ê²°ì • ë””ë²„ê¹…:")
            print(f"  â”œâ”€ AIê²°ì •: {ai_decision}")
            print(f"  â”œâ”€ ì‹ ë¢°ë„: {confidence:.2f}")
            print(f"  â”œâ”€ ì‹œì¥ì¶”ì„¸: {market_trend}")
            
            # ğŸš¨ ë§¤ìš° ê´€ëŒ€í•œ ë§¤ìˆ˜ ì¡°ê±´
            should_buy = False
            reasons = []
            
            # ê¸°ë³¸ ì¡°ê±´: AIê°€ BUY ì‹ í˜¸ + ì‹ ë¢°ë„ 0.3 ì´ìƒ
            if ai_decision == "BUY" and confidence >= 0.3:
                should_buy = True
                reasons.append(f"AIë§¤ìˆ˜ì‹ í˜¸+ì‹ ë¢°ë„{confidence:.2f}")
            
            # ì¶”ê°€ ë³´ì •: ë‰´ìŠ¤ê°€ ê¸ì •ì ì´ë©´ ì‹ ë¢°ë„ ë‚®ì•„ë„ OK
            if ai_decision == "BUY" and confidence >= 0.2:
                if news_sentiment.get('sentiment_score', 0) > 0.1:
                    should_buy = True
                    reasons.append("ê¸ì •ë‰´ìŠ¤ë³´ì •")
            
            # ìµœì¢… ì•ˆì „ì¥ì¹˜: ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ë©´ ë¬´ì¡°ê±´ ë§¤ìˆ˜
            if confidence >= 0.8:
                should_buy = True
                reasons.append(f"ê³ ì‹ ë¢°ë„{confidence:.2f}")
            
            print(f"  â”œâ”€ ë§¤ìˆ˜ê²°ì •: {should_buy}")
            print(f"  â””â”€ ê·¼ê±°: {', '.join(reasons) if reasons else 'ì¡°ê±´ë¯¸ë‹¬'}")
            
            return {
                'should_buy': should_buy,
                'total_score': confidence * 100,
                'reasons': reasons,
                'details': f"ê°„ë‹¨í†µí•©ê²°ì •: {'ë§¤ìˆ˜' if should_buy else 'ë³´ë¥˜'}"
            }
        
        # ğŸš¨ 3. ê°„ë‹¨í•œ í¬ì§€ì…˜ ì‚¬ì´ì§•
        def simple_position_sizing(price, confidence, balance):
            """ê°„ë‹¨í•œ í¬ì§€ì…˜ ì‚¬ì´ì§• - í™•ì‹¤íˆ ì‘ë™"""
            
            print(f"ğŸ” í¬ì§€ì…˜ì‚¬ì´ì§• ë””ë²„ê¹…:")
            print(f"  â”œâ”€ í˜„ì¬ê°€ê²©: â‚©{price:,.0f}")
            print(f"  â”œâ”€ ì‹ ë¢°ë„: {confidence:.2f}")
            print(f"  â”œâ”€ ì”ê³ : â‚©{balance:,.0f}")
            
            # ê¸°ë³¸ íˆ¬ì ë¹„ìœ¨: 20% (ì•ˆì „í•˜ê²Œ)
            base_ratio = 0.2
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ì •
            confidence_multiplier = max(0.5, min(1.5, confidence * 2))
            final_ratio = base_ratio * confidence_multiplier
            
            # ìµœëŒ€ 50%ë¡œ ì œí•œ
            final_ratio = min(0.5, final_ratio)
            
            investment_amount = balance * final_ratio
            fee_rate = 0.0005
            
            # ìˆ˜ìˆ˜ë£Œ ê³ ë ¤í•œ ì‹¤ì œ ë§¤ìˆ˜ ê°€ëŠ¥ ê¸ˆì•¡
            available_for_coin = investment_amount / (1 + fee_rate)
            coin_amount = available_for_coin / price
            fee = investment_amount - available_for_coin
            total_cost = investment_amount
            
            print(f"  â”œâ”€ íˆ¬ìë¹„ìœ¨: {final_ratio*100:.1f}%")
            print(f"  â”œâ”€ íˆ¬ìê¸ˆì•¡: â‚©{investment_amount:,.0f}")
            print(f"  â”œâ”€ ì½”ì¸ìˆ˜ëŸ‰: {coin_amount:.8f}")
            print(f"  â”œâ”€ ìˆ˜ìˆ˜ë£Œ: â‚©{fee:,.0f}")
            print(f"  â””â”€ ì´ë¹„ìš©: â‚©{total_cost:,.0f}")
            
            position_adjustments = {
                'fee': fee,
                'profit_target_adjustment': 0,
                'stop_loss_adjustment': 0,
                'investment_ratio': final_ratio
            }
            
            return coin_amount, total_cost, final_ratio, position_adjustments
        
        # RAG íŒ¨í„´ ë°ì´í„° ë¡œë“œ
        try:
            self.load_rag_patterns()
            print("ê¸°ì¡´ RAG íŒ¨í„´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"RAG íŒ¨í„´ ë¡œë“œ ì‹¤íŒ¨: {str(e)}. ìƒˆë¡œìš´ íŒ¨í„´ ì €ì¥ì†Œë¡œ ì‹œì‘")
            if not hasattr(self, 'document_store'):
                self.document_store = []
        
        # Fear & Greed Index ì´ˆê¸°í™”
        self.fear_greed_index = 50
        
        # timeframe ì„¤ì •
        if timeframe is None:
            timeframe = getattr(self, 'timeframe', '1h')
        
        print(f"ğŸ¯ RAG ê¸°ë°˜ ì„ ë³„ì  í˜¸ì¶œ ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print(f"- íƒ€ì„í”„ë ˆì„: {timeframe}")
        print(f"- RAG ê¸°ë°˜ ì‹œì  ì„ ë³„")
        print(f"- ğŸš¨ ê°„ë‹¨í•œ ë§¤ìˆ˜ ì¡°ê±´ ì ìš©")
        
        # ì´ˆê¸°í™”
        backtest_results = []
        
        # ê°•í™”ëœ ê³„ì¢Œ ê´€ë¦¬
        self.initial_balance = getattr(self, 'initial_balance', 10000000)
        self.current_balance = self.initial_balance
        self.coin_amount = 0.0
        self.total_fees_paid = 0.0
        
        print(f"ğŸ’° ì´ˆê¸° ì„¤ì •: ì”ê³ =â‚©{self.current_balance:,.0f}")
        
        # í¬ì§€ì…˜ ê´€ë¦¬ ë³€ìˆ˜
        in_position = initial_position
        entry_price = 0.0
        entry_date = None
        entry_amount_krw = 0.0  
        profit_target = 7.0  # ğŸš¨ ìˆ˜ì •: ë” ë†’ì€ ëª©í‘œ
        stop_loss = -3.0     # ğŸš¨ ìˆ˜ì •: ë” í° ì†ì ˆ
        trailing_stop = 1.0
        self.trailing_stop_price = 0.0
        current_pattern_id = None
        position_adjustments = None
        
        # ê°•í™”ëœ í†µê³„ ë³€ìˆ˜
        ai_calls_count = 0
        trigger_count = 0
        rag_approved_count = 0
        rag_rejected_count = 0
        strong_buy_signals = 0
        confirmed_signals = 0
        unconfirmed_signals = 0
        actual_buy_count = 0  # ğŸš¨ ì¶”ê°€: ì‹¤ì œ ë§¤ìˆ˜ íšŸìˆ˜
        
        # ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë³€ìˆ˜
        self.consecutive_losses = 0
        self.consecutive_wins = 0
        self.breakeven_protection_active = False
        self.partial_profit_taken = False
        self.profit_stagnation_days = 0
        
        # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì´ˆê¸°í™”
        self.backtest_results = []
        
        # ì²˜ë¦¬ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì§‘í•©
        processed_timestamps = set()
        
        # ì¼ë³„ ë°±í…ŒìŠ¤íŒ… ë£¨í”„
        while current_date <= end_dt:
            print(f"\nğŸ“… === ì²˜ë¦¬ ì¤‘: {current_date.strftime('%Y-%m-%d')} ===")
            
            # í•˜ë£¨ ë‹¨ìœ„ ë°ì´í„° ë¡œë”©
            daily_data = self.load_daily_data(current_date.strftime('%Y-%m-%d'), timeframe)
            
            # ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            news_lookback_days = 3
            lookback_start = current_date - datetime.timedelta(days=news_lookback_days)
            daily_news = self.fetch_news("BTC", lookback_start, current_date)
            
            # Fear & Greed Index ì—…ë°ì´íŠ¸
            if not daily_data.empty:
                market_volatility = self.calculate_volatility(daily_data)
                if market_volatility > 0.1:
                    self.fear_greed_index = max(10, self.fear_greed_index - 10)
                elif market_volatility < 0.03:
                    self.fear_greed_index = min(90, self.fear_greed_index + 5)
            
            if daily_data.empty:
                print(f"âš ï¸ {current_date.strftime('%Y-%m-%d')} ë°ì´í„° ì—†ìŒ")
                current_date += datetime.timedelta(days=1)
                continue
            
            # í•˜ë£¨ ë°ì´í„°ë¥¼ historical_dataì— ì¶”ê°€
            for timestamp, row in daily_data.iterrows():
                current_data = {
                    'date': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'datetime': timestamp,
                    'price': row['close'],
                    'close': row['close'],
                    'open': row['open'],
                    'high': row['high'],
                    'low': row['low'],
                    'volume': row['volume']
                }
                
                if hasattr(self, 'historical_data'):
                    self.historical_data.append(current_data)
                else:
                    self.historical_data = [current_data]
            
            # ê° ìº”ë“¤ ì²˜ë¦¬
            daily_candles = list(daily_data.iterrows())
            
            for idx, (timestamp, row) in enumerate(daily_candles):
                timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')
                
                if timestamp_str in processed_timestamps:
                    continue
                
                processed_timestamps.add(timestamp_str)
                price = row['close']
                
                # í˜„ì¬ ìº”ë“¤ ì •ë³´
                current_candle_data = {
                    'open': row['open'],
                    'high': row['high'],
                    'low': row['low'],
                    'close': row['close'],
                    'volume': row['volume']
                }
                
                # ë‹¤ìŒ ìº”ë“¤ ì •ë³´ (ì»¨íŒìš©)
                next_candle_data = None
                if idx < len(daily_candles) - 1:
                    next_timestamp, next_row = daily_candles[idx + 1]
                    next_candle_data = {
                        'open': next_row['open'],
                        'high': next_row['high'],
                        'low': next_row['low'],
                        'close': next_row['close'],
                        'volume': next_row['volume']
                    }
                
                # ê°€ìƒ ê±°ë˜ ë° ê¸°íšŒë¹„ìš© ì¶”ì  ì—…ë°ì´íŠ¸
                self.track_hypothetical_trades(price, timestamp_str)
                
                # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì œí•œ
                if test_mode and ai_calls_count > 10:
                    break
                
                # === í¬ì§€ì…˜ ë³´ìœ  ì¤‘ ë§¤ë„ ë¡œì§ ===
                if in_position:
                    current_portfolio_value = self.current_balance + (self.coin_amount * price)
                    profit_pct = ((price / entry_price) - 1) * 100
                    
                    print(f"ğŸ’ í¬ì§€ì…˜ ë³´ìœ ì¤‘: ìˆ˜ìµë¥  {profit_pct:.2f}%")
                    
                    # ğŸš¨ ìˆ˜ì •ëœ ê°„ë‹¨í•œ ë§¤ë„ ì „ëµ ì‚¬ìš©
                    exit_decision, exit_reason = simple_exit_strategy_fixed(
                        price, entry_price, entry_date, timestamp_str,
                        "Unknown", profit_target, stop_loss, 
                        getattr(self, 'last_confidence', 0.5),
                        position_adjustments
                    )
                    
                    # ì™„ì „ ë§¤ë„ ì²˜ë¦¬
                    if exit_decision != "HOLD":
                        fee_rate = 0.0005
                        sell_amount_krw = self.coin_amount * price
                        fee = sell_amount_krw * fee_rate
                        final_amount = sell_amount_krw - fee
                        
                        # ğŸš¨ ìˆ˜ìµ ê³„ì‚° ë””ë²„ê¹…
                        print(f"ğŸ” ë§¤ë„ ê³„ì‚°:")
                        print(f"  â”œâ”€ ì½”ì¸ìˆ˜ëŸ‰: {self.coin_amount:.8f}")
                        print(f"  â”œâ”€ ë§¤ë„ê°€ê²©: â‚©{price:,.0f}")
                        print(f"  â”œâ”€ ë§¤ë„ê¸ˆì•¡: â‚©{sell_amount_krw:,.0f}")
                        print(f"  â”œâ”€ ìˆ˜ìˆ˜ë£Œ: â‚©{fee:,.0f}")
                        print(f"  â”œâ”€ ì‹¤ìˆ˜ë ¹ì•¡: â‚©{final_amount:,.0f}")
                        print(f"  â”œâ”€ ì›íˆ¬ìê¸ˆ: â‚©{entry_amount_krw:,.0f}")
                        print(f"  â””â”€ ì‹¤ì œìˆ˜ìµ: â‚©{final_amount - entry_amount_krw:,.0f}")
                        
                        self.current_balance += final_amount
                        profit_amount = final_amount - entry_amount_krw  
                        self.coin_amount = 0.0
                        self.total_fees_paid += fee
                        in_position = False
                        
                        # í¬ì§€ì…˜ ê´€ë ¨ í”Œë˜ê·¸ ë¦¬ì…‹
                        self.breakeven_protection_active = False
                        self.partial_profit_taken = False
                        self.profit_stagnation_days = 0
                        
                        print(f"ğŸ“¤ ë§¤ë„ ì™„ë£Œ: ìˆ˜ìµ=â‚©{profit_amount:,.0f} ({profit_pct:.2f}%)")
                        
                        backtest_results.append({
                            'date': timestamp_str,
                            'datetime': timestamp,
                            'price': price,
                            'ai_decision': 'NONE',
                            'actual_decision': exit_decision,
                            'profit_pct': profit_pct,
                            'profit_amount': profit_amount,
                            'confidence': getattr(self, 'last_confidence', 0.5),
                            'entry_price': entry_price,
                            'entry_date': entry_date,
                            'exit_reason': exit_reason,
                            'balance': self.current_balance,
                            'coin_amount': 0.0,
                            'portfolio_value': self.current_balance,
                            'fees_paid': fee
                        })
                        continue
                    
                    continue
                
                # === ğŸš¨ í•µì‹¬ ìˆ˜ì •: RAG ê¸°ë°˜ ì„ ë³„ì  ì§„ì… ë¡œì§ ===
                if not in_position:
                    # ğŸ¯ 1ë‹¨ê³„: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (RAG ì²´í¬ìš©)
                    if len(getattr(self, 'historical_data', [])) > 14:
                        temp_data = []
                        for item in self.historical_data[-30:]:
                            temp_data.append({
                                'close': item['close'],
                                'open': item.get('open', item['close']),
                                'high': item.get('high', item['close']),
                                'low': item.get('low', item['close']),
                                'volume': item.get('volume', 0)
                            })
                        temp_df = pd.DataFrame(temp_data)
                        temp_df, tech_indicators = self.calculate_technical_indicators(temp_df)
                    else:
                        tech_indicators = {}
                    
                    # ğŸ¯ 2ë‹¨ê³„: í˜„ì¬ ìº”ë“¤ ì‹œì ì˜ ë‰´ìŠ¤ í•„í„°ë§
                    candle_news = self._filter_news_for_timestamp(daily_news, timestamp)
                    
                    # ğŸš¨ í•µì‹¬: RAG ê¸°ë°˜ íŠ¸ë¦¬ê±° ì²´í¬
                    rag_trigger, rag_reason = self.rag_based_trigger_check(price, timestamp, tech_indicators, candle_news)
                    print(f"ğŸ” RAG íŠ¸ë¦¬ê±° ê²°ê³¼: {rag_trigger}, ì´ìœ : {rag_reason}")
                    
                    if rag_trigger:
                        # âœ… RAG ìŠ¹ì¸ëœ ê²½ìš°ì—ë§Œ AI ë¶„ì„ ì§„í–‰
                        rag_approved_count += 1
                        trigger_count += 1
                        print(f"ğŸ¯ [RAG ì„ ë³„ íŠ¸ë¦¬ê±° #{trigger_count}] {rag_reason}")
                        
                        # LLM ë¶„ì„ ì‹¤í–‰
                        if llm_mode:
                            ai_calls_count += 1
                            print(f"ğŸ¤– [AI í˜¸ì¶œ #{ai_calls_count}] ê°•í™”ëœ ë¶„ì„ ì‹œì‘...")
                            
                            if len(backtest_results) > 0:
                                self.backtest_results = backtest_results.copy()
                            
                            # ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
                            analysis_context = {
                                'current_datetime': timestamp,
                                'current_date': timestamp.strftime('%Y-%m-%d'),
                                'current_time': timestamp.strftime('%H:%M:%S'),
                                'backtest_mode': True,
                                'fear_greed_index': self.fear_greed_index,
                                'volatility_context': self.get_volatility_context_for_ai(price, current_candle_data.get('volume', 0))
                            }
                            
                            # AI ë¶„ì„ ê²°ê³¼
                            analysis_result = self.analyze_with_llm_with_context(
                                "BTC/KRW", price, tech_indicators, candle_news, analysis_context, test_mode
                            )
                            
                            # AI ê²°ê³¼ íŒŒì‹±
                            ai_decision = analysis_result.get('signal', 'HOLD')
                            confidence = analysis_result.get('confidence', 0.5)
                            profit_target_ai = analysis_result.get('profit_target', 7.0)
                            stop_loss_ai = analysis_result.get('stop_loss', -3.0)
                            market_trend = analysis_result.get('market_trend', 'Unknown')
                            news_sentiment = analysis_result.get('news_sentiment', {})
                            
                            self.last_confidence = confidence
                            
                            print(f"ğŸ¯ AI ê²°ì •: {ai_decision}, ì‹ ë¢°ë„: {confidence:.2f}")
                            
                            # ì»¨íŒ ìº”ë“¤ ì‹œìŠ¤í…œ ì ìš© (ê°„ì†Œí™”)
                            if ai_decision == "BUY" and confidence >= 0.4:
                                confirmed_signals += 1
                                final_ai_decision = "BUY"
                                final_confidence = confidence
                            else:
                                final_ai_decision = ai_decision
                                final_confidence = confidence
                            
                            # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰ (ê°„ì†Œí™”)
                            try:
                                similar_patterns = self.find_similar_patterns(tech_indicators, success_weight=True, time_decay=True)
                                pattern_advice = self.get_pattern_based_advice(similar_patterns)
                            except:
                                pattern_advice = {'success_rate': 0.5, 'avg_return': 0.0}
                            
                            # ğŸš¨ í•µì‹¬: ê°„ë‹¨í•œ í†µí•© ê²°ì •
                            integrated_decision = simple_integrated_decision(
                                analysis_result, pattern_advice, news_sentiment, market_trend, {}
                            )
                            
                            should_buy = integrated_decision['should_buy']
                            print(f"ğŸ¯ í†µí•© ê²°ì •: {integrated_decision['details']}")
                            print(f"   ê·¼ê±°: {', '.join(integrated_decision['reasons'])}")
                            
                            # ğŸš¨ ìˆ˜ì •ëœ ë§¤ìˆ˜ ì‹¤í–‰
                            if should_buy:
                                # ğŸš¨ ì‚¬ì „ ì”ê³  ì²´í¬
                                if self.current_balance < 50000:  # ìµœì†Œ 5ë§Œì›
                                    print(f"âŒ ì”ê³  ë¶€ì¡±ìœ¼ë¡œ ë§¤ìˆ˜ í¬ê¸°: â‚©{self.current_balance:,.0f}")
                                    should_buy = False
                                    rejection_reason = f"ì”ê³  ë¶€ì¡±: â‚©{self.current_balance:,.0f}"
                                else:
                                    print(f"ğŸ’° ë§¤ìˆ˜ ì‹œë„ - í˜„ì¬ ì”ê³ : â‚©{self.current_balance:,.0f}")
                                    
                                    # ğŸš¨ ê°„ë‹¨í•œ í¬ì§€ì…˜ ì‚¬ì´ì§•
                                    coin_amount, total_cost, final_investment_ratio, position_adjustments = simple_position_sizing(
                                        price, final_confidence, self.current_balance
                                    )
                                    
                                    # ğŸš¨ ì¶”ê°€ ì•ˆì „ ê²€ì¦
                                    if total_cost > 0 and coin_amount > 0 and total_cost < self.current_balance:
                                        # ğŸš¨ ì•ˆì „í•œ ë§¤ìˆ˜ ì‹¤í–‰
                                        old_balance = self.current_balance
                                        
                                        self.coin_amount = coin_amount
                                        self.current_balance -= total_cost  
                                        self.total_fees_paid += position_adjustments.get('fee', 0)
                                        
                                        in_position = True
                                        entry_price = price
                                        entry_date = timestamp_str
                                        entry_amount_krw = total_cost  
                                        actual_buy_count += 1
                                        
                                        # ì¡°ì •ëœ ìµì ˆ/ì†ì ˆ ì ìš©
                                        profit_target = profit_target_ai
                                        stop_loss = stop_loss_ai
                                        
                                        strong_buy_signals += 1
                                        print(f"âœ… ë§¤ìˆ˜ ì‹¤í–‰ ì„±ê³µ! (#{actual_buy_count})")
                                        print(f"  â”œâ”€ ì´ ì§€ì¶œ: â‚©{total_cost:,.0f}")
                                        print(f"  â”œâ”€ ì½”ì¸ìˆ˜ëŸ‰: {coin_amount:.8f} BTC")
                                        print(f"  â”œâ”€ í˜„ì¬ ì”ê³ : â‚©{self.current_balance:,.0f}")
                                        print(f"  â””â”€ ì‹ ë¢°ë„: {final_confidence:.2f}")
                                        
                                        backtest_results.append({
                                            'date': timestamp_str,
                                            'datetime': timestamp,
                                            'price': price,
                                            'ai_decision': final_ai_decision,
                                            'actual_decision': 'BUY',
                                            'profit_pct': 0.0,
                                            'confidence': final_confidence,
                                            'market_trend': market_trend,
                                            'profit_target': profit_target,
                                            'stop_loss': stop_loss,
                                            'entry_price': entry_price,
                                            'entry_date': entry_date,
                                            'total_cost': total_cost,  
                                            'coin_amount': coin_amount,
                                            'balance': self.current_balance,
                                            'portfolio_value': self.current_balance + (coin_amount * price),
                                            'fees_paid': position_adjustments.get('fee', 0),
                                            'fear_greed_index': self.fear_greed_index,
                                            'integrated_score': integrated_decision['total_score'],
                                            'rag_approved': True
                                        })
                                    else:
                                        should_buy = False
                                        rejection_reason = "í¬ì§€ì…˜ ì‚¬ì´ì§• ì‹¤íŒ¨"
                                        print(f"âŒ í¬ì§€ì…˜ ì‚¬ì´ì§• ì‹¤íŒ¨: total_cost={total_cost}, coin_amount={coin_amount}")
                            
                            # ê±°ë¶€ëœ ê²½ìš° ê²°ê³¼ ê¸°ë¡
                            if not should_buy:
                                print(f"âŒ ë§¤ìˆ˜ ê±°ë¶€: {rejection_reason if 'rejection_reason' in locals() else 'í†µí•© ê²°ì • ê±°ë¶€'}")
                                
                                backtest_results.append({
                                    'date': timestamp_str,
                                    'datetime': timestamp,
                                    'price': price,
                                    'ai_decision': final_ai_decision,
                                    'actual_decision': 'HOLD_RAG_APPROVED',
                                    'profit_pct': 0.0,
                                    'confidence': final_confidence,
                                    'market_trend': market_trend,
                                    'balance': self.current_balance,
                                    'portfolio_value': self.current_balance,
                                    'rejection_reason': rejection_reason if 'rejection_reason' in locals() else "í†µí•© ê²°ì • ê±°ë¶€",
                                    'fear_greed_index': self.fear_greed_index,
                                    'integrated_score': integrated_decision['total_score'],
                                    'rag_approved': True
                                })
                    
                    else:
                        # âŒ RAG ê±°ë¶€ëœ ê²½ìš°
                        rag_rejected_count += 1
                        # print(f"ğŸš« RAG íŠ¸ë¦¬ê±° ê±°ë¶€ #{rag_rejected_count}: {rag_reason}")
                        
                        # RAG ê±°ë¶€ ê²°ê³¼ë„ ê¸°ë¡ (í†µê³„ìš©)
                        backtest_results.append({
                            'date': timestamp_str,
                            'datetime': timestamp,
                            'price': price,
                            'ai_decision': 'NONE',
                            'actual_decision': 'RAG_REJECTED',
                            'profit_pct': 0.0,
                            'confidence': 0.0,
                            'balance': self.current_balance,
                            'portfolio_value': self.current_balance,
                            'rag_rejection_reason': rag_reason,
                            'rag_approved': False
                        })
            
            # ë‹¤ìŒ ë‚ ì§œë¡œ ì´ë™
            current_date += datetime.timedelta(days=1)
        
        # ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ìµœì¢… í†µê³„
        print(f"\nğŸ‰ === RAG ê¸°ë°˜ ì„ ë³„ì  ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        print(f"ì²˜ë¦¬ ê¸°ê°„: {start_date} ~ {end_date}")
        print(f"RAG ìŠ¹ì¸: {rag_approved_count}íšŒ")
        print(f"RAG ê±°ë¶€: {rag_rejected_count}íšŒ")
        print(f"ìŠ¹ì¸ìœ¨: {rag_approved_count/(rag_approved_count+rag_rejected_count)*100:.1f}%")
        print(f"ì´ AI í˜¸ì¶œ: {ai_calls_count}íšŒ")
        print(f"ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸: {strong_buy_signals}íšŒ")
        print(f"ğŸš¨ ì‹¤ì œ ë§¤ìˆ˜ ì‹¤í–‰: {actual_buy_count}íšŒ")  # ğŸš¨ ì¤‘ìš” ì§€í‘œ ì¶”ê°€
        print(f"ì»¨íŒëœ ì‹ í˜¸: {confirmed_signals}íšŒ")
        print(f"ì´ ìˆ˜ìˆ˜ë£Œ: â‚©{getattr(self, 'total_fees_paid', 0):,.0f}")
        
        # ğŸš¨ ë§¤ìˆ˜ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš° ê²½ê³ 
        if actual_buy_count == 0:
            print(f"ğŸš¨ğŸš¨ğŸš¨ ê²½ê³ : ì‹¤ì œ ë§¤ìˆ˜ê°€ ì „í˜€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print(f"  - ë§¤ìˆ˜ ì¡°ê±´ì´ ë„ˆë¬´ ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            print(f"  - AI ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”")
            print(f"  - ì”ê³  ë¶€ì¡± ë¬¸ì œë¥¼ í™•ì¸í•˜ì„¸ìš”")
        
        # ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚°
        final_price = price if 'price' in locals() else self.initial_balance / 1000000
        final_portfolio_value = self.current_balance + (self.coin_amount * final_price)
        total_return_pct = ((final_portfolio_value / self.initial_balance) - 1) * 100
        
        print(f"ğŸ’° ìµœì¢… ê²°ê³¼:")
        print(f"  â”œâ”€ í˜„ê¸ˆ ì”ê³ : â‚©{self.current_balance:,.0f}")
        print(f"  â”œâ”€ ì½”ì¸ ë³´ìœ : {self.coin_amount:.8f} BTC")
        print(f"  â”œâ”€ ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤: â‚©{final_portfolio_value:,.0f}")
        print(f"  â””â”€ ì´ ìˆ˜ìµë¥ : {total_return_pct:.2f}%")
        
        # RAG íš¨ê³¼ ë¶„ì„
        if rag_approved_count + rag_rejected_count > 0:
            efficiency_pct = (rag_rejected_count/(rag_approved_count+rag_rejected_count))*100
            print(f"ğŸ“Š RAG ì„ ë³„ íš¨ê³¼:")
            print(f"  â”œâ”€ ê¸°ì¡´ ë°©ì‹: ëª¨ë“  íŠ¸ë¦¬ê±°ì—ì„œ AI í˜¸ì¶œ")
            print(f"  â”œâ”€ ìƒˆ ë°©ì‹: {rag_approved_count}ë²ˆë§Œ AI í˜¸ì¶œ ({rag_rejected_count}ë²ˆ ê±°ë¶€)")
            print(f"  â””â”€ íš¨ìœ¨ì„±: {efficiency_pct:.1f}% ë¶ˆí•„ìš”í•œ í˜¸ì¶œ ì œê±°")
        
        # RAG íŒ¨í„´ ë°ì´í„° ì €ì¥
        try:
            self.save_rag_patterns()
            print("âœ… ê°•í™”ëœ RAG íŒ¨í„´ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ RAG íŒ¨í„´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        return backtest_results





    
    
    def calculate_holding_days(self, entry_date, exit_date):
        """
        ë‘ ë‚ ì§œ ì‚¬ì´ì˜ ì¼ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            entry_date (str): ì§„ì… ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD HH:MM:SS í˜•ì‹)
            exit_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD HH:MM:SS í˜•ì‹)
            
        Returns:
            int: ë³´ìœ  ê¸°ê°„(ì¼)
        """
        try:
            # ë‚ ì§œ í¬ë§· ì •ê·œí™” (ì‹œê°„ ë¶€ë¶„ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬)
            if isinstance(entry_date, str) and ' ' in entry_date:
                entry_date = entry_date.split(' ')[0]
            if isinstance(exit_date, str) and ' ' in exit_date:
                exit_date = exit_date.split(' ')[0]
            
            entry_dt = pd.to_datetime(entry_date)
            exit_dt = pd.to_datetime(exit_date)
            
            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta = exit_dt - entry_dt
            return max(0, delta.days)
        except Exception as e:
            print(f"ë‚ ì§œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0



    def _load_reference_data(self, start_date):
        """ì§€í‘œ ê³„ì‚°ìš© ê³¼ê±° ë°ì´í„°ë§Œ ë¡œë“œ (ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ ë¶„ë¦¬)"""
        print("ì§€í‘œ ê³„ì‚°ìš© ê³¼ê±° ë°ì´í„° ë¡œë“œ ì¤‘...")
        pre_start_date = start_date - datetime.timedelta(days=30)
        print(f"ì°¸ì¡° ë°ì´í„° ê¸°ê°„: {pre_start_date.strftime('%Y-%m-%d')} ~ {start_date.strftime('%Y-%m-%d')}")
        
        try:
            pre_data = pyupbit.get_ohlcv(
                "KRW-BTC", 
                interval="day", 
                count=30, 
                to=start_date.strftime('%Y-%m-%d')
            )
            
            if pre_data is not None and not pre_data.empty:
                # historical_data ì´ˆê¸°í™”
                self.historical_data = []
                
                # ê³¼ê±° ë°ì´í„°ë¥¼ historical_dataì— ì¶”ê°€
                for timestamp, row in pre_data.iterrows():
                    # ì¤‘ìš”: ì´ ë°ì´í„°ëŠ” ì°¸ì¡°ìš©ì´ë¯€ë¡œ ì²˜ë¦¬ëœ íƒ€ì„ìŠ¤íƒ¬í”„ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                    data_point = {
                        'date': timestamp.strftime('%Y-%m-%d'),
                        'datetime': timestamp,
                        'price': row['close'],
                        'close': row['close'],
                        'open': row['open'],
                        'high': row['high'],
                        'low': row['low'],
                        'volume': row['volume'],
                        'reference_only': True  # ì°¸ì¡°ìš© í”Œë˜ê·¸ ì¶”ê°€
                    }
                    self.historical_data.append(data_point)
                
                print(f"ì°¸ì¡°ìš© ê³¼ê±° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.historical_data)}ì¼")
            else:
                print("ì°¸ì¡°ìš© ê³¼ê±° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                self.historical_data = []
        except Exception as e:
            print(f"ì°¸ì¡°ìš© ê³¼ê±° ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            self.historical_data = []    

    

    def _run_backtest_legacy(self, data, test_mode=False, llm_mode=True, initial_position=False):
        """
        ê¸°ì¡´ ë°±í…ŒìŠ¤íŠ¸ ë¡œì§ (í˜¸í™˜ì„± ìœ ì§€)
        """
        import time  # ì‹œê°„ ì¸¡ì •ìš© ì¶”ê°€
        
        print(f"Starting news-enhanced backtest with {len(data)} days of data...")
        print(f"LLM mode: {llm_mode}, Initial position: {initial_position}")
        
        # ===== NEW: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ì „ì²´ ê¸°ê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ =====
        if hasattr(data, 'index') and len(data) > 0:
            start_date = data.index[0] if isinstance(data.index[0], pd.Timestamp) else pd.to_datetime(data.iloc[0]['date'])
            end_date = data.index[-1] if isinstance(data.index[-1], pd.Timestamp) else pd.to_datetime(data.iloc[-1]['date'])
            
            print("Collecting news data for the entire backtest period...")
            self.collect_all_news_for_period(start_date, end_date)
            
            print("Analyzing news-price correlations...")
            # Convert DataFrame to list of dicts for correlation analysis
            minute_data_list = []
            for index, row in data.iterrows():
                minute_data_list.append({
                    'datetime': index if isinstance(index, pd.Timestamp) else pd.to_datetime(index),
                    'close': row['close'],
                    'open': row.get('open', row['close']),
                    'high': row.get('high', row['close']),
                    'low': row.get('low', row['close']),
                    'volume': row.get('volume', 0)
                })
            self.analyze_news_price_correlations(minute_data_list)
        
        # ===== í•µì‹¬ ì¶”ê°€: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ê³¼ê±° 30ì¼ ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ =====
        print("ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ê³¼ê±° ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ë°±í…ŒìŠ¤íŠ¸ ì²« ë‚ ì§œ í™•ì¸
        first_date = data.index[0] if isinstance(data.index[0], pd.Timestamp) else pd.to_datetime(data.iloc[0]['date'])
        
        # 30ì¼ ì „ ë‚ ì§œ ê³„ì‚°
        pre_start_date = first_date - datetime.timedelta(days=35)  # ì—¬ìœ ìˆê²Œ 35ì¼
        
        # ê³¼ê±° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            pre_data = pyupbit.get_ohlcv("KRW-BTC", interval="day", count=100, to=first_date.strftime('%Y-%m-%d'))  # 35 â†’ 100ìœ¼ë¡œ ë³€ê²½
            
            if pre_data is not None and not pre_data.empty:
                # historical_data ì´ˆê¸°í™”
                self.historical_data = []
                
                # ê³¼ê±° ë°ì´í„°ë¥¼ historical_dataì— ì¶”ê°€
                for timestamp, row in pre_data.iterrows():
                    data_point = {
                        'date': timestamp.strftime('%Y-%m-%d'),
                        'datetime': timestamp,
                        'price': row['close'],
                        'close': row['close'],
                        'open': row['open'],
                        'high': row['high'],
                        'low': row['low'],
                        'volume': row['volume']
                    }
                    self.historical_data.append(data_point)
                
                print(f"ê³¼ê±° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.historical_data)}ì¼")
            else:
                print("ê³¼ê±° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”")
                self.historical_data = []
        except Exception as e:
            print(f"ê³¼ê±° ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            self.historical_data = []

        # ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ ì´ˆê¸°í™”
        backtest_results = []
        in_position = False  # ì´ˆê¸° í¬ì§€ì…˜ì€ í•­ìƒ Falseë¡œ ì‹œì‘ (ì¤‘ìš” ìˆ˜ì •)
        entry_price = 0.0
        entry_date = None
        profit_target = 5.0
        stop_loss = -2.0
        trailing_stop = 1.0
        self.trailing_stop_price = 0.0
        
        # ì‹œê°„ ì¸¡ì • ì´ˆê¸°í™”
        total_llm_time = 0
        llm_calls = 0
        
        # ì—°ì† ì†ì‹¤ ê´€ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.consecutive_losses = 0
        self.stop_loss_streak = 0
        self.cooldown_until = -1
        self.recovery_factor = 1.0
        
        # ì´ì „ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ (ì»¨í…ìŠ¤íŠ¸ ì œê³µìš©)
        self.backtest_results = []
        
        # ë°±í…ŒìŠ¤íŠ¸ìš© historical_data ê´€ë¦¬
        original_historical_data = self.historical_data.copy() if hasattr(self, 'historical_data') else []
        self.historical_data = []  # ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘ ì ì§„ì ìœ¼ë¡œ ì±„ì›Œì§
        
        # ì§„í–‰ë¥  í‘œì‹œìš© ë³€ìˆ˜
        total_days = len(data)
        progress_step = max(1, int(total_days / 10))
        
        # ì¤‘ê°„ ì €ì¥ ì£¼ê¸° (ì‹œê°„ë§ˆë‹¤ ê²°ê³¼ ì €ì¥)
        last_save_time = time.time()
        save_interval = 3600  # 1ì‹œê°„ë§ˆë‹¤ ì €ì¥
        
        # ë°ì´í„° ë³€í™˜ - DataFrameì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if not isinstance(data, pd.DataFrame):
            if isinstance(data, list) and len(data) > 0:
                try:
                    # ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                    data = pd.DataFrame(data)
                except Exception as e:
                    print(f"Error converting data to DataFrame: {str(e)}")
                    return []
            else:
                print("Invalid data format. Expected DataFrame or list of dictionaries.")
                return []
        
        # ì¸ë±ìŠ¤ ë¦¬ì…‹ - Timestamp ì¸ë±ìŠ¤ ë¬¸ì œ í•´ê²°
        try:
            data = data.reset_index(drop=False)
        except Exception as e:
            print(f"Warning: Could not reset DataFrame index: {str(e)}")
        
        # ì¼ë³„ ë°ì´í„° ì²˜ë¦¬
        for idx, (_, row) in enumerate(data.iterrows()):
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” ì¼ë¶€ ë°ì´í„°ë§Œ ì²˜ë¦¬
            if test_mode and idx > 10:
                break
            
            # ì§„í–‰ë¥  ì¶œë ¥
            if idx % progress_step == 0:
                progress = (idx / total_days) * 100
                print(f"Processing {progress:.1f}% complete... ({idx}/{total_days})")
                
                # ì£¼ê¸°ì  ì €ì¥ (1ì‹œê°„ë§ˆë‹¤)
                current_time = time.time()
                if current_time - last_save_time > save_interval:
                    try:
                        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                        temp_file = f"backtest_results/temp_results_{int(current_time)}.json"
                        print(f"Saving intermediate results to {temp_file}...")
                        
                        # ê¸°ë³¸ ì •ë³´ë§Œ ì €ì¥ (ìš©ëŸ‰ ì¶•ì†Œ)
                        simplified_results = []
                        for day in backtest_results:
                            simplified_day = {k: v for k, v in day.items() if k not in ['technical_indicators', 'analysis']}
                            simplified_results.append(simplified_day)
                        
                        with open(temp_file, 'w', encoding='utf-8') as f:
                            json.dump(simplified_results, f, ensure_ascii=False, indent=2)
                        
                        last_save_time = current_time
                        print("Intermediate results saved successfully")
                    except Exception as e:
                        print(f"Error saving intermediate results: {str(e)}")
            
            # ë‚ ì§œ ë° ê°€ê²© ì¶”ì¶œ
            date = None
            price = None
            
            # ë‚ ì§œ í•„ë“œ í™•ì¸ (ìˆ˜ì •: ì‹¤ì œ ë‚ ì§œ ì‚¬ìš©)
            if 'date' in row:
                date = row['date']
            elif 'Date' in row:
                date = row['Date']
            elif 'datetime' in row:
                date = row['datetime']
            elif 'index' in row and isinstance(row['index'], (pd.Timestamp, datetime.datetime)):
                date = row['index'].strftime('%Y-%m-%d')
            else:
                # ë‚ ì§œ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ì¸ë±ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                date = str(idx)
            
            # ê°€ê²© í•„ë“œ í™•ì¸
            if 'close' in row:
                price = row['close']
            elif 'price' in row:
                price = row['price']
            elif 'Close' in row:
                price = row['Close']
            elif 'Price' in row:
                price = row['Price']
            else:
                print(f"Warning: No price data found for {date}, skipping...")
                continue
                    
            # ë¬¸ìì—´ë¡œ ì €ì¥ëœ ê°€ê²© ì²˜ë¦¬
            if isinstance(price, str):
                try:
                    price = float(price.replace(',', ''))
                except (ValueError, TypeError):
                    print(f"Error converting price to float: {price}")
                    continue
            
            # í˜„ì¬ ë°ì´í„°ë¥¼ historical_dataì— ì¶”ê°€
            current_data = {
                'date': date,
                'datetime': pd.to_datetime(date) if isinstance(date, str) else date,
                'price': price,
                'close': price,
                'open': row.get('open', price),
                'high': row.get('high', price),
                'low': row.get('low', price),
                'volume': row.get('volume', 0)
            }
            self.historical_data.append(current_data)
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¶”ê°€ (ì¤‘ìš” ìˆ˜ì •)
            if len(self.historical_data) > 14:  # RSI ë“±ì„ ê³„ì‚°í•˜ê¸° ìœ„í•œ ìµœì†Œ ë°ì´í„°
                # self.historical_dataë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                temp_data = []
                for item in self.historical_data[-30:]:  # ìµœê·¼ 30ì¼ ë°ì´í„°ë§Œ ì‚¬ìš©
                    temp_data.append({
                        'close': item['close'],
                        'open': item.get('open', item['close']),
                        'high': item.get('high', item['close']),
                        'low': item.get('low', item['close']),
                        'volume': item.get('volume', 0)
                    })
                temp_df = pd.DataFrame(temp_data)
                temp_df, tech_indicators = self.calculate_technical_indicators(temp_df)
            else:
                # ì•„ì§ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ê¸°ìˆ ì  ì§€í‘œ ì‚¬ìš©
                tech_indicators = {}
                    
            # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            current_date_obj = pd.to_datetime(date) if isinstance(date, str) else datetime.datetime.now()
            one_day_before = current_date_obj - datetime.timedelta(days=1)
            try:
                news_data = self.fetch_news("BTC", one_day_before, current_date_obj)
                news_count = len(news_data)
            except:
                news_data = []
                news_count = 0
            
            # ë‰´ìŠ¤ ê°ì„± ë¶„ì„
            news_sentiment = self.analyze_news_sentiment(news_data)
            
            # LLM í•­ìƒ í˜¸ì¶œí•˜ë„ë¡ ìˆ˜ì •
            decision = "HOLD"
            confidence = 0.5
            profit_target_new = 5.0
            stop_loss_new = -2.0
            trailing_stop_new = 1.0
            market_trend = "Unknown"
            analysis = ""
            reasoning = ""
            
            if llm_mode:
                # ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ì €ì¥
                if len(backtest_results) > 0:
                    self.backtest_results = backtest_results.copy()
                
                try:
                    print(f"ë‚ ì§œ {date}: LLM ë¶„ì„ ì¤‘...")  # ë¡œê·¸ ì¶”ê°€
                    start_time = time.time()  # ì‹œê°„ ì¸¡ì • ì‹œì‘
                    
                    analysis_result = self.analyze_with_llm("BTC/KRW", price, tech_indicators, news_data, test_mode)
                    
                    elapsed = time.time() - start_time  # ì†Œìš” ì‹œê°„ ê³„ì‚°
                    print(f"LLM ë¶„ì„ ì™„ë£Œ: {elapsed:.2f}ì´ˆ ì†Œìš”")
                    
                    # ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
                    total_llm_time += elapsed
                    llm_calls += 1
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    decision = analysis_result.get('signal', 'HOLD')
                    confidence = analysis_result.get('confidence', 0.5)
                    profit_target_new = analysis_result.get('profit_target', 5.0)
                    stop_loss_new = analysis_result.get('stop_loss', -2.0)
                    trailing_stop_new = analysis_result.get('trailing_stop', 1.0)
                    market_trend = analysis_result.get('market_trend', 'Unknown')
                    analysis = analysis_result.get('analysis', '')
                    reasoning = analysis_result.get('reasoning', '')
                    news_sentiment = analysis_result.get('news_sentiment', news_sentiment)
                    
                    print(f"AI ë¶„ì„ ê²°ê³¼: {decision} (ì‹ ë¢°ë„: {confidence:.2f})")
                    print(f"ì¡°ì •: ëª©í‘œê°€={profit_target_new}%, ì†ì ˆê°€={stop_loss_new}%, íŠ¸ë ˆì¼ë§={trailing_stop_new}%")
                    if reasoning:
                        print(f"ì¶”ë¡ : {reasoning[:1000]}...")
                except Exception as e:
                    print(f"Error in LLM analysis: {str(e)}")
                    decision = "HOLD"  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            else:
                # LLM ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° ê¸°ì¡´ ë¡œì§ ìœ ì§€
                if 'decision' in row:
                    decision = row['decision']
                elif 'ai_decision' in row:
                    decision = row['ai_decision']
                elif 'signal' in row:
                    decision = row['signal']
                
                confidence = row.get('confidence', 0.5)
                profit_target_new = row.get('profit_target', 5.0)
                stop_loss_new = row.get('stop_loss', -2.0)
                trailing_stop_new = row.get('trailing_stop', 1.0)
                market_trend = row.get('market_trend', 'Unknown')
            
            # ë§¤ìˆ˜/ë§¤ë„ ê²°ì •
            should_buy = False
            should_sell = False
            
            # RSI ê°’ í™•ì¸
            rsi = None
            if 'RSI(14)' in tech_indicators:
                try:
                    rsi = float(str(tech_indicators['RSI(14)']).replace(',', ''))
                except:
                    pass
            
            # ë§¤ìˆ˜ ì¡°ê±´ ì²´í¬ (ì§€ì§€ì„  ì¡°ê±´ í¬í•¨)
            if not in_position and decision == "BUY":
                # ì¿¨ë‹¤ìš´ ì²´í¬
                if hasattr(self, 'cooldown_until') and idx <= self.cooldown_until:
                    print(f"Skipping BUY signal on {date} due to cooldown period")
                # RSI ê¸°ë°˜ ê³¼ë§¤ìˆ˜ ì²´í¬ (85 â†’ 90ìœ¼ë¡œ ì™„í™”)
                elif rsi is not None and rsi > 90:
                    print(f"Skipping BUY signal on {date} due to extreme overbought condition (RSI > 90)")
                # ì—°ì† ì†ì‹¤ ì²´í¬ (ì¡°ê±´ ì™„í™”)
                elif hasattr(self, 'consecutive_losses') and self.consecutive_losses >= 4 and "strong downtrend" in market_trend.lower():  # 3 â†’ 4ë¡œ ë³€ê²½
                    print(f"Skipping BUY signal on {date} during strong downtrend with {self.consecutive_losses} consecutive losses")
                # ì‹ ë¢°ë„ í•„í„°ë§ (0.3 â†’ 0.2ë¡œ ì™„í™”)
                elif confidence < 0.2:
                    print(f"Skipping BUY signal on {date} due to very low confidence: {confidence}")
                # ì§€ì§€ì„  ì¡°ê±´ ê°œì„  - ë‹¤ì¤‘ ì¡°ê±´ ì‚¬ìš©
                else:
                    # ì§€ì§€ì„  ì²´í¬
                    support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                    
                    # ì—¬ëŸ¬ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë§Œ ë§Œì¡±í•˜ë©´ ë§¤ìˆ˜
                    conditions_met = False
                    reasons = []
                    
                    # ì¡°ê±´ 1: ì§€ì§€ì„  ê·¼ì²˜ (ê°•ë„ 0.4 ì´ìƒ)
                    if support_analysis['is_near_support'] and support_analysis['strength'] >= 0.4:
                        conditions_met = True
                        reasons.append(f"Near support (strength: {support_analysis['strength']:.2f})")
                    
                    # ì¡°ê±´ 2: RSI ê³¼ë§¤ë„ (35 â†’ 40ìœ¼ë¡œ ì™„í™”)
                    if rsi is not None and rsi < 40:
                        conditions_met = True
                        reasons.append(f"RSI oversold ({rsi:.1f})")
                    
                    # ì¡°ê±´ 3: ë†’ì€ ì‹ ë¢°ë„ (0.7 â†’ 0.6ìœ¼ë¡œ ì™„í™”)
                    if confidence >= 0.6:
                        conditions_met = True
                        reasons.append(f"High confidence ({confidence:.2f})")
                    
                    # ì¡°ê±´ 4: ê°•í•œ ìƒìŠ¹ ë‰´ìŠ¤ (ì¶”ê°€)
                    if news_sentiment['impact_level'] == "high" and news_sentiment['sentiment_score'] > 0.5:
                        conditions_met = True
                        reasons.append("Strong positive news")
                    
                    # ì¡°ê±´ 5: ì´ì „ ì§€ì§€ì„  ê·¼ì²˜ (ì¶”ê°€)
                    if support_analysis['distance_percent'] is not None and support_analysis['distance_percent'] <= 3.0:
                        conditions_met = True
                        reasons.append(f"Close to support ({support_analysis['distance_percent']:.1f}%)")
                    
                    if conditions_met:
                        reason_str = " & ".join(reasons)
                        print(f"BUY signal approved: {reason_str}")
                        should_buy = True
                    else:
                        print(f"BUY signal rejected: No conditions met (support strength: {support_analysis.get('strength', 0):.2f}, RSI: {rsi}, confidence: {confidence:.2f})")
                        should_buy = False
                                
            if in_position and decision == "SELL":
                # ê³¼ë§¤ë„ ìƒíƒœì—ì„œì˜ ë§¤ë„ ì‹ í˜¸ ì œí•œ
                if rsi is not None and rsi < 15:
                    print(f"Considering SELL signal on {date} carefully due to extreme oversold condition (RSI < 15)")
                    # ì‹ ë¢°ë„ ë‚®ì€ ê²½ìš° ìŠ¤í‚µ
                    if confidence < 0.5:
                        should_sell = False
                    else:
                        should_sell = True
                # ë‰´ìŠ¤ ê°ì„±ì´ ë§¤ìš° ê¸ì •ì ì¸ ê²½ìš° ë§¤ë„ ì‹ í˜¸ í•„í„°ë§ 
                elif news_sentiment['impact_level'] == "high" and news_sentiment['sentiment_score'] > 0.6:
                    print(f"Skipping SELL signal on {date} due to highly positive news sentiment")
                    should_sell = False
                else:
                    should_sell = True
            
            # í¬ì§€ì…˜ ê´€ë¦¬
            if in_position:
                # ìˆ˜ìµë¥  ê³„ì‚°
                profit_pct = ((price / entry_price) - 1) * 100
                
                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì²´í¬
                if hasattr(self, 'trailing_stop_price') and self.trailing_stop_price > 0:
                    if price <= self.trailing_stop_price:
                        print(f"TRAILING STOP triggered on {date}: Sell at {price}, profit: {profit_pct:.2f}%")
                        in_position = False
                        
                        # ì†ìµ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                        loss_state = self.manage_consecutive_losses(profit_pct, idx)
                        print(f"Loss management state: {loss_state}")
                        
                        # ì§€ì§€ì„  ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ê¸°ë¡
                        support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                        backtest_results.append({
                            'date': date,
                            'price': price,
                            'ai_decision': decision,
                            'actual_decision': 'SELL_TRAILING',
                            'profit_pct': profit_pct,
                            'confidence': confidence,
                            'market_trend': market_trend,
                            'profit_target': profit_target,
                            'stop_loss': stop_loss,
                            'trailing_stop': trailing_stop,
                            'entry_price': entry_price,
                            'entry_date': entry_date,
                            'technical_indicators': tech_indicators,
                            'news_count': news_count,
                            'news_sentiment': news_sentiment,
                            'analysis': analysis,
                            'reasoning': reasoning,
                            'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                            'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
                        })
                        continue
                
                # ëª©í‘œê°€ ë„ë‹¬ ì²´í¬
                if profit_pct >= profit_target:
                    print(f"PROFIT TARGET reached on {date}: Sell at {price}, profit: {profit_pct:.2f}%")
                    in_position = False
                    
                    # ì†ìµ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                    loss_state = self.manage_consecutive_losses(profit_pct, idx)
                    print(f"Loss management state: {loss_state}")
                    
                    # ì§€ì§€ì„  ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ê¸°ë¡
                    support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                    backtest_results.append({
                        'date': date,
                        'price': price,
                        'ai_decision': decision,
                        'actual_decision': 'SELL_PROFIT',
                        'profit_pct': profit_pct,
                        'confidence': confidence,
                        'market_trend': market_trend,
                        'profit_target': profit_target,
                        'stop_loss': stop_loss,
                        'trailing_stop': trailing_stop,
                        'entry_price': entry_price,
                        'entry_date': entry_date,
                        'technical_indicators': tech_indicators,
                        'news_count': news_count,
                        'news_sentiment': news_sentiment,
                        'analysis': analysis,
                        'reasoning': reasoning,
                        'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                        'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
                    })
                    continue
                    
                # ì†ì ˆê°€ ë„ë‹¬ ì²´í¬
                if profit_pct <= stop_loss:
                    print(f"STOP LOSS triggered on {date}: Sell at {price}, loss: {profit_pct:.2f}%")
                    in_position = False
                    
                    # ì†ìµ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                    loss_state = self.manage_consecutive_losses(profit_pct, idx)
                    print(f"Loss management state: {loss_state}")
                    
                    # ì§€ì§€ì„  ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ê¸°ë¡
                    support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                    backtest_results.append({
                        'date': date,
                        'price': price,
                        'ai_decision': decision,
                        'actual_decision': 'SELL_STOPLOSS',
                        'profit_pct': profit_pct,
                        'confidence': confidence,
                        'market_trend': market_trend,
                        'profit_target': profit_target,
                        'stop_loss': stop_loss,
                        'trailing_stop': trailing_stop,
                        'entry_price': entry_price,
                        'entry_date': entry_date,
                        'technical_indicators': tech_indicators,
                        'news_count': news_count,
                        'news_sentiment': news_sentiment,
                        'analysis': analysis,
                        'reasoning': reasoning,
                        'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                        'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
                    })
                    continue
                
                # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸
                if hasattr(self, 'trailing_stop_price') and price > self.trailing_stop_price * (1 + trailing_stop/100):
                    # ì ì‘í˜• íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ê³„ì‚°
                    volatility = self.calculate_volatility(backtest_results)
                    self.trailing_stop_price = self.set_adaptive_trailing_stop(price, market_trend, volatility)
                    
                    if hasattr(self, 'debug_mode') and self.debug_mode:
                        print(f"Trailing stop updated to {self.trailing_stop_price:.2f} on {date}")
            
            # ë§¤ìˆ˜ ì‹¤í–‰
            if should_buy:
                in_position = True
                entry_price = price
                entry_date = date
                profit_target = profit_target_new
                stop_loss = stop_loss_new
                trailing_stop = trailing_stop_new
                
                # íšŒë³µ ê³„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¦¬ìŠ¤í¬ ì¡°ì •
                if hasattr(self, 'recovery_factor'):
                    # ë‚®ì€ íšŒë³µ ê³„ìˆ˜ëŠ” ë” ì—„ê²©í•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ì˜ë¯¸
                    if self.recovery_factor < 0.5:
                        profit_target = max(3.0, profit_target * 0.8)  # ë” ë¹ ë¥¸ ìˆ˜ìµ ì‹¤í˜„
                        stop_loss = max(-1.5, stop_loss * 0.8)  # ë” íƒ€ì´íŠ¸í•œ ì†ì ˆë§¤
                
                # ì ì‘í˜• íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì„¤ì •
                volatility = self.calculate_volatility(backtest_results)
                self.trailing_stop_price = self.set_adaptive_trailing_stop(price, market_trend, volatility)
                
                print(f"BUY executed on {date} at {price} (confidence: {confidence})")
                print(f"  Profit target: {profit_target}%, Stop loss: {stop_loss}%, Trailing stop: {trailing_stop}%")
                print(f"  Recovery factor: {getattr(self, 'recovery_factor', 1.0)}")
                
                # ì§€ì§€ì„  ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ê¸°ë¡
                support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                backtest_results.append({
                    'date': date,
                    'price': price,
                    'ai_decision': decision,
                    'actual_decision': 'BUY',
                    'profit_pct': 0.0,
                    'confidence': confidence,
                    'market_trend': market_trend,
                    'profit_target': profit_target,
                    'stop_loss': stop_loss,
                    'trailing_stop': trailing_stop,
                    'entry_price': entry_price,
                    'entry_date': entry_date,
                    'technical_indicators': tech_indicators,
                    'news_count': news_count,
                    'news_sentiment': news_sentiment,
                    'analysis': analysis,
                    'reasoning': reasoning,
                    'recovery_factor': getattr(self, 'recovery_factor', 1.0),
                    'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                    'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
                })
                continue
                
            # ë§¤ë„ ì‹¤í–‰
            if should_sell:
                profit_pct = ((price / entry_price) - 1) * 100
                print(f"SELL executed on {date} at {price}, profit: {profit_pct:.2f}%")
                in_position = False
                
                # ì†ìµ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                loss_state = self.manage_consecutive_losses(profit_pct, idx)
                print(f"Loss management state: {loss_state}")
                
                # ì§€ì§€ì„  ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ê¸°ë¡
                support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
                backtest_results.append({
                    'date': date,
                    'price': price,
                    'ai_decision': decision,
                    'actual_decision': 'SELL',
                    'profit_pct': profit_pct,
                    'confidence': confidence,
                    'market_trend': market_trend,
                    'profit_target': profit_target,
                    'stop_loss': stop_loss,
                    'trailing_stop': trailing_stop,
                    'entry_price': entry_price,
                    'entry_date': entry_date,
                    'technical_indicators': tech_indicators,
                    'news_count': news_count,
                    'news_sentiment': news_sentiment,
                    'analysis': analysis,
                    'reasoning': reasoning,
                    'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                    'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
                })
                continue
            
            # ê·¸ ì™¸ ì¼ë°˜ ê±°ë˜ì¼ ê¸°ë¡ (ì§€ì§€ì„  ì •ë³´ í¬í•¨)
            support_analysis = self._check_near_support_level_enhanced("KRW-BTC", price)
            backtest_results.append({
                'date': date,
                'price': price,
                'ai_decision': decision,
                'actual_decision': 'HOLD',
                'profit_pct': ((price / entry_price) - 1) * 100 if in_position else 0.0,
                'confidence': confidence,
                'market_trend': market_trend,
                'profit_target': profit_target if in_position else profit_target_new,
                'stop_loss': stop_loss if in_position else stop_loss_new,
                'trailing_stop': trailing_stop if in_position else trailing_stop_new,
                'entry_price': entry_price if in_position else 0.0,
                'entry_date': entry_date if in_position else None,
                'technical_indicators': tech_indicators,
                'news_count': news_count,
                'news_sentiment': news_sentiment,
                'analysis': analysis,
                'reasoning': reasoning,
                'in_position': in_position,
                'support_analysis': support_analysis,  # ìƒˆë¡œ ì¶”ê°€
                'support_strength': support_analysis.get('strength', 0)  # ìƒˆë¡œ ì¶”ê°€
            })
            
            # ì ì‘í˜• íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì£¼ê¸°ì  ì—…ë°ì´íŠ¸ (í¬ì§€ì…˜ ìˆëŠ” ê²½ìš°)
            if in_position and idx % 3 == 0:  # 3ì¼ë§ˆë‹¤ ì—…ë°ì´íŠ¸
                volatility = self.calculate_volatility(backtest_results)
                new_trailing_stop = self.set_adaptive_trailing_stop(price, market_trend, volatility)
                
                # ìƒˆ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ì´ í˜„ì¬ë³´ë‹¤ ë†’ì„ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸ (í•˜ë½ ë°©ì§€)
                if new_trailing_stop > self.trailing_stop_price:
                    self.trailing_stop_price = new_trailing_stop
                    if hasattr(self, 'debug_mode') and self.debug_mode:
                        print(f"Periodic trailing stop update to {self.trailing_stop_price:.2f} on {date}")
        
        # ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ original_historical_data ë³µì›
        if original_historical_data:
            self.historical_data = original_historical_data
        
        # ë°±í…ŒìŠ¤íŠ¸ ë§ˆë¬´ë¦¬ - LLM ì„±ëŠ¥ í†µê³„ ì¶”ê°€
        avg_llm_time = total_llm_time / llm_calls if llm_calls > 0 else 0
        print(f"Backtest complete. Processed {len(backtest_results)} days.")
        print(f"LLM ì„±ëŠ¥: ì´ {llm_calls}íšŒ í˜¸ì¶œ, í‰ê·  {avg_llm_time:.2f}ì´ˆ/í˜¸ì¶œ, ì´ ì²˜ë¦¬ ì‹œê°„ {total_llm_time:.2f}ì´ˆ")
        
        # ë‰´ìŠ¤ í†µê³„ ì¶œë ¥ (NEW)
        if hasattr(self, 'news_database'):
            total_news = sum(len(news_list) for news_list in self.news_database.values())
            print(f"ë‰´ìŠ¤ í™œìš©: ì´ {total_news}ê°œ ë‰´ìŠ¤, {len(self.news_database)}ì¼ê°„ ìˆ˜ì§‘")
        
        # í˜„ì¬ í¬ì§€ì…˜ ìƒíƒœ ì¶œë ¥
        if in_position:
            last_price = backtest_results[-1]['price'] if backtest_results else 0
            entry_profit = ((last_price / entry_price) - 1) * 100 if entry_price > 0 else 0
            print(f"Still in position at end of backtest: Entry price: {entry_price}, Current price: {last_price}")
            print(f"Unrealized P/L: {entry_profit:.2f}%")
        else:
            print("No open position at end of backtest.")
        
        # ì¸ê¸°ìˆëŠ” íŠ¸ë ˆì´ë”© íŒ¨í„´ ë¶„ì„
        profitable_patterns = self.identify_profitable_patterns(backtest_results)
        if profitable_patterns:
            print("\n=== ìˆ˜ìµì„± ë†’ì€ íŠ¸ë ˆì´ë”© íŒ¨í„´ TOP 3 ===")
            for i, pattern in enumerate(profitable_patterns[:3]):
                print(f"{i+1}. {pattern['description']}")
                print(f"   í‰ê·  ìˆ˜ìµë¥ : {pattern['avg_profit']:.2f}%, ê±°ë˜ íšŸìˆ˜: {pattern['trade_count']}")
        
        # LLM í†µê³„ ì •ë³´ ì¶”ê°€
        backtest_summary = {
            'llm_calls': llm_calls,
            'avg_llm_time': avg_llm_time,
            'total_llm_time': total_llm_time,
            'days_processed': len(backtest_results),
            'news_articles_processed': total_news if hasattr(self, 'news_database') else 0,  # NEW
            'news_days_covered': len(self.news_database) if hasattr(self, 'news_database') else 0  # NEW
        }
        
        # ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ìš”ì•½ ì •ë³´ ì €ì¥
        try:
            final_result_file = f"backtest_results/final_results_{int(time.time())}.json"
            with open(final_result_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'summary': backtest_summary,
                    'patterns': profitable_patterns[:10] if profitable_patterns else [],
                    # ì „ì²´ ê²°ê³¼ëŠ” ìš©ëŸ‰ ë¬¸ì œë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ
                }, f, ensure_ascii=False, indent=2)
            print(f"Final summary saved to {final_result_file}")
        except Exception as e:
            print(f"Error saving final summary: {str(e)}")
        
        return backtest_results

    
    
    def evaluate_backtest(self, backtest_results, initial_balance=10000000, initial_position=False):
        """
        ğŸš¨ í•„ë“œëª… ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°ëœ ë°±í…ŒìŠ¤íŠ¸ í‰ê°€ í•¨ìˆ˜
        """
        import numpy as np
        import time
        
        if not backtest_results or len(backtest_results) == 0:
            print("No backtest results to evaluate")
            return None
        
        start_time = time.time()
        print(f"ğŸ” ìˆ˜ì •ëœ ë°±í…ŒìŠ¤íŠ¸ í‰ê°€ ì‹œì‘: {len(backtest_results)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì  ë³€ìˆ˜ ì´ˆê¸°í™”
        current_balance = initial_balance
        coin_amount = 0.0
        peak_equity = initial_balance
        
        # ê±°ë˜ ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜
        total_trades = 0
        winning_trades = 0
        losing_trades = 0
        trade_history = []
        current_position = None
        
        # ì—í€´í‹° ì»¤ë¸Œ ì¶”ì 
        equity_curve = []
        max_drawdown_pct = 0
        
        print(f"ì´ˆê¸° ì„¤ì •: ì”ê³ =â‚©{current_balance:,.0f}, ì½”ì¸={coin_amount:.8f}")
        
        # ğŸš¨ í•„ë“œëª… ë§¤í•‘ í•¨ìˆ˜
        def get_investment_amount(result):
            """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ íˆ¬ìê¸ˆì•¡ ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ì§€ì›)"""
            return (result.get('total_cost', 0) or 
                    result.get('investment_amount', 0) or 
                    result.get('entry_amount_krw', 0))
        
        def get_fee_paid(result):
            """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ìˆ˜ìˆ˜ë£Œ ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ì§€ì›)"""
            return (result.get('fees_paid', 0) or 
                    result.get('fee', 0) or 
                    result.get('entry_fee', 0))
        
        # ê° ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì²˜ë¦¬
        for i, result in enumerate(backtest_results):
            decision = result.get('actual_decision', 'HOLD')
            price = result.get('price', 0)
            date = result.get('date', '')
            
            # ğŸš¨ ìˆ˜ì •ëœ ë§¤ìˆ˜ ì²˜ë¦¬ - ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›
            if decision == 'BUY' and current_balance > 0:
                # âœ… ì—¬ëŸ¬ í•„ë“œëª… ì‹œë„í•´ì„œ ë°ì´í„° ì¶”ì¶œ
                investment_amount = get_investment_amount(result)
                coin_bought = result.get('coin_amount', 0)
                fee_paid = get_fee_paid(result)
                
                print(f"ğŸ” ë§¤ìˆ˜ ë°ì´í„° í™•ì¸ [{i}]:")
                print(f"  â”œâ”€ investment_amount: {investment_amount}")
                print(f"  â”œâ”€ coin_amount: {coin_bought}")
                print(f"  â”œâ”€ fee_paid: {fee_paid}")
                print(f"  â””â”€ total_cost í•„ë“œ: {result.get('total_cost', 'NONE')}")
                
                # âœ… ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
                if investment_amount > 0 and coin_bought > 0:
                    current_position = {
                        'entry_date': date,
                        'entry_price': price,
                        'entry_amount_krw': investment_amount,
                        'coin_amount': coin_bought,
                        'fee_paid': fee_paid
                    }
                    
                    # âœ… ì •í™•í•œ ê¸ˆì•¡ ì°¨ê°
                    current_balance = current_balance - investment_amount
                    coin_amount = coin_bought
                    
                    print(f"âœ… ë§¤ìˆ˜ ì²˜ë¦¬ ì™„ë£Œ: {date}")
                    print(f"  â”œâ”€ ê°€ê²©: â‚©{price:,.0f}")
                    print(f"  â”œâ”€ íˆ¬ìê¸ˆ: â‚©{investment_amount:,.0f}")
                    print(f"  â”œâ”€ ì½”ì¸ìˆ˜ëŸ‰: {coin_bought:.8f}")
                    print(f"  â”œâ”€ ìˆ˜ìˆ˜ë£Œ: â‚©{fee_paid:,.0f}")
                    print(f"  â””â”€ ë‚¨ì€ì”ê³ : â‚©{current_balance:,.0f}")
                else:
                    print(f"âŒ ë§¤ìˆ˜ ë°ì´í„° ë¶€ì¡±: {date}")
                    print(f"  â”œâ”€ investment_amount: {investment_amount}")
                    print(f"  â””â”€ coin_amount: {coin_bought}")
            
            # ğŸš¨ ìˆ˜ì •ëœ ë§¤ë„ ì²˜ë¦¬
            elif decision in ['SELL', 'SELL_PROFIT', 'SELL_TRAILING', 'SELL_STOPLOSS', 'SELL_TIMEOUT'] and coin_amount > 0:
                profit_pct = result.get('profit_pct', 0)
                profit_amount = result.get('profit_amount', 0)
                
                print(f"ğŸ” ë§¤ë„ ë°ì´í„° í™•ì¸ [{i}]:")
                print(f"  â”œâ”€ ê²°ì •: {decision}")
                print(f"  â”œâ”€ ìˆ˜ìµë¥ : {profit_pct:.2f}%")
                print(f"  â”œâ”€ ìˆ˜ìµê¸ˆ: â‚©{profit_amount:,.0f}")
                print(f"  â””â”€ ë³´ìœ ì½”ì¸: {coin_amount:.8f}")
                
                # current_position ì •ë³´ë¡œ ê±°ë˜ ê¸°ë¡
                if current_position:
                    final_amount = current_position['entry_amount_krw'] + profit_amount
                    
                    trade_history.append({
                        'type': decision,
                        'entry_date': current_position['entry_date'],
                        'exit_date': date,
                        'entry_price': current_position['entry_price'],
                        'exit_price': price,
                        'profit_pct': profit_pct,
                        'profit_amount': profit_amount,
                        'entry_amount': current_position['entry_amount_krw'],
                        'exit_amount': final_amount,
                        'total_fees': current_position.get('fee_paid', 0)
                    })
                    
                    print(f"âœ… ë§¤ë„ ì²˜ë¦¬ ì™„ë£Œ: {date}")
                    print(f"  â”œâ”€ ì§„ì…ê°€: â‚©{current_position['entry_price']:,.0f}")
                    print(f"  â”œâ”€ ë§¤ë„ê°€: â‚©{price:,.0f}")
                    print(f"  â”œâ”€ íˆ¬ìì›ê¸ˆ: â‚©{current_position['entry_amount_krw']:,.0f}")
                    print(f"  â”œâ”€ íšŒìˆ˜ê¸ˆì•¡: â‚©{final_amount:,.0f}")
                    print(f"  â””â”€ ìˆœìˆ˜ìµ: â‚©{profit_amount:,.0f} ({profit_pct:.2f}%)")
                else:
                    print(f"âŒ ë§¤ë„ ì‹œ í¬ì§€ì…˜ ì •ë³´ ì—†ìŒ: {date}")
                    # ê¸°ë³¸ ê³„ì‚°ìœ¼ë¡œ ì²˜ë¦¬
                    sell_amount_krw = coin_amount * price
                    fee = sell_amount_krw * 0.0005
                    final_amount = sell_amount_krw - fee
                    
                    trade_history.append({
                        'type': decision,
                        'entry_date': 'Unknown',
                        'exit_date': date,
                        'entry_price': 0,
                        'exit_price': price,
                        'profit_pct': profit_pct,
                        'profit_amount': final_amount,
                        'entry_amount': 0,
                        'exit_amount': final_amount,
                        'total_fees': fee
                    })
                
                # í¬ì§€ì…˜ ì •ë¦¬
                current_balance += current_position['entry_amount_krw'] + profit_amount if current_position else final_amount
                coin_amount = 0
                current_position = None
                
                total_trades += 1
                if profit_pct > 0:
                    winning_trades += 1
                else:
                    losing_trades += 1
            
            # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚°
            current_equity = current_balance + (coin_amount * price)
            
            # ìµœëŒ€ ë‚™í­ ê³„ì‚°
            if current_equity > peak_equity:
                peak_equity = current_equity
            elif peak_equity > 0:
                drawdown = ((current_equity / peak_equity) - 1) * 100
                max_drawdown_pct = min(max_drawdown_pct, drawdown)
            
            # ì—í€´í‹° ì»¤ë¸Œ ê¸°ë¡
            if decision != 'HOLD' or len(equity_curve) == 0 or len(equity_curve) % 24 == 0:
                equity_curve.append({
                    'date': date,
                    'price': price,
                    'equity': current_equity,
                    'decision': decision,
                    'balance': current_balance,
                    'coin_amount': coin_amount
                })
        
        # ìµœì¢… ê³„ì‚°
        if len(backtest_results) > 0:
            final_price = backtest_results[-1].get('price', 0)
            final_equity = current_balance + (coin_amount * final_price)
        else:
            final_equity = initial_balance
        
        # ë¯¸ê²°ì œ í¬ì§€ì…˜ ì²˜ë¦¬
        unrealized_pnl = 0
        if coin_amount > 0 and current_position and final_price > 0:
            unrealized_pnl = ((final_price / current_position['entry_price']) - 1) * 100
            print(f"âš ï¸ ë¯¸ê²°ì œ í¬ì§€ì…˜ ë°œê²¬:")
            print(f"  â”œâ”€ ì§„ì…ê°€: â‚©{current_position['entry_price']:,.0f}")
            print(f"  â”œâ”€ í˜„ì¬ê°€: â‚©{final_price:,.0f}")
            print(f"  â””â”€ ë¯¸ì‹¤í˜„ì†ìµ: {unrealized_pnl:.2f}%")
        
        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
        total_return_pct = ((final_equity / initial_balance) - 1) * 100
        
        # í‰ê·  ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°
        avg_profit = 0
        avg_loss = 0
        if winning_trades > 0:
            winning_trades_data = [t for t in trade_history if t['profit_pct'] > 0]
            avg_profit = sum(t['profit_pct'] for t in winning_trades_data) / len(winning_trades_data)
        if losing_trades > 0:
            losing_trades_data = [t for t in trade_history if t['profit_pct'] <= 0]
            avg_loss = sum(t['profit_pct'] for t in losing_trades_data) / len(losing_trades_data)
        
        # ì†ìµë¹„ ê³„ì‚°
        profit_factor = 0
        if trade_history:
            total_profit = sum(t['profit_amount'] for t in trade_history if t['profit_amount'] > 0)
            total_loss = abs(sum(t['profit_amount'] for t in trade_history if t['profit_amount'] < 0))
            if total_loss > 0:
                profit_factor = total_profit / total_loss
            elif total_profit > 0:
                profit_factor = float('inf')
        
        # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
        sharpe_ratio = 0
        if len(trade_history) > 1:
            returns = [trade['profit_pct'] for trade in trade_history]
            if returns:
                mean_return = np.mean(returns)
                std_dev = np.std(returns) if len(returns) > 1 else 0.001
                if std_dev > 0:
                    sharpe_ratio = mean_return / std_dev
        
        execution_time = time.time() - start_time
        
        # ğŸš¨ ìƒì„¸ ê±°ë˜ ë‚´ì—­ ì¶œë ¥
        print(f"\nğŸ“Š === ê±°ë˜ ë‚´ì—­ ìƒì„¸ ===")
        for i, trade in enumerate(trade_history, 1):
            print(f"ê±°ë˜ #{i}: {trade['entry_date']} â†’ {trade['exit_date']}")
            print(f"  â”œâ”€ {trade['entry_price']:,.0f} â†’ {trade['exit_price']:,.0f}")
            print(f"  â”œâ”€ íˆ¬ì: â‚©{trade['entry_amount']:,.0f}")
            print(f"  â””â”€ ê²°ê³¼: â‚©{trade['profit_amount']:,.0f} ({trade['profit_pct']:+.2f}%)")
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ’° === ìˆ˜ì •ëœ ë°±í…ŒìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼ ===")
        print(f"ì´ˆê¸° ìë³¸: â‚©{initial_balance:,.0f}")
        print(f"ìµœì¢… ìë³¸: â‚©{final_equity:,.0f}")
        print(f"í˜„ê¸ˆ ì”ê³ : â‚©{current_balance:,.0f}")
        print(f"ì½”ì¸ ë³´ìœ : {coin_amount:.8f} BTC (â‚©{coin_amount * final_price:,.0f})")
        print(f"ì´ ìˆ˜ìµë¥ : {total_return_pct:.2f}%")
        print(f"ìµœëŒ€ ë‚™í­: {max_drawdown_pct:.2f}%")
        print(f"ê±°ë˜ íšŸìˆ˜: {total_trades}")
        print(f"ìŠ¹ë¥ : {win_rate:.2f}%")
        print(f"í‰ê·  ìˆ˜ìµ: {avg_profit:.2f}%")
        print(f"í‰ê·  ì†ì‹¤: {avg_loss:.2f}%")
        print(f"ì†ìµë¹„: {profit_factor:.2f}")
        print(f"ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ratio:.2f}")
        
        return {
            'initial_balance': initial_balance,
            'final_balance': final_equity,
            'cash_balance': current_balance,
            'coin_amount': coin_amount,
            'final_price': final_price,
            'total_return': final_equity - initial_balance,
            'total_return_pct': total_return_pct,
            'max_drawdown_pct': max_drawdown_pct,
            'trade_count': total_trades,
            'winning_trades': winning_trades,
            'losing_trades': losing_trades,
            'win_rate': win_rate,
            'profit_factor': profit_factor,
            'sharpe_ratio': sharpe_ratio,
            'avg_profit': avg_profit,
            'avg_loss': avg_loss,
            'equity_curve': equity_curve,
            'trades': trade_history,
            'execution_time': execution_time,
            'unrealized_pnl_pct': unrealized_pnl
        }

    # ì‚¬ìš©ë²•:
    # ê¸°ì¡´ í•¨ìˆ˜ ëŒ€ì‹  ì´ê±¸ ì‚¬ìš©í•˜ì„¸ìš”
    # results = trader.evaluate_backtest_fixed(backtest_results)

    
    import matplotlib.pyplot as plt
    import matplotlib.dates as mdates
    import pandas as pd
    import numpy as np
    from datetime import datetime
    import os

    def plot_backtest_results(results, trades_df=None, save_dir="backtest_results"):
        """
        ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)
        
        Parameters:
        - results: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        - trades_df: ê±°ë˜ ë‚´ì—­ DataFrame (ì„ íƒì‚¬í•­)
        - save_dir: ì €ì¥ ë””ë ‰í† ë¦¬
        """
        try:
            # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            
            # Figure ì„¤ì •
            plt.style.use('default')
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle(f'ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ - ìˆ˜ìµë¥ : {results.get("total_return", 0):.2f}%', 
                        fontsize=16, fontweight='bold')
            
            # 1. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™” (ì¢Œìƒë‹¨)
            ax1 = axes[0, 0]
            if 'portfolio_values' in results and results['portfolio_values']:
                dates = results.get('dates', [])
                portfolio_values = results['portfolio_values']
                
                if dates and len(dates) == len(portfolio_values):
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                    if isinstance(dates[0], str):
                        dates = [pd.to_datetime(date) for date in dates]
                    
                    ax1.plot(dates, portfolio_values, linewidth=2, color='blue', label='í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜')
                    ax1.axhline(y=results.get('initial_capital', 10000000), 
                            color='red', linestyle='--', alpha=0.7, label='ì´ˆê¸° ìë³¸')
                    ax1.set_title('í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”')
                    ax1.set_ylabel('í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ (â‚©)')
                    ax1.legend()
                    ax1.grid(True, alpha=0.3)
                    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
                    ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
                    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
                else:
                    ax1.text(0.5, 0.5, 'í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax1.transAxes)
            else:
                ax1.text(0.5, 0.5, 'í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax1.transAxes)
            
            # 2. ê±°ë˜ë³„ ìˆ˜ìµë¥  (ìš°ìƒë‹¨)
            ax2 = axes[0, 1]
            if trades_df is not None and len(trades_df) > 0:
                trade_returns = []
                trade_dates = []
                
                for _, trade in trades_df.iterrows():
                    if 'profit_pct' in trade:
                        trade_returns.append(trade['profit_pct'])
                        if 'sell_date' in trade:
                            trade_dates.append(pd.to_datetime(trade['sell_date']))
                        else:
                            trade_dates.append(pd.to_datetime(trade.get('exit_date', datetime.now())))
                
                if trade_returns:
                    colors = ['green' if r > 0 else 'red' for r in trade_returns]
                    bars = ax2.bar(range(len(trade_returns)), trade_returns, color=colors, alpha=0.7)
                    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
                    ax2.set_title(f'ê±°ë˜ë³„ ìˆ˜ìµë¥  (ì´ {len(trade_returns)}íšŒ)')
                    ax2.set_ylabel('ìˆ˜ìµë¥  (%)')
                    ax2.set_xlabel('ê±°ë˜ ë²ˆí˜¸')
                    ax2.grid(True, alpha=0.3)
                    
                    # ìˆ˜ìµ/ì†ì‹¤ í†µê³„ í‘œì‹œ
                    wins = [r for r in trade_returns if r > 0]
                    losses = [r for r in trade_returns if r < 0]
                    win_rate = len(wins) / len(trade_returns) * 100 if trade_returns else 0
                    ax2.text(0.02, 0.98, f'ìŠ¹ë¥ : {win_rate:.1f}%\ní‰ê· ìˆ˜ìµ: {np.mean(wins):.2f}%\ní‰ê· ì†ì‹¤: {np.mean(losses):.2f}%' if losses else f'ìŠ¹ë¥ : {win_rate:.1f}%\ní‰ê· ìˆ˜ìµ: {np.mean(wins):.2f}%', 
                            transform=ax2.transAxes, verticalalignment='top', 
                            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            else:
                ax2.text(0.5, 0.5, 'ê±°ë˜ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax2.transAxes)
            
            # 3. ì›”ë³„ ìˆ˜ìµë¥  (ì¢Œí•˜ë‹¨)
            ax3 = axes[1, 0]
            if trades_df is not None and len(trades_df) > 0:
                monthly_returns = {}
                
                for _, trade in trades_df.iterrows():
                    if 'profit_pct' in trade and 'sell_date' in trade:
                        sell_date = pd.to_datetime(trade['sell_date'])
                        month_key = sell_date.strftime('%Y-%m')
                        
                        if month_key not in monthly_returns:
                            monthly_returns[month_key] = 0
                        monthly_returns[month_key] += trade['profit_pct']
                
                if monthly_returns:
                    months = sorted(monthly_returns.keys())
                    returns = [monthly_returns[month] for month in months]
                    colors = ['green' if r > 0 else 'red' for r in returns]
                    
                    ax3.bar(range(len(months)), returns, color=colors, alpha=0.7)
                    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)
                    ax3.set_title('ì›”ë³„ ìˆ˜ìµë¥ ')
                    ax3.set_ylabel('ìˆ˜ìµë¥  (%)')
                    ax3.set_xlabel('ì›”')
                    ax3.set_xticks(range(len(months)))
                    ax3.set_xticklabels(months, rotation=45)
                    ax3.grid(True, alpha=0.3)
            else:
                ax3.text(0.5, 0.5, 'ì›”ë³„ ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax3.transAxes)
            
            # 4. ì£¼ìš” í†µê³„ (ìš°í•˜ë‹¨)
            ax4 = axes[1, 1]
            ax4.axis('off')
            
            # í†µê³„ ì •ë³´ ì¤€ë¹„
            stats_text = f"""
            ğŸ† ë°±í…ŒìŠ¤íŠ¸ ì£¼ìš” ê²°ê³¼
            
            ğŸ“Š ìˆ˜ìµì„± ì§€í‘œ:
            â€¢ ì´ ìˆ˜ìµë¥ : {results.get('total_return', 0):.2f}%
            â€¢ ìµœì¢… ìë³¸: â‚©{results.get('final_capital', 0):,.0f}
            â€¢ ì´ˆê¸° ìë³¸: â‚©{results.get('initial_capital', 10000000):,.0f}
            
            ğŸ“ˆ ê±°ë˜ ì„±ê³¼:
            â€¢ ì´ ê±°ë˜ íšŸìˆ˜: {results.get('total_trades', 0)}íšŒ
            â€¢ ìŠ¹ë¥ : {results.get('win_rate', 0):.1f}%
            â€¢ í‰ê·  ìˆ˜ìµ: {results.get('avg_profit', 0):.2f}%
            â€¢ í‰ê·  ì†ì‹¤: {results.get('avg_loss', 0):.2f}%
            
            âš¡ ë¦¬ìŠ¤í¬ ì§€í‘œ:
            â€¢ ìµœëŒ€ ë‚™í­: {results.get('max_drawdown', 0):.2f}%
            â€¢ ìƒ¤í”„ ë¹„ìœ¨: {results.get('sharpe_ratio', 0):.2f}
            â€¢ ì†ìµë¹„: {results.get('profit_loss_ratio', 0):.2f}
            
            ğŸ’° ìˆ˜ìˆ˜ë£Œ ì •ë³´:
            â€¢ ì´ ìˆ˜ìˆ˜ë£Œ: â‚©{results.get('total_fees', 0):,.0f}
            """
            
            ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, 
                    verticalalignment='top', fontsize=11, 
                    bbox=dict(boxstyle='round,pad=1', facecolor='lightblue', alpha=0.8))
            
            # ë ˆì´ì•„ì›ƒ ì¡°ì •
            plt.tight_layout()
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"backtest_results_{timestamp}.png"
            filepath = os.path.join(save_dir, filename)
            
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            print(f"âœ… ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì°¨íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
            
            # ì°¨íŠ¸ í‘œì‹œ (ì„ íƒì‚¬í•­)
            plt.show()
            
            return filepath
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ì˜¤ë¥˜: {e}")
            print(f"ê²°ê³¼ ë°ì´í„° êµ¬ì¡°: {list(results.keys()) if isinstance(results, dict) else type(results)}")
            return None

   
    
    def save_backtest_results(self, ticker, backtest_results, evaluation, output_dir="backtest_results", suffix=""):
        """ìµœì í™”ëœ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ """
        print(f"ì €ì¥ ì‹œì‘: {output_dir} í´ë”ì— ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ (OPTIMIZED)")
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # 1. í•µì‹¬ ê²°ê³¼ë§Œ ì €ì¥ (ìš©ëŸ‰ ëŒ€í­ ì¶•ì†Œ)
        essential_results = []
        
        # ê±°ë˜ ê´€ë ¨ ë‚ ì§œë§Œ ì €ì¥
        for result in backtest_results:
            decision = result.get('actual_decision', 'HOLD')
            
            # HOLDê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì €ì¥
            if decision != 'HOLD' or result.get('in_position', False):
                essential_data = {
                    'date': result.get('date'),
                    'price': result.get('price'),
                    'ai_decision': result.get('ai_decision'),
                    'actual_decision': decision,
                    'profit_pct': result.get('profit_pct', 0),
                    'confidence': result.get('confidence', 0),
                    'market_trend': result.get('market_trend', ''),
                    'news_count': result.get('news_count', 0),
                    'support_strength': result.get('support_strength', 0)
                }
                essential_results.append(essential_data)
        
        # 2. ì••ì¶• ì €ì¥
        results_file = os.path.join(output_dir, f"{ticker}_backtest_essential{suffix}.json")
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(essential_results, f, indent=1, ensure_ascii=False)
            print(f"Essential results saved ({len(essential_results)} records): {results_file}")
        except Exception as e:
            print(f"Error saving essential results: {str(e)}")
        
        # 3. í‰ê°€ ê²°ê³¼ ì €ì¥ (ê°„ì†Œí™”)
        eval_file = os.path.join(output_dir, f"{ticker}_evaluation{suffix}.json")
        
        if evaluation:
            # í‰ê°€ ê²°ê³¼ì—ì„œ í° ë°ì´í„° ì œì™¸
            compact_evaluation = {
                'initial_balance': evaluation.get('initial_balance'),
                'final_balance': evaluation.get('final_balance'),
                'total_return_pct': evaluation.get('total_return_pct'),
                'max_drawdown_pct': evaluation.get('max_drawdown_pct'),
                'trade_count': evaluation.get('trade_count'),
                'win_rate': evaluation.get('win_rate'),
                'profit_factor': evaluation.get('profit_factor'),
                'sharpe_ratio': evaluation.get('sharpe_ratio'),
                'avg_profit': evaluation.get('avg_profit'),
                'avg_loss': evaluation.get('avg_loss'),
                'execution_time': evaluation.get('execution_time'),
                # ê±°ë˜ ë‚´ì—­ì€ ê°„ì†Œí™”
                'trade_summary': {
                    'total_trades': len(evaluation.get('trades', [])),
                    'profitable_trades': len([t for t in evaluation.get('trades', []) if t.get('profit_pct', 0) > 0])
                }
            }
            
            try:
                with open(eval_file, 'w', encoding='utf-8') as f:
                    json.dump(compact_evaluation, f, indent=2, ensure_ascii=False)
                print(f"Compact evaluation saved: {eval_file}")
            except Exception as e:
                print(f"Error saving evaluation: {str(e)}")
        
        print(f"ìµœì í™”ëœ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
        return (results_file, eval_file)
    
    def generate_sample_news(self, coin, date_from, date_to):
        """
        ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„± (ë‰´ìŠ¤ API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        """
        sample_topics = [
            "Bitcoin price analysis",
            "Cryptocurrency market trends",
            "Bitcoin trading volume surges",
            "Institutional investors enter Bitcoin market",
            "Regulatory updates for cryptocurrencies",
            "Bitcoin technical analysis",
            "Blockchain technology developments",
            "Cryptocurrency adoption news",
            "Bitcoin mining difficulty adjustments",
            "Digital asset investment strategies"
        ]
        
        sample_sources = [
            "CoinDesk", "CryptoNews", "Bitcoin Magazine", 
            "Cointelegraph", "The Block", "Decrypt", 
            "Bitcoin.com", "CoinMarketCap", "BlockFi Blog"
        ]
        
        # ë‚ ì§œ ë²”ìœ„ ë‚´ ëœë¤ ë‚ ì§œ ìƒì„±
        date_range = (date_to - date_from).days
        
        sample_news = []
        for i in range(10):  # 10ê°œ ìƒ˜í”Œ ë‰´ìŠ¤
            random_days = random.randint(0, max(0, date_range))
            news_date = date_from + datetime.timedelta(days=random_days)
            
            news_item = {
                "title": f"{random.choice(sample_topics)} - {coin}",
                "description": f"This is a sample news article about {coin} generated for backtesting purposes.",
                "source": random.choice(sample_sources),
                "publishedAt": news_date.strftime("%Y-%m-%dT%H:%M:%SZ"),
                "url": f"https://example.com/news/{i+1}",
                "is_sample": True
            }
            sample_news.append(news_item)
        
        return sample_news

    
    def generate_backtest_report(self, ticker, backtest_results, evaluation, output_dir="backtest_results", suffix=""):
        """ë” ìƒì„¸í•œ ë°±í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„± - KRW í‘œì‹œ ê°œì„  ë° ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        report_file = os.path.join(output_dir, f"{ticker}_backtest_report{suffix}.md")
        
        # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
        report = f"""# AI-Driven Backtesting Report for {ticker}

    ## Overview
    - **Period**: {backtest_results[0]['date']} to {backtest_results[-1]['date']}
    - **Initial Investment**: â‚©{evaluation['initial_balance']:,.0f} KRW
    - **Final Portfolio Value**: â‚©{evaluation['final_balance']:,.0f} KRW
    - **Total Return**: {evaluation['total_return_pct']:.2f}%

    ## Performance Metrics
    - **Number of Trades**: {evaluation['trade_count']}
    - **Win Rate**: {evaluation['win_rate']:.2f}%
    - **Average Profit per Winning Trade**: â‚©{evaluation['avg_profit']:,.0f} KRW
    - **Average Loss per Losing Trade**: â‚©{evaluation['avg_loss']:,.0f} KRW
    - **Profit Factor**: {evaluation.get('profit_factor', 0):.2f}
    - **Sharpe Ratio**: {evaluation.get('sharpe_ratio', 0):.2f}%
    - **Max Drawdown**: {evaluation.get('max_drawdown_pct', 0):.2f}%

    ## Korean Market Specific Notes
    - All prices are in Korean Won (KRW)
    - All trading occurs on Upbit exchange
    - Markets operate 24/7 with different liquidity patterns
    - Korean market hours affect volume and volatility patterns

    ## RAG System Analysis

    ### Context Learning Effectiveness
    - **Total Context Entries**: {len(self.document_store) if hasattr(self, 'document_store') else 'N/A'}
    - **Vectorization Status**: {'Active' if hasattr(self, 'vectors') and self.vectors is not None else 'Inactive'}
    - **Pattern Recognition**: Enabled for similar market conditions

    ## News Data Source Summary
    - **Dataset Sources**: {len(self.news_handlers) if hasattr(self, 'news_handlers') else 0}
    - **Total News Articles Processed**: {sum(day.get('news_count', 0) for day in backtest_results)}

    ## Trade Details
    | # | Type | Reason | Entry Date | Exit Date | Entry Price (â‚©) | Exit Price (â‚©) | Profit % | Profit Amount (â‚©) |
    |---|------|--------|------------|-----------|----------------|----------------|----------|---------------------|
    """
        
        # íŠ¸ë ˆì´ë“œ í…Œì´ë¸” ì‘ì„± - ì´ ë¶€ë¶„ì´ ìˆ˜ì •ë¨
        # 'trades'ì™€ 'trade_history' í‚¤ ëª¨ë‘ ì‹œë„
        trades_data = evaluation.get('trades', evaluation.get('trade_history', []))
        
        if trades_data:
            for i, trade in enumerate(trades_data):
                try:
                    # í•„ë“œ ì ‘ê·¼ ì‹œ get ë©”ì„œë“œë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                    trade_type = trade.get('type', trade.get('trade_type', 'Unknown'))
                    reason = trade.get('reason', '-')
                    entry_date = trade.get('entry_date', '-')
                    exit_date = trade.get('exit_date', '-')
                    entry_price = trade.get('entry_price', 0)
                    exit_price = trade.get('exit_price', 0)
                    profit_pct = trade.get('profit_pct', 0)
                    profit_amount = trade.get('profit_amount', 0)
                    
                    report += f"| {i+1} | {trade_type} | {reason} | {entry_date} | {exit_date} | â‚©{entry_price:,.0f} | â‚©{exit_price:,.0f} | {profit_pct:.2f}% | â‚©{profit_amount:,.0f} |\n"
                except Exception as e:
                    print(f"Error processing trade #{i}: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°„ë‹¨í•œ í˜•íƒœë¡œ ì¶œë ¥
                    report += f"| {i+1} | Error | Error | Error | Error | Error | Error | Error | Error |\n"
        else:
            report += "| - | No trades found | - | - | - | - | - | - | - |\n"
        
        # ì¼ë³„ AI ê²°ì •ê³¼ ë‰´ìŠ¤ ìš”ì•½ ì¶”ê°€
        report += "\n\n## Daily AI Decisions and News\n\n"
        
        for day in backtest_results[:10]:  # ì²˜ìŒ 10ì¼ë§Œ ìƒì„¸íˆ í‘œì‹œ
            try:
                report += f"### {day['date']} - Price: â‚©{day['price']:,.0f} - Decision: {day['ai_decision']}\n\n"
                
                # ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
                report += "#### Technical Indicators\n"
                tech_indicators = day.get('technical_indicators', {})
                if tech_indicators:
                    for indicator, value in tech_indicators.items():
                        report += f"- **{indicator}**: {value}\n"
                else:
                    report += "- No technical indicators available\n"
                
                # ë‰´ìŠ¤ ì¶”ê°€
                news_count = day.get('news_count', 0)
                if news_count > 0:
                    report += f"\n#### News ({news_count} articles)\n"
                    news_data = day.get('news_data', [])
                    if news_data:
                        for i, news in enumerate(news_data[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                            report += f"{i+1}. **{news.get('title', '')}** ({news.get('source', '')}, {news.get('publishedAt', '')})\n"
                            if 'description' in news and news['description']:
                                report += f"   {news['description'][:150]}...\n\n"
                    else:
                        report += "- News data not available\n"
                
                # AI ë¶„ì„ ì¶”ê°€
                report += f"\n#### AI Analysis (Confidence: {day.get('confidence', 0):.2f})\n"
                report += f"Market Trend: {day.get('market_trend', 'N/A')}\n\n"
                
                report += "---\n\n"
            except Exception as e:
                print(f"Error processing day report: {str(e)}")
                report += f"Error processing day data\n\n---\n\n"
        
        # ì‹œì¥ ìƒí™©ë³„ ì„±ëŠ¥ ë¶„ì„
        report += "\n## Market Condition Analysis\n\n"
        
        # ì¶”ì„¸ë³„ ê±°ë˜ ì„±ê³¼ ë¶„ì„
        trend_analysis = {}
        for day in backtest_results:
            trend = day.get('market_trend', 'Unknown')
            if trend not in trend_analysis:
                trend_analysis[trend] = {'buy_signals': 0, 'sell_signals': 0, 'hold_signals': 0}
            
            if day.get('ai_decision') == 'BUY':
                trend_analysis[trend]['buy_signals'] += 1
            elif day.get('ai_decision') == 'SELL':
                trend_analysis[trend]['sell_signals'] += 1
            else:
                trend_analysis[trend]['hold_signals'] += 1
        
        report += "### Trading Signals by Market Trend\n\n"
        report += "| Market Trend | BUY Signals | SELL Signals | HOLD Signals |\n"
        report += "|--------------|------------|--------------|-------------|\n"
        for trend, signals in trend_analysis.items():
            report += f"| {trend} | {signals['buy_signals']} | {signals['sell_signals']} | {signals['hold_signals']} |\n"
        
        # ë‰´ìŠ¤ ì˜í–¥ ë¶„ì„
        report += "\n### News Impact Analysis\n\n"
        
        # ì¼ë³„ ë‰´ìŠ¤ ìˆ˜ì— ë”°ë¥¸ ì˜ì‚¬ê²°ì • ë° ê²°ê³¼ ë¶„ì„
        news_impact = {
            "high_news_days": {"days": 0, "correct_decisions": 0},
            "low_news_days": {"days": 0, "correct_decisions": 0}
        }
        
        for i, day in enumerate(backtest_results):
            # ë‹¤ìŒ ë‚ ì˜ ê°€ê²© ë³€í™” í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)
            if i < len(backtest_results) - 1:
                next_day = backtest_results[i + 1]
                price_change = ((next_day['price'] / day['price']) - 1) * 100
                
                # ë‰´ìŠ¤ê°€ ë§ì€ ë‚ ê³¼ ì ì€ ë‚  êµ¬ë¶„
                if day.get('news_count', 0) >= 3:  # ë‰´ìŠ¤ê°€ ë§ì€ ë‚ 
                    news_impact["high_news_days"]["days"] += 1
                    
                    # AI ê²°ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
                    if (day['ai_decision'] == "BUY" and price_change > 0) or \
                    (day['ai_decision'] == "SELL" and price_change < 0) or \
                    (day['ai_decision'] == "HOLD" and abs(price_change) < 1.0):
                        news_impact["high_news_days"]["correct_decisions"] += 1
                else:  # ë‰´ìŠ¤ê°€ ì ì€ ë‚ 
                    news_impact["low_news_days"]["days"] += 1
                    
                    # AI ê²°ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
                    if (day['ai_decision'] == "BUY" and price_change > 0) or \
                    (day['ai_decision'] == "SELL" and price_change < 0) or \
                    (day['ai_decision'] == "HOLD" and abs(price_change) < 1.0):
                        news_impact["low_news_days"]["correct_decisions"] += 1
        
        # ë‰´ìŠ¤ ì˜í–¥ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if news_impact["high_news_days"]["days"] > 0:
            high_news_accuracy = (news_impact["high_news_days"]["correct_decisions"] / news_impact["high_news_days"]["days"]) * 100
            report += f"On days with 3+ news articles ({news_impact['high_news_days']['days']} days), AI decisions were correct {high_news_accuracy:.2f}% of the time.\n"
        
        if news_impact["low_news_days"]["days"] > 0:
            low_news_accuracy = (news_impact["low_news_days"]["correct_decisions"] / news_impact["low_news_days"]["days"]) * 100
            report += f"On days with fewer news articles ({news_impact['low_news_days']['days']} days), AI decisions were correct {low_news_accuracy:.2f}% of the time.\n"
        
        # ì‹œìŠ¤í…œ ê°œì„  ì œì•ˆ
        report += "\n## System Improvement Recommendations\n\n"
        
        # ìŠ¹ë¥  ê¸°ë°˜ ì œì•ˆ
        if evaluation['win_rate'] < 50:
            report += "1. **Signal Filtering**: Consider implementing stricter signal filtering to improve win rate\n"
            report += "2. **Position Sizing**: Implement dynamic position sizing based on confidence levels\n"
            report += "3. **Market Regime Detection**: Enhance market condition detection for better strategy adaptation\n"
        
        # ì†ìµë¹„ ê¸°ë°˜ ì œì•ˆ
        if evaluation.get('profit_factor', 0) < 1.5:
            report += "4. **Risk Management**: Review stop-loss and trailing-stop parameters for better risk control\n"
            report += "5. **Target Optimization**: Optimize profit targets based on historical performance\n"
        
        # ìƒ¤í”„ ë¹„ìœ¨ ê¸°ë°˜ ì œì•ˆ
        if evaluation.get('sharpe_ratio', 0) < 1.0:
            report += "6. **Volatility Adjustment**: Implement volatility-based position sizing\n"
            report += "7. **Strategy Diversification**: Consider multiple strategies for different market conditions\n"
        
        # RAG ì‹œìŠ¤í…œ ê°œì„  ì œì•ˆ
        report += "\n## RAG System Enhancement\n\n"
        report += "1. **Context Expansion**: Increase historical context window for pattern recognition\n"
        report += "2. **Similarity Metrics**: Implement more sophisticated similarity scoring beyond RSI comparison\n"
        report += "3. **Learning Feedback**: Add post-trade analysis to improve future decision making\n"
        report += "4. **Multi-Asset Context**: Consider cross-asset correlation in decision making\n"
        
        # ê¸°ìˆ ì  ë…¸íŠ¸ ì¶”ê°€
        report += "\n### Technical Note\n"
        report += "This backtest utilized an enhanced RAG (Retrieval-Augmented Generation) system that learns from historical patterns and adapts to market conditions. The system maintains a document store of past market contexts and uses similarity search to inform trading decisions.\n"
        
        # ë³´ê³ ì„œ ì €ì¥
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"Backtest report saved to {report_file}")
        except Exception as e:
            print(f"Error saving backtest report: {str(e)}")
            report_file = None
        
        return report_file
    

class NewsDatasetHandler:
    """
    ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤
    """
    def __init__(self, dataset_path, format_config=None):
        """
        format_config: ë°ì´í„°ì…‹ í˜•ì‹ì„ ì •ì˜í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        """
        self.dataset_path = dataset_path
        # format_configê°€ ì—†ìœ¼ë©´ detect_format() í˜¸ì¶œ, ìˆìœ¼ë©´ ì‚¬ìš©
        self.format_config = format_config if format_config is not None else self.detect_format()
        self.news_data = None
        self.load_dataset()
        
    def load_dataset(self):
        try:
            # CSV íŒŒì¼ ë¡œë“œ
            self.news_data = pd.read_csv(self.dataset_path)
            
            # utc=True íŒŒë¼ë¯¸í„° ì¶”ê°€: ëª¨ë“  ë‚ ì§œë¥¼ UTC íƒ€ì„ì¡´ìœ¼ë¡œ ë³€í™˜
            self.news_data['published_time'] = pd.to_datetime(self.news_data['published_time'], errors='coerce', utc=True)
            
            # ë‚ ì§œê°€ ì—†ëŠ” í–‰ ì œê±°
            self.news_data = self.news_data.dropna(subset=['published_time'])
            
            # ë‚ ì§œë³„ë¡œ ì •ë ¬
            self.news_data = self.news_data.sort_values('published_time')
            
            print(f"Successfully loaded {len(self.news_data)} news articles from dataset.")
            print("Dataset time range:", 
                self.news_data['published_time'].min().strftime('%Y-%m-%d'),
                "to", 
                self.news_data['published_time'].max().strftime('%Y-%m-%d'))
        
        except Exception as e:
            print(f"Error loading news dataset: {str(e)}")
            self.news_data = pd.DataFrame()


    def detect_format(self):
        """ì²« ëª‡ ì¤„ì„ ì½ì–´ì„œ í˜•ì‹ ìë™ ê°ì§€"""
        try:
            # ì²« 10ì¤„ë§Œ ì½ì–´ì„œ ë¶„ì„
            df_sample = pd.read_csv(self.dataset_path, nrows=10)
            columns = df_sample.columns.tolist()
            
            # ì—´ ì´ë¦„ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­
            if 'url' in columns and 'text' in columns and 'title' in columns:
                return {
                    'type': 'cointelegraph',
                    'mappings': {
                        'title': 'title',
                        'description': 'text',
                        'url': 'url',
                        'published_time': 'published_time'
                    }
                }
            elif 'header' in columns and 'date' in columns and 'link' in columns:
                return {
                    'type': 'crypto_news',
                    'mappings': {
                        'title': 'header',
                        'url': 'link',
                        'published_time': 'date'
                    }
                }
            elif 'datetime' in columns and 'text' in columns:
                return {
                    'type': 'labeled_news',
                    'mappings': {
                        'description': 'text',
                        'url': 'url',
                        'published_time': 'datetime'
                    }
                }
            else:
                # ê¸°ë³¸ í˜•ì‹
                return {
                    'type': 'default',
                    'mappings': {
                        'title': columns[0] if len(columns) > 0 else 'title',
                        'description': columns[1] if len(columns) > 1 else 'text',
                        'url': columns[2] if len(columns) > 2 else 'url'
                    }
                }
        except Exception as e:
            print(f"Error detecting format: {str(e)}")
            return {
            'type': 'default',
            'mappings': {
                'title': 'title',
                'description': 'text',
                'url': 'url',
                'published_time': 'published_time'
            }
        }
        
    def load_dataset(self):
        """ë°ì´í„°ì…‹ ë¡œë“œ ë° í‘œì¤€í™”"""
        try:
            self.news_data = pd.read_csv(self.dataset_path)
            
            # ë³µí•© í—¤ë” ì²˜ë¦¬ (NFT market í˜•ì‹)
            if 'header' in self.news_data.columns and '\n' in str(self.news_data['header'].iloc[0]):
                self.news_data['clean_header'] = self.news_data['header'].apply(
                    lambda x: x.split('\n')[0] if isinstance(x, str) else x
                )
                self.format_config['mappings']['title'] = 'clean_header'
            
            # ë‚ ì§œ ì—´ í‘œì¤€í™”
            date_columns = ['published_time', 'date', 'datetime']
            for col in date_columns:
                if col in self.news_data.columns:
                    self.news_data[col] = pd.to_datetime(
                        self.news_data[col], 
                        errors='coerce', 
                        utc=True
                    )
            
        except Exception as e:
            print(f"Error loading dataset: {str(e)}")
            self.news_data = pd.DataFrame()
    

    def get_news_cache_path(self, coin, date_from, date_to):
        """
        íŠ¹ì • ë‚ ì§œ ë²”ìœ„ì˜ ë‰´ìŠ¤ì— ëŒ€í•œ ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜ - ìˆ˜ì •ëœ ë²„ì „
        """
        # ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        if not hasattr(self, 'news_cache_dir') or not self.news_cache_dir:
            self.news_cache_dir = "news_cache"
        os.makedirs(self.news_cache_dir, exist_ok=True)
        
        # ì½”ì¸ ì‹¬ë³¼ ì •ë¦¬
        if isinstance(coin, str) and coin.startswith("KRW-"):
            symbol = coin.split("-")[1]
        else:
            symbol = str(coin)
        
        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        if isinstance(date_from, (datetime.datetime, pd.Timestamp)):
            date_from_str = date_from.strftime("%Y%m%d")
        else:
            # ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            date_from_str = str(date_from).replace("-", "")[:8]
        
        if isinstance(date_to, (datetime.datetime, pd.Timestamp)):
            date_to_str = date_to.strftime("%Y%m%d")
        else:
            # ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            date_to_str = str(date_to).replace("-", "")[:8]
        
        return os.path.join(self.news_cache_dir, f"{symbol.lower()}_{date_from_str}_{date_to_str}.json")


    def get_news_for_date_range(self, start_date, end_date):
        """í‘œì¤€í™”ëœ í˜•ì‹ìœ¼ë¡œ ë‰´ìŠ¤ ë°˜í™˜"""
        if self.news_data is None or self.news_data.empty:
            return []
        
        try:
            # ë‚ ì§œ ì—´ ì°¾ê¸°
            date_col = None
            for col in ['published_time', 'date', 'datetime']:
                if col in self.news_data.columns:
                    date_col = col
                    break
            
            if date_col is None:
                return []
            
            # ë‚ ì§œ í•„í„°ë§
            start_date_ts = pd.Timestamp(start_date).tz_localize('UTC')
            end_date_ts = pd.Timestamp(end_date).tz_localize('UTC')
            
            mask = (self.news_data[date_col] >= start_date_ts) & \
                   (self.news_data[date_col] <= end_date_ts)
            
            filtered_news = self.news_data[mask]
            
            # ë§¤í•‘ì„ í†µí•´ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            news_list = []
            mappings = self.format_config.get('mappings', {})
            
            for _, news in filtered_news.iterrows():
                news_dict = {
                    "title": news.get(mappings.get('title', ''), ''),
                    "url": news.get(mappings.get('url', ''), ''),
                    "description": news.get(mappings.get('description', ''), ''),
                    "source": f"Dataset-{self.format_config['type']}",
                    "publishedAt": news[date_col].strftime('%Y-%m-%dT%H:%M:%SZ') if pd.notna(news[date_col]) else ''
                }
                news_list.append(news_dict)
            
            return news_list
            
        except Exception as e:
            print(f"Error getting news for date range: {str(e)}")
            return []

    # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì§ì ‘ í™•ì¸í•˜ëŠ” ì½”ë“œ
def check_backtest_results_directly(backtest_results):
    """
    í‰ê°€ í•¨ìˆ˜ ì—†ì´ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì§ì ‘ ë¶„ì„
    """
    
    print("ğŸ” === ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì§ì ‘ ë¶„ì„ ===")
    print(f"ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(backtest_results)}")
    
    # ë§¤ìˆ˜/ë§¤ë„ ê±°ë˜ ì¶”ì¶œ
    buy_trades = []
    sell_trades = []
    
    for result in backtest_results:
        if result.get('actual_decision') == 'BUY':
            buy_trades.append(result)
        elif result.get('actual_decision') in ['SELL_PROFIT', 'SELL_STOPLOSS', 'SELL_TIMEOUT']:
            sell_trades.append(result)
    
    print(f"\nğŸ“ˆ ë§¤ìˆ˜ ê±°ë˜: {len(buy_trades)}ê±´")
    for i, trade in enumerate(buy_trades, 1):
        print(f"  {i}. {trade['date']} - â‚©{trade['price']:,.0f}")
        print(f"     íˆ¬ìê¸ˆ: â‚©{trade.get('total_cost', trade.get('investment_amount', 0)):,.0f}")
        print(f"     ì½”ì¸ëŸ‰: {trade['coin_amount']:.8f} BTC")
    
    print(f"\nğŸ“‰ ë§¤ë„ ê±°ë˜: {len(sell_trades)}ê±´")
    for i, trade in enumerate(sell_trades, 1):
        print(f"  {i}. {trade['date']} - â‚©{trade['price']:,.0f}")
        print(f"     ìˆ˜ìµ: â‚©{trade.get('profit_amount', 0):,.0f} ({trade.get('profit_pct', 0):.2f}%)")
        print(f"     ì‚¬ìœ : {trade.get('exit_reason', 'ë¶ˆëª…')}")
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    total_profit = sum(trade.get('profit_amount', 0) for trade in sell_trades)
    total_investment = sum(trade.get('total_cost', trade.get('investment_amount', 0)) for trade in buy_trades)
    
    if total_investment > 0:
        actual_return_pct = (total_profit / total_investment) * 100
    else:
        actual_return_pct = 0
    
    print(f"\nğŸ’° ì‹¤ì œ ê³„ì‚° ê²°ê³¼:")
    print(f"  â”œâ”€ ì´ íˆ¬ìê¸ˆ: â‚©{total_investment:,.0f}")
    print(f"  â”œâ”€ ì´ ìˆ˜ìµ: â‚©{total_profit:,.0f}")
    print(f"  â”œâ”€ ì‹¤ì œ ìˆ˜ìµë¥ : {actual_return_pct:.2f}%")
    print(f"  â””â”€ ê±°ë˜ ì„±ê³µë¥ : {len(sell_trades)}/{len(buy_trades)} = {(len(sell_trades)/max(1,len(buy_trades)))*100:.1f}%")
    
    # ê° ê±°ë˜ ìƒì„¸ ë¶„ì„
    print(f"\nğŸ“Š ê±°ë˜ë³„ ìƒì„¸:")
    for i, buy in enumerate(buy_trades):
        buy_date = buy['date']
        buy_price = buy['price']
        investment = buy.get('total_cost', buy.get('investment_amount', 0))
        
        # í•´ë‹¹ ë§¤ìˆ˜ì— ëŒ€ì‘í•˜ëŠ” ë§¤ë„ ì°¾ê¸°
        corresponding_sell = None
        for sell in sell_trades:
            if sell['entry_date'] == buy_date:
                corresponding_sell = sell
                break
        
        if corresponding_sell:
            profit = corresponding_sell.get('profit_amount', 0)
            profit_pct = corresponding_sell.get('profit_pct', 0)
            sell_date = corresponding_sell['date']
            exit_reason = corresponding_sell.get('exit_reason', 'ë¶ˆëª…')
            
            print(f"  ê±°ë˜ #{i+1}:")
            print(f"    ë§¤ìˆ˜: {buy_date} @ â‚©{buy_price:,.0f} (â‚©{investment:,.0f})")
            print(f"    ë§¤ë„: {sell_date} @ â‚©{corresponding_sell['price']:,.0f}")
            print(f"    ê²°ê³¼: â‚©{profit:,.0f} ({profit_pct:+.2f}%) - {exit_reason}")
        else:
            print(f"  ê±°ë˜ #{i+1}: ë§¤ìˆ˜ë§Œ ìˆìŒ (ë§¤ë„ ë¯¸ì™„ë£Œ)")
    
    return {
        'buy_count': len(buy_trades),
        'sell_count': len(sell_trades),
        'total_profit': total_profit,
        'total_investment': total_investment,
        'actual_return_pct': actual_return_pct
    }

# ì‚¬ìš©ë²•:
# results = check_backtest_results_directly(backtest_results)



from dotenv import load_dotenv
import os

    

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ìƒˆë¡œìš´ íš¨ìœ¨ì  ë°±í…ŒìŠ¤íŒ… ì ìš©"""
    load_dotenv()
    
    # ì„¤ì •
    LLAMA_MODEL_PATH = "C:/work/Trading_AI/llama4-dolphin-8B/llama4-dolphin-8B.Q5_K_M.gguf"
    NEWS_API_KEY = os.getenv("NEWS_API_KEY")
    
    # í…ŒìŠ¤íŠ¸ ê¸°ê°„ - ì •í™•í•œ 2021ë…„ 2ì›” ë°ì´í„°ë§Œ ì‚¬ìš©
    TEST_PERIODS = [
        {"name": "efficient_test", "start": "2018-05-01", "end": "2025-05-30", 
         "desc": "íš¨ìœ¨ì  ë°±í…ŒìŠ¤íŠ¸ (rag1)10m", "method": "new"},
       
            ]
    
    # ë‹¤ì–‘í•œ ì‹œê°„í”„ë ˆì„ í…ŒìŠ¤íŠ¸
    TIMEFRAMES = ['10m']  # '1m'ì€ API ë¶€í•˜ê°€ ì»¤ì„œ '1h'ë¡œ ë³€ê²½
    
    NEWS_DATASETS = [
        "C:\\work\\Data_Set\\dmitriykutsenko_bitcoin_news-train.csv",
        "C:\\work\\Data_Set\\FadedCalendula_cryptonews_srp_data-train.csv",
        "C:\\work\\Data_Set\\SahandNZ_cryptonews-articles-with-price-momentum-labels-train.csv"
    ]
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
    results_dir = "backtest_results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
        print(f"ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    
    # ê²°ê³¼ ì €ì¥
    test_results = {}
    
    for timeframe in TIMEFRAMES:
        for period in TEST_PERIODS:
            test_id = f"{period['name']}_{timeframe}_{period['method']}"
            
            print(f"\n{'='*60}")
            print(f"í…ŒìŠ¤íŠ¸ ID: {test_id}")
            print(f"ì„¤ëª…: {period['desc']}")
            print(f"ì‹œê°„í”„ë ˆì„: {timeframe}")
            print(f"ë°©ì‹: {period['method']}")
            print(f"{'='*60}")
            
            # ì¤‘ìš”: ë§¤ í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            backtester = AIBacktester(
                llama_model_path=LLAMA_MODEL_PATH,
                n_gpu_layers=20,
                news_api_key=NEWS_API_KEY,
                news_datasets=NEWS_DATASETS,
                use_selenium=True,
                headless=True,
                timeframe=timeframe
            )
            
            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì „ ìƒíƒœ ì´ˆê¸°í™”
            if hasattr(backtester, 'reset'):
                backtester.reset()
            else:
                # reset ë©”ì„œë“œê°€ ì—†ëŠ” ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ì´ˆê¸°í™”
                backtester.historical_data = []
                backtester.backtest_results = []
                backtester.document_store = []
                backtester.processed_timestamps = set() if hasattr(backtester, 'processed_timestamps') else set()
                backtester.consecutive_losses = 0
                backtester.stop_loss_streak = 0
                backtester.cooldown_until = -1
                backtester.recovery_factor = 1.0
            
            # í…ŒìŠ¤íŠ¸ ë°©ì‹ ì„ íƒ
            try:
                if period['method'] == 'new':
                    # ìƒˆë¡œìš´ ë°©ì‹
                    print(f"ì‹¤í–‰ ì¤‘: ìƒˆë¡œìš´ ë°±í…ŒìŠ¤íŠ¸ ë°©ì‹ (ì§€ì§€ì„  íŠ¸ë¦¬ê±°)")
                    backtest_results = backtester.run_backtest(
                        start_date=period['start'],
                        end_date=period['end'],
                        timeframe=timeframe,
                        test_mode=False,
                        llm_mode=True,
                        initial_position=False
                    )
                else:
                    # ê¸°ì¡´ ë°©ì‹
                    print(f"ì‹¤í–‰ ì¤‘: ê¸°ì¡´ ë°±í…ŒìŠ¤íŠ¸ ë°©ì‹ (ì „ì²´ ë°ì´í„°)")
                    historical_data = backtester.fetch_historical_data(
                        ticker="KRW-BTC",
                        interval="day",
                        count=30,
                        to=period["end"]
                    )
                    
                    if historical_data is not None and not historical_data.empty:
                        backtest_results = backtester.run_backtest(
                            data=historical_data,
                            test_mode=False,
                            llm_mode=True,
                            initial_position=False
                        )
                    else:
                        print(f"Failed to fetch historical data for {test_id}")
                        continue
                
                # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‰ê°€
                if backtest_results and len(backtest_results) > 0:
                    print(f"ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ. ê²°ê³¼ í‰ê°€ ì¤‘...")
                    
                    try:
                        # calculate_holding_days í•¨ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° ì¶”ê°€
                        if not hasattr(backtester, 'calculate_holding_days'):
                            backtester.calculate_holding_days = lambda entry_date, exit_date: 1  # ì„ì‹œ ê¸°ëŠ¥
                            print("Warning: calculate_holding_days í•¨ìˆ˜ê°€ ì—†ì–´ ì„ì‹œ í•¨ìˆ˜ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                            
                        evaluation = backtester.evaluate_backtest(backtest_results)
                        
                        if evaluation:
                            # ê²°ê³¼ ì €ì¥
                            test_results[test_id] = {
                                "method": period['method'],
                                "timeframe": timeframe,
                                "total_return": evaluation["total_return_pct"],
                                "trade_count": evaluation["trade_count"],
                                "win_rate": evaluation["win_rate"],
                                "max_drawdown": evaluation.get("max_drawdown_pct", 0),
                                "sharpe_ratio": evaluation.get("sharpe_ratio", 0),
                                "ai_calls": len([r for r in backtest_results if r.get('ai_decision') != 'NONE']),
                                "rag_patterns": len(backtester.document_store) if hasattr(backtester, 'document_store') else 0
                            }
                            
                            # ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
                            try:
                                print(f"ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥ ì¤‘...")
                                backtester.plot_backtest_results("KRW-BTC", backtest_results, evaluation)
                                backtester.save_backtest_results("KRW-BTC", backtest_results, evaluation, suffix=f"_{test_id}")
                                backtester.generate_backtest_report("KRW-BTC", backtest_results, evaluation, suffix=f"_{test_id}")
                                print(f"ê²°ê³¼ê°€ {results_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                print(f"ê²°ê³¼ ì‹œê°í™”/ì €ì¥ ì˜¤ë¥˜: {str(e)}")
                            
                            print(f"\n--- ê²°ê³¼ ìš”ì•½: {test_id} ---")
                            print(f"ì´ ìˆ˜ìµë¥ : {evaluation['total_return_pct']:.2f}%")
                            print(f"ê±°ë˜ íšŸìˆ˜: {evaluation['trade_count']}")
                            print(f"ìŠ¹ë¥ : {evaluation['win_rate']:.2f}%")
                            print(f"ìµœëŒ€ ë‚™í­: {evaluation.get('max_drawdown_pct', 0):.2f}%")
                            print(f"ìƒ¤í”„ ë¹„ìœ¨: {evaluation.get('sharpe_ratio', 0):.2f}")
                    except Exception as e:
                        print(f"ë°±í…ŒìŠ¤íŠ¸ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
                        import traceback
                        traceback.print_exc()
            except Exception as e:
                print(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                import traceback
                traceback.print_exc()
    
    # ê²°ê³¼ ë¹„êµ ì¶œë ¥
    if test_results:
        print(f"\n{'='*80}")
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¢…í•© ë¹„êµ")
        print(f"{'='*80}")
        print(f"{'í…ŒìŠ¤íŠ¸ ID':<30} {'ë°©ì‹':<10} {'ì‹œê°„í”„ë ˆì„':<10} {'ìˆ˜ìµë¥ ':<10} {'ê±°ë˜ìˆ˜':<8} {'ìŠ¹ë¥ ':<8} {'ìµœëŒ€ë‚™í­':<10} {'ìƒ¤í”„ë¹„ìœ¨':<10}")
        print("-" * 80)
        
        for test_id, result in test_results.items():
            print(f"{test_id:<30} {result['method']:<10} {result['timeframe']:<10} "
                  f"{result['total_return']:>8.2f}% {result['trade_count']:>6} "
                  f"{result['win_rate']:>6.2f}% {result['max_drawdown']:>8.2f}% "
                  f"{result['sharpe_ratio']:>8.2f}")
        
        # ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥
        try:
            summary_file = os.path.join(results_dir, f"test_summary_{int(time.time())}.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, indent=2, ensure_ascii=False)
            print(f"\nì¢…í•© ê²°ê³¼ê°€ {summary_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    main()
